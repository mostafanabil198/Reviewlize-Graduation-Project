{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GP-Aspect Opinion Pair Extraction",
      "provenance": [],
      "collapsed_sections": [
        "2zFvaA8_A32_",
        "0X9FlEjfaP04",
        "5ySGY6y-exgS",
        "2wYsYaug7O7L",
        "VK-owXSwXd_2",
        "515tq6DzXxwy"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafanabil198/Reviewlize-Graduation-Project/blob/aspect-opinion-pair-extraction/GP_Aspect_Opinion_Pair_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51J1ZqenajeH"
      },
      "source": [
        "## Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUF_TgLkaoTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a7b7ec4-98cc-4ae1-9a8b-71a0993b653b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1jR582pjUDA"
      },
      "source": [
        "corenlp_dir = 'drive/My Drive/GP/pair-extraction/corenlp'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpKwWeVkASGt"
      },
      "source": [
        "## Installation & Environment Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Az2ECuAfG8"
      },
      "source": [
        "### Installing Stanza"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiFwYAgW4Mss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9bb461-55b3-4172-a4e5-08f1cab64a91"
      },
      "source": [
        "# Install stanza\n",
        "!pip install stanza\n",
        "\n",
        "# Import stanza\n",
        "import stanza"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stanza\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/ae/a70a58ce6b4e2daad538688806ee0f238dbe601954582a74ea57cde6c532/stanza-1.2-py3-none-any.whl (282kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 20.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 17.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30kB 15.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 51kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 81kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 92kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 102kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 112kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 122kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 143kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 153kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 163kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 174kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 184kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 194kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 204kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 215kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 225kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 235kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 245kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 256kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 266kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 276kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (57.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2020.12.5)\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP_qn4hAZ6Ys"
      },
      "source": [
        "### Installing Spacy and Pysbd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w08A6CIPZ59f",
        "outputId": "d086fa05-594c-4577-84d8-c63d68f89251"
      },
      "source": [
        "# Install pysbd\n",
        "!pip install pysbd\n",
        "\n",
        "import spacy\n",
        "from pysbd.utils import PySBDFactory\n",
        "nlp = spacy.blank('en')\n",
        "nlp.add_pipe(PySBDFactory(nlp))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pysbd\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/0a/c99fb7d7e176f8b176ef19704a32e6a9c6aafdf19ef75a187f701fc15801/pysbd-0.3.4-py3-none-any.whl (71kB)\n",
            "\r\u001b[K     |████▋                           | 10kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 20kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 30kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 40kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 51kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 61kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.5MB/s \n",
            "\u001b[?25hInstalling collected packages: pysbd\n",
            "Successfully installed pysbd-0.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zFvaA8_A32_"
      },
      "source": [
        "### Downloading & Setting up Stanford CoreNLP on server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgK6-LPV-OdA"
      },
      "source": [
        "# Download the Stanford CoreNLP package with Stanza's installation command\n",
        "# This'll take several minutes, depending on the network speed\n",
        "corenlp_dir = './corenlp'\n",
        "stanza.install_corenlp(dir=corenlp_dir)\n",
        "\n",
        "# Set the CORENLP_HOME environment variable to point to the installation location\n",
        "import os\n",
        "os.environ[\"CORENLP_HOME\"] = corenlp_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X9FlEjfaP04"
      },
      "source": [
        "### Downloading & Setting up Stanford CoreNLP On Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKtBXh4MaSrS",
        "outputId": "69745fa5-e486-4d2a-a02b-c89a66e63518"
      },
      "source": [
        "# Download the Stanford CoreNLP package with Stanza's installation command\n",
        "# This'll take several minutes, depending on the network speed\n",
        "corenlp_dir = 'drive/My Drive/GP/pair-extraction/corenlp'\n",
        "stanza.install_corenlp(dir=corenlp_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-19 15:06:46 INFO: Installing CoreNLP package into drive/My Drive/GP/pair-extraction/corenlp...\n",
            "Downloading http://nlp.stanford.edu/software/stanford-corenlp-latest.zip: 100%|██████████| 505M/505M [01:39<00:00, 5.08MB/s]\n",
            "2021-04-19 15:08:32 WARNING: For customized installation location, please set the `CORENLP_HOME` environment variable to the location of the installation. In Unix, this is done with `export CORENLP_HOME=drive/My Drive/GP/pair-extraction/corenlp`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRXWoo9VhNr6"
      },
      "source": [
        "### Set Environment variable for CoreNLP on Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s63dElL0hVb0"
      },
      "source": [
        "# Set the CORENLP_HOME environment variable to point to the installation location\n",
        "import os\n",
        "os.environ[\"CORENLP_HOME\"] = corenlp_dir"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJsuO6D8D05q"
      },
      "source": [
        "## Initialize Stanford Parser CoreNLP Interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZNHxXHkH1K2"
      },
      "source": [
        "### Constructing CoreNLPClient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS4OKnqJ8wui"
      },
      "source": [
        "# Import client module\n",
        "from stanza.server import CoreNLPClient\n",
        "import string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbOBugvd9JaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f57472-e943-431c-8b9b-c9d25a24467d"
      },
      "source": [
        "# Construct a CoreNLPClient with some basic annotators, a memory allocation of 4GB, and port number 9001\n",
        "client = CoreNLPClient(\n",
        "        annotators=['tokenize','pos','lemma','depparse'],\n",
        "        memory='16G',\n",
        "        endpoint='http://localhost:9002',\n",
        "        be_quiet=True)\n",
        "\n",
        "print(client)\n",
        "\n",
        "# Start the background server and wait for some time\n",
        "# Note that in practice this is totally optional, as by default the server will be started when the first annotation is performed\n",
        "client.start()\n",
        "import time; time.sleep(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-06 23:25:22 INFO: Writing properties to tmp file: corenlp_server-00260168fb4a4ab4.props\n",
            "2021-06-06 23:25:22 INFO: Starting server with command: java -Xmx16G -cp drive/My Drive/GP/pair-extraction/corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9002 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-00260168fb4a4ab4.props -annotators tokenize,pos,lemma,depparse -preload -outputFormat serialized\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<stanza.server.client.CoreNLPClient object at 0x7fe1d8c61fd0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spZrJ-oFdkdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c3b8ed9-0627-4baf-f0fb-5848cc4f8f74"
      },
      "source": [
        "# Print background processes and look for java\n",
        "# You should be able to see a StanfordCoreNLPServer java process running in the background\n",
        "!ps -o pid,cmd | grep java"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    322 java -Xmx16G -cp drive/My Drive/GP/pair-extraction/corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9002 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-00260168fb4a4ab4.props -annotators tokenize,pos,lemma,depparse -preload -outputFormat serialized\n",
            "    343 /bin/bash -c ps -o pid,cmd | grep java\n",
            "    345 grep java\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ySGY6y-exgS"
      },
      "source": [
        "# -Dependency printing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aJJ5mANUM2PG",
        "outputId": "1cd1988b-d129-46cf-8c19-a4fd01d9e720"
      },
      "source": [
        "document = client.annotate(\"I am happy with my Nokia phone\")\n",
        "sentence = document.sentence[0]\n",
        "sentence.token[2].pos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'JJ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI-LngNZagqQ"
      },
      "source": [
        "def getDependencies(review_sentence):\n",
        "  # doc = nlp(text)\n",
        "  # for t in list(doc.sents):\n",
        "  document = client.annotate(str(review_sentence))\n",
        "  sentence = document.sentence[0]\n",
        "  dependency_parse = sentence.basicDependencies\n",
        "  tokens_parse = sentence.token\n",
        "  token_dict = {}\n",
        "  pos_dict = {}\n",
        "  for i in range(0, len(sentence.token)) :\n",
        "      token_dict[sentence.token[i].tokenEndIndex] = sentence.token[i].word\n",
        "      pos_dict[sentence.token[i].word] = sentence.token[i].pos\n",
        "\n",
        "  #get a list of the dependencies with the words they connect\n",
        "  list_dep=[]\n",
        "  for i in range(0, len(dependency_parse.edge)):\n",
        "\n",
        "      source_node = dependency_parse.edge[i].source\n",
        "      source_name = token_dict[source_node]\n",
        "\n",
        "      target_node = dependency_parse.edge[i].target\n",
        "      target_name = token_dict[target_node]\n",
        "\n",
        "      dep = dependency_parse.edge[i].dep\n",
        "      list_dep.append((dep, source_name, target_name))\n",
        "  # print(list_dep)\n",
        "  return list_dep, pos_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgJMcnaGdsA"
      },
      "source": [
        "examples = {1: \"The battery life is good\",\n",
        "            2: \"It is great having the LCD display\",\n",
        "            3: \"I like this camera\",\n",
        "            4: \"The optical zoom works great\",\n",
        "            5: \"It has movie mode that works good for a digital camera\",\n",
        "            6: \"There is a great camera\",\n",
        "            71: \"Nokia has fine, excellent, cheapest battery\",\n",
        "            72: \"Nokia has fine, excellent and cheapest battery\",\n",
        "            8: \"Nokia has good screen and battery\",\n",
        "            9: \"I am happy with my Nokia phone\",\n",
        "            10: \"Battery life was never a problem for me\",\n",
        "            11: \"This camera will give you a great picture quality, LCD screen, and price\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuXqZwSaOh0-"
      },
      "source": [
        "# 1\n",
        "# Extract pair when it's after capular verb => the battery is good\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def copularVerb(list_dep, list_pos, nsubjIx):\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  for nsubjI in nsubjIx:\n",
        "    if(\"JJ\" in list_pos[list_dep[nsubjI][1]]):\n",
        "      for dep in list_dep:\n",
        "        if dep[0] == \"cop\" and dep[1] == list_dep[nsubjI][1]:\n",
        "          opinion = list_dep[nsubjI][1]\n",
        "          aspect = list_dep[nsubjI][2]\n",
        "    if aspect != \"\" and opinion != \"\":\n",
        "      break\n",
        "  return aspect, opinion\n",
        "\n",
        "# Call after any function to return compund aspects or same aspect => battery life\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getCompund(list_dep, aspect):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"compound\" and dep[1] == aspect :\n",
        "      aspect = dep[2] + \" \" + aspect\n",
        "      break;\n",
        "  return aspect\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6f1JCAoXiII"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[1])\n",
        "aspect, opinion = copularVerb(x, y, nsubjI)\n",
        "aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \",opinions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZAmM2gTX9py"
      },
      "source": [
        "# 3\n",
        "# Extract pair when the opinions is the verb like love and like\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "# sentiment_verbs => list of verbs that may be opinion\n",
        "sentiment_verbs = [\"like\", \"love\", \"adore\", \"enjoyed\", \"liked\", \"loved\", \"enjoy\"]\n",
        "def opinionVerb(list_dep, dep):\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  if(sentiment_verbs.count(dep[1])):\n",
        "    opinion = dep[1]\n",
        "    for dep in list_dep:\n",
        "      if (dep[0] == \"obj\" and dep[1] == opinion):\n",
        "        aspect = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8HEa9d6cjl0"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[3])\n",
        "aspect, opinion = opinionVerb(x, y, nsubjI)\n",
        "aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PykGw5pc1Lk"
      },
      "source": [
        "# 5\n",
        "# Extract pair when there is a relative clause relation between the aspect and the opinion => movie mode that works good\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def relativeClause(list_dep, dependency):\n",
        "  aspect = dependency[1]\n",
        "  relcl_opinion = dependency[2]\n",
        "  opinion = \"\"\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"advmod\" and relcl_opinion == dep[1]:\n",
        "      opinion = dep[2]\n",
        "      return aspect, opinion\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGpNXe3KrXGm"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[5])\n",
        "aspect, opinion = relativeClause(x, y, nsubjI)\n",
        "aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAW_vwILrW9U"
      },
      "source": [
        "# 7-1\n",
        "# Extract multi opinions if without \"and\" word. only with \",\"\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def multiOpinion(list_dep, dependency, visited_dep):\n",
        "  aspect = dependency[1]\n",
        "  opinions = []\n",
        "  for dep in list_dep:\n",
        "    if(dep[0] == \"amod\" and dependency[1] == dep[1]):\n",
        "      opinions.append(dep[2])\n",
        "      visited_dep[list_dep.index(dep)] = True\n",
        "  opinions = getAndOpinions(list_dep, opinions)\n",
        "  return aspect, opinions\n",
        "\n",
        "# 7-2\n",
        "# Call after any function to get list of opinions if multi exist with \"and\" word\n",
        "# list_dep => dependency_parsed\n",
        "# opnions => list of opinions \"List\"\n",
        "def getAndOpinions(list_dep, opinions):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (opinions.count(dep[1]) != 0):\n",
        "      opinions.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (opinions.count(dep[2]) != 0):\n",
        "      opinions.append(dep[1])\n",
        "  return opinions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcY8WSuzyd1-"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[72])\n",
        "# aspect, opinions = multiOpinion(x, y, nsubjI)\n",
        "# opinions = getAndOpinions(x, [opinion])\n",
        "# aspects = getAndAspects(x, aspects)\n",
        "# print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRvjc7eB1NjK"
      },
      "source": [
        "# 9\n",
        "# Extract pair when theres a preposition => i am happy \"with\" my phone\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def prepositions(list_dep, list_pos, nsubjIs):\n",
        "  opinion_pos = [\"JJ\", \"JJS\", \"RB\"]\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  for nsubjI in nsubjIs:\n",
        "    if (opinion_pos.count(list_pos[list_dep[nsubjI][1]]) != 0):\n",
        "      for dep in list_dep:\n",
        "          if dep[0] == \"obl\" and dep[1] == list_dep[nsubjI][1]:\n",
        "            aspect = dep[2]\n",
        "            opinion = dep[1]\n",
        "    if aspect != \"\" and opinion != \"\" :\n",
        "      break\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nold0-yy5dYH"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[9])\n",
        "# x, y, nsubjI = getDependencies(\"I had fun with my nokia phone\")\n",
        "aspect, opinion = prepositions(x, y, nsubjI)\n",
        "# aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED91Wkdl84QV"
      },
      "source": [
        "# 11\n",
        "# Call after any function to get list of aspects if multi exist\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getAndAspects(list_dep, aspect):\n",
        "  aspects = [aspect]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (dep[1] == aspect):\n",
        "      aspects.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (dep[2] == aspect):\n",
        "      aspects.append(dep[1])\n",
        "  for i in range(len(aspects)):\n",
        "    aspects[i] = getCompund(list_dep, aspects[i])\n",
        "  return aspects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_ujdlFNOTUK"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[11])\n",
        "# x, y, nsubjI = getDependencies(\"I had fun with my nokia phone\")\n",
        "aspect, opinions = multiOpinion(x, y, nsubjI)\n",
        "# aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, opinions)\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpjcqdH5Xk40"
      },
      "source": [
        "# when the secomd argument in nsubj dependency is not noun and the first is adj.\n",
        "# the feature of the sentence will be the object of it.\n",
        "# use dependencies (nsubj , xcomp , obj) to get the feature.\n",
        "# Ex : it is great having the LCD Display.\n",
        "def apply_nsubj_second(list_dep, dependancy):\n",
        "  f_arg = ''\n",
        "  s_arg = dependancy[1]\n",
        "  verb = ''\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'dep' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'obj' and dep[1] == verb :\n",
        "      f_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ub7aVsdcuJ7"
      },
      "source": [
        "# when the second argument is noun and the opnion part is verb.\n",
        "# the opinion will be the complement of the verb.\n",
        "# Ex : the flash works great.\n",
        "def apply_nsubj_forth (list_dep, dependency) :\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = ''\n",
        "  verb = dependency[1]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'advmod' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ7IDbuvi3SS"
      },
      "source": [
        "# when the feature and opinion pair candidate could in same dependency.\n",
        "# amod dependency the first arg is considered to be the feature.\n",
        "# the second arg is considered to be the opinion words.\n",
        "# Ex : this is a great screen.\n",
        "def apply_amod_sixth (list_dep, dependency) :\n",
        "  f_arg = dependency[1]\n",
        "  s_arg = dependency[2]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyNSP89wsYC-"
      },
      "source": [
        "# when the same opinion word is used to describe more than one feature.\n",
        "# apply conj dependency on the related features. \n",
        "# Ex : Nokia has a good screen and battery.\n",
        "def apply_amod_eight (list_dep, feature) :\n",
        "  feats = []\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'conj' and dep[1] == feature:\n",
        "      feats.append(dep[2])\n",
        "  #call the function check compound of each feature\n",
        "  return feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NdRa9RQ4cBS"
      },
      "source": [
        "# when nsubj dependency is between two nouns.\n",
        "# the first argument can be used as a opinion word.\n",
        "# Ex : the battery was never a problem.\n",
        "def apply_nsubj_ten (list_dep, dependency):\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = dependency[1]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DXQbM5r5qto"
      },
      "source": [
        "# check negation of the opinion words as it can reverse the sentiment.\n",
        "def check_neg(list_dep, adj):\n",
        "    list_neg = ['no' , 'never' , 'not' , 'n\\'t' , 'none' , 'neither'] \n",
        "    #can also check the negative seed list for that.\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == 'advmod' and dep[1] == adj and ( dep[2] in list_neg) :\n",
        "        adj = dep[2] + ' ' + adj\n",
        "        return adj\n",
        "    return adj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbT910j_1R4G"
      },
      "source": [
        "def nsubjAdj(list_dep, list_pos, dependency):\n",
        "  aspect = dependency[2]\n",
        "  opinion = dependency[1]\n",
        "  if list_pos[dependency[1]] == \"JJR\":\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == \"advcl\" and dep[1] == dependency[1]:\n",
        "        opinion = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wYsYaug7O7L"
      },
      "source": [
        "# -All Together\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzzD0hOc7Rz2"
      },
      "source": [
        "def aspectOpinionPairExtractor(list_dep, list_pos):\n",
        "  aspect_opinion_pairs = set()\n",
        "  visited_dep = [False]*len(list_dep)\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'nsubj':\n",
        "      # print(\"nsubj\")\n",
        "      if \"JJ\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #1\n",
        "        aspect, opinion = nsubjAdj(list_dep, list_pos, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"JJ\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #2\n",
        "        aspect, opinion = apply_nsubj_second(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #3\n",
        "        aspect, opinion = opinionVerb(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #4\n",
        "        aspect, opinion = apply_nsubj_forth(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"NN\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #10\n",
        "        aspect, opinion = apply_nsubj_ten(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'amod' and visited_dep[list_dep.index(dep)] == False:\n",
        "      # print(\"amod\")\n",
        "      if \"JJ\" in list_pos[dep[2]]:\n",
        "        aspect, opinion = apply_amod_sixth(list_dep, dep) #6\n",
        "        aspects = apply_amod_eight(list_dep, aspect) #8\n",
        "        aspects.append(aspect)\n",
        "        for a in aspects:\n",
        "          addPair(a, opinion, list_dep, aspect_opinion_pairs)\n",
        "        aspect, opinions = multiOpinion(list_dep, dep, visited_dep) #7\n",
        "        for o in opinions:\n",
        "          addPair(aspect, o, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'obl' and \"JJ\" in list_pos[dep[1]]: #9\n",
        "      # print(\"obl\")\n",
        "      aspect, opinion = prepositions(dep)\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'acl:relcl': #5\n",
        "      # print(\"acl:relcl\")\n",
        "      aspect, opinion = relativeClause(list_dep, dep)\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "  return aspect_opinion_pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A95gaDa7R09g"
      },
      "source": [
        "def addPair(aspect, opinion, list_dep, aspect_opinion_pairs):\n",
        "  if aspect == \"\" or opinion == \"\":\n",
        "    return\n",
        "  aspect = getCompund(list_dep, aspect)\n",
        "  opinion = check_neg(list_dep, opinion)\n",
        "  p = (aspect, opinion)\n",
        "  # print(p)\n",
        "  aspect_opinion_pairs.add(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW6zkW3iUUmx"
      },
      "source": [
        "aspect_opinion_pairs = set()\n",
        "list_dep, list_pos = getDependencies(examples[3])\n",
        "# print(list_pos[\"more\"])\n",
        "x = aspectOpinionPairExtractor(list_dep, list_pos)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH9oosw4Lvx5"
      },
      "source": [
        "# Aspect-Opinion Pair Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgw1VgOPXGuB"
      },
      "source": [
        "## Reviews Anlyzer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e5jSwi_L0TZ"
      },
      "source": [
        "def reviewsAnalyzer(reviews_list, debug = False):\n",
        "  # list to hold each review's sentences and its aspects \n",
        "  # reviews->[ sentences->[ aspects->[{aspect: opinion}, {aspect, opinion}]], [[]], [[]], ]\n",
        "  reviews_sentences_aspects = []\n",
        "\n",
        "  # For each review:\n",
        "    # 1- split to sentences using spacy\n",
        "    # 2- for each sentence:\n",
        "      # 3- get dependences\n",
        "      # 4- extract aspect_opinion pairs\n",
        "  \n",
        "  for review in reviews_list:\n",
        "    # print(\"-=-=R-=>\", review)\n",
        "    review_boundries = nlp(review)\n",
        "    review_sentences = []\n",
        "    for sentence in list(review_boundries.sents): # 1, 2\n",
        "      # print(\"-=-=S-=>\", sentence)\n",
        "      sentence_aspects = []\n",
        "      sentence1 = str(sentence).translate( str.maketrans( '', '', string.punctuation )).strip()\n",
        "      # print(\"-=-=S1-=>\", sentence1)\n",
        "      if (sentence1 == '' or sentence1 == ' ' or len(sentence1) == 0):\n",
        "            continue\n",
        "      list_dep, list_pos = getDependencies(sentence1) # 3\n",
        "      aspect_opinion_pairs = aspectOpinionPairExtractor(list_dep=list_dep, list_pos=list_pos) # 4\n",
        "      if debug == True:\n",
        "        print(\"==========\")\n",
        "        print(\"sentence: \", sentence1)\n",
        "        print(\"dependencies: \", list_dep)\n",
        "        print(\"POS: \", list_pos)\n",
        "        print(\"aspects opinion pairs: \", aspect_opinion_pairs)\n",
        "        print(\"==========\")\n",
        "      for as_op_pair in aspect_opinion_pairs:\n",
        "        sentence_aspects.append(as_op_pair)\n",
        "      review_sentences.append(sentence_aspects)\n",
        "    reviews_sentences_aspects.append(review_sentences)\n",
        "  return reviews_sentences_aspects"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-XkBXxeXV8t"
      },
      "source": [
        "def getDependencies(review_sentence):\n",
        "  document = client.annotate(str(review_sentence))\n",
        "  # print(\"=====>\", review_sentence)\n",
        "  sentence = document.sentence[0]\n",
        "  dependency_parse = sentence.basicDependencies\n",
        "  token_dict = {}\n",
        "  pos_dict = {}\n",
        "  for i in range(0, len(sentence.token)) :\n",
        "      token_dict[sentence.token[i].tokenEndIndex] = sentence.token[i].word\n",
        "      pos_dict[sentence.token[i].word] = sentence.token[i].pos\n",
        "\n",
        "  # get a list of the dependencies with the words they connect\n",
        "  list_dep=[]\n",
        "  for i in range(0, len(dependency_parse.edge)):\n",
        "\n",
        "      source_node = dependency_parse.edge[i].source\n",
        "      source_name = token_dict[source_node]\n",
        "\n",
        "      target_node = dependency_parse.edge[i].target\n",
        "      target_name = token_dict[target_node]\n",
        "\n",
        "      dep = dependency_parse.edge[i].dep\n",
        "      list_dep.append((dep, source_name, target_name))\n",
        "  # print(list_dep)\n",
        "  return list_dep, pos_dict"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtqcWF31Xmr-"
      },
      "source": [
        "def aspectOpinionPairExtractor(list_dep, list_pos):\n",
        "  aspect_opinion_pairs = set()\n",
        "  visited_dep = [False]*len(list_dep)\n",
        "  for dep in list_dep:\n",
        "    if  'nsubj' in dep[0]:\n",
        "      # print(\"nsubj\")\n",
        "      if \"JJ\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #1\n",
        "        aspect, opinion = nsubjAdj(list_dep, list_pos, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"JJ\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #2\n",
        "        aspect, opinion = apply_nsubj_second(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #3\n",
        "        aspect, opinion = opinionVerb(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and (\"NN\" in list_pos[dep[2]]): #4\n",
        "        aspect, opinion = apply_nsubj_forth(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      #elif \"NN\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #10\n",
        "        #aspect, opinion = apply_nsubj_ten(list_dep, dep)\n",
        "        #addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"NN\" in list_pos[dep[1]]: #10\n",
        "        aspect, opinion = apply_nsubj_ten(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'amod' and visited_dep[list_dep.index(dep)] == False:\n",
        "      # print(\"amod\")\n",
        "      if \"JJ\" in list_pos[dep[2]]:\n",
        "        aspect, opinion = apply_amod_sixth(list_dep, dep) #6\n",
        "        # Get multi aspects for same opinion\n",
        "        aspects = apply_amod_eight(list_dep, aspect) #8\n",
        "        aspects.append(aspect)\n",
        "        for a in aspects:\n",
        "          addPair(a, opinion, list_dep, aspect_opinion_pairs)\n",
        "\n",
        "        # Get multi opinions for same aspect\n",
        "        aspect, opinions = multiOpinion(list_dep, dep, visited_dep) #7\n",
        "        for o in opinions:\n",
        "          addPair(aspect, o, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'obl' and \"JJ\" in list_pos[dep[1]]: #9\n",
        "      # print(\"obl\")\n",
        "      aspect = dep[2]\n",
        "      opinion = dep[1]\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'acl:relcl': #5\n",
        "      # print(\"acl:relcl\")\n",
        "      aspect, opinion = relativeClause(list_dep, dep)\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif 'nmod' in dep[0]: #new\n",
        "      aspect = dep[1]\n",
        "      opinion = dep[2]\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "  return aspect_opinion_pairs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bci22ybxXou0"
      },
      "source": [
        "def addPair(aspect, opinion, list_dep, aspect_opinion_pairs):\n",
        "  if aspect == \"\" or opinion == \"\":\n",
        "    return\n",
        "  aspect = getCompund(list_dep, aspect)\n",
        "  opinion = check_neg(list_dep, opinion)\n",
        "  p = (aspect, opinion)\n",
        "  # print(p)\n",
        "  aspect_opinion_pairs.add(p)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK-owXSwXd_2"
      },
      "source": [
        "## Dependencies Rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvaoHCvzXzvO"
      },
      "source": [
        "# Call after any function to return compund aspects or same aspect => battery life\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getCompund(list_dep, aspect):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"compound\" and dep[1] == aspect :\n",
        "      aspect = dep[2] + \" \" + aspect\n",
        "      break;\n",
        "  return aspect"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FmKJzMqYcrA"
      },
      "source": [
        "# 1\n",
        "# Extract pair when it's after capular verb => the battery is good \n",
        "# and if having comparitave adj then get the advcl => the battery is more satisfying\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# dependency => the nsubj dep that leaded to this case\n",
        "def nsubjAdj(list_dep, list_pos, dependency):\n",
        "  aspect = dependency[2]\n",
        "  opinion = dependency[1]\n",
        "  if list_pos[dependency[1]] == \"JJR\":\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == \"advcl\" and dep[1] == dependency[1]:\n",
        "        opinion = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkb7IAnlYcq1"
      },
      "source": [
        "# 2\n",
        "# when the second argument in nsubj dependency is not noun and the first is adj.\n",
        "# the feature of the sentence will be the object of it.\n",
        "# use dependencies (nsubj , xcomp , obj) to get the feature.\n",
        "# Ex : it is great having the LCD Display.\n",
        "def apply_nsubj_second(list_dep, dependancy):\n",
        "  f_arg = ''\n",
        "  s_arg = dependancy[1]\n",
        "  verb = ''\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'dep' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'obj' and dep[1] == verb :\n",
        "      f_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAMFq3ndYcqq"
      },
      "source": [
        "# 3\n",
        "# Extract pair when the opinions is the verb like love and like\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# dependency => the current dep that leaded to this case\n",
        "# sentiment_verbs => list of verbs that may be opinion\n",
        "sentiment_verbs = [\"like\", \"love\", \"adore\", \"enjoyed\", \"liked\", \"loved\", \"enjoy\", \"overloaded\"]\n",
        "def opinionVerb(list_dep, dependency):\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  # if(sentiment_verbs.count(dependency[1])):\n",
        "  opinion = dependency[1]\n",
        "  for dep in list_dep:\n",
        "    if (\"obj\" in dep[0] and dep[1] == opinion):\n",
        "      aspect = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwr-mnGwYcq3"
      },
      "source": [
        "# 4\n",
        "# when the second argument is noun and the opnion part is verb.\n",
        "# the opinion will be the complement of the verb.\n",
        "# Ex : the flash works great.\n",
        "def apply_nsubj_forth (list_dep, dependency) :\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = ''\n",
        "  verb = dependency[1]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'advmod' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPrl0FmrYcqt"
      },
      "source": [
        "# 5\n",
        "# Extract pair when there is a relative clause relation between the aspect and the opinion => movie mode that works good\n",
        "# list_dep => dependency_parsed\n",
        "# dependency => the current dep that leaded to this case\n",
        "def relativeClause(list_dep, dependency):\n",
        "  aspect = dependency[1]\n",
        "  relcl_opinion = dependency[2]\n",
        "  opinion = \"\"\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"advmod\" and relcl_opinion == dep[1]:\n",
        "      opinion = dep[2]\n",
        "      return aspect, opinion\n",
        "  return aspect, opinion"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FrHlqzoYcq6"
      },
      "source": [
        "# 6\n",
        "# when the feature and opinion pair candidate could in same dependency.\n",
        "# amod dependency the first arg is considered to be the feature.\n",
        "# the second arg is considered to be the opinion words.\n",
        "# Ex : this is a great screen.\n",
        "def apply_amod_sixth (list_dep, dependency) :\n",
        "  f_arg = dependency[1]\n",
        "  s_arg = dependency[2]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX9_fQ6WYcqv"
      },
      "source": [
        "# 7-1\n",
        "# Extract multi opinions if without \"and\" word. only with \",\"\n",
        "# list_dep => dependency_parsed\n",
        "# dependency => the current dep that leaded to this case\n",
        "# visited_dep => to make sure if the amod dependency was considered or not in the main loop\n",
        "def multiOpinion(list_dep, dependency, visited_dep):\n",
        "  aspect = dependency[1]\n",
        "  opinions = []\n",
        "  for dep in list_dep:\n",
        "    if(dep[0] == \"amod\" and dependency[1] == dep[1]):\n",
        "      opinions.append(dep[2])\n",
        "      visited_dep[list_dep.index(dep)] = True\n",
        "  opinions = getAndOpinions(list_dep, opinions)\n",
        "  return aspect, opinions\n",
        "\n",
        "# 7-2\n",
        "# Call after any function to get list of opinions if multi exist with \"and\" word\n",
        "# list_dep => dependency_parsed\n",
        "# opnions => list of opinions \"List\"\n",
        "def getAndOpinions(list_dep, opinions):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (opinions.count(dep[1]) != 0):\n",
        "      opinions.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (opinions.count(dep[2]) != 0):\n",
        "      opinions.append(dep[1])\n",
        "  return opinions"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPyhgRTlYcq7"
      },
      "source": [
        "# 8\n",
        "# when the same opinion word is used to describe more than one feature.\n",
        "# apply conj dependency on the related features. \n",
        "# Ex : Nokia has a good screen and battery.\n",
        "def apply_amod_eight (list_dep, feature) :\n",
        "  feats = []\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'conj' and dep[1] == feature:\n",
        "      feats.append(dep[2])\n",
        "  #call the function check compound of each feature\n",
        "  return feats"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNfw29XHYcqx"
      },
      "source": [
        "# 9\n",
        "# Extract pair when theres a preposition => i am happy \"with\" my phone\n",
        "# dependency => the current dep that leaded to this case\n",
        "def prepositions(dependency):\n",
        "  aspect = dependency[2]\n",
        "  opinion = dependency[1]\n",
        "  return aspect, opinion"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYpiAG8TYcq9"
      },
      "source": [
        "# 10\n",
        "# when nsubj dependency is between two nouns.\n",
        "# the first argument can be used as a opinion word.\n",
        "# Ex : the battery was never a problem.\n",
        "def apply_nsubj_ten (list_dep, dependency):\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = dependency[1]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg\n",
        "  "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SarUlp2hYcqz"
      },
      "source": [
        "# 11\n",
        "# Call after any function to get list of aspects if multi exist\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getAndAspects(list_dep, aspect):\n",
        "  aspects = [aspect]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (dep[1] == aspect):\n",
        "      aspects.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (dep[2] == aspect):\n",
        "      aspects.append(dep[1])\n",
        "  for i in range(len(aspects)):\n",
        "    aspects[i] = getCompund(list_dep, aspects[i])\n",
        "  return aspects"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9nG8xaQYcq-"
      },
      "source": [
        "# neg\n",
        "# check negation of the opinion words as it can reverse the sentiment.\n",
        "def check_neg(list_dep, adj):\n",
        "    list_neg = ['no' , 'never' , 'not' , 'n\\'t' , 'none' , 'neither'] \n",
        "    #can also check the negative seed list for that.\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == 'advmod' and dep[1] == adj and ( dep[2] in list_neg) :\n",
        "        adj = dep[2] + ' ' + adj\n",
        "        return adj\n",
        "    return adj"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "515tq6DzXxwy"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWPsmLIpYkUw",
        "outputId": "8e89d279-0159-4271-f41f-df1a287f3dda"
      },
      "source": [
        "xxx = \"mostafa nabil\"\n",
        "client.annotate(xxx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text: \"mostafa nabil\"\n",
              "sentence {\n",
              "  token {\n",
              "    word: \"mostafa\"\n",
              "    pos: \"NN\"\n",
              "    value: \"mostafa\"\n",
              "    before: \"\"\n",
              "    after: \" \"\n",
              "    originalText: \"mostafa\"\n",
              "    lemma: \"mostafa\"\n",
              "    beginChar: 0\n",
              "    endChar: 7\n",
              "    tokenBeginIndex: 0\n",
              "    tokenEndIndex: 1\n",
              "    hasXmlContext: false\n",
              "    isNewline: false\n",
              "  }\n",
              "  token {\n",
              "    word: \"nabil\"\n",
              "    pos: \"NN\"\n",
              "    value: \"nabil\"\n",
              "    before: \" \"\n",
              "    after: \"\"\n",
              "    originalText: \"nabil\"\n",
              "    lemma: \"nabil\"\n",
              "    beginChar: 8\n",
              "    endChar: 13\n",
              "    tokenBeginIndex: 1\n",
              "    tokenEndIndex: 2\n",
              "    hasXmlContext: false\n",
              "    isNewline: false\n",
              "  }\n",
              "  tokenOffsetBegin: 0\n",
              "  tokenOffsetEnd: 2\n",
              "  sentenceIndex: 0\n",
              "  characterOffsetBegin: 0\n",
              "  characterOffsetEnd: 13\n",
              "  basicDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    edge {\n",
              "      source: 2\n",
              "      target: 1\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 2\n",
              "  }\n",
              "  collapsedDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    edge {\n",
              "      source: 2\n",
              "      target: 1\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 2\n",
              "  }\n",
              "  collapsedCCProcessedDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    edge {\n",
              "      source: 2\n",
              "      target: 1\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 2\n",
              "  }\n",
              "  enhancedDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    edge {\n",
              "      source: 2\n",
              "      target: 1\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 2\n",
              "  }\n",
              "  enhancedPlusPlusDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    edge {\n",
              "      source: 2\n",
              "      target: 1\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 2\n",
              "  }\n",
              "  hasRelationAnnotations: false\n",
              "  hasNumerizedTokensAnnotation: false\n",
              "  hasEntityMentionsAnnotation: false\n",
              "}\n",
              "xmlDoc: false\n",
              "hasEntityMentionsAnnotation: false\n",
              "hasCorefMentionAnnotation: false\n",
              "hasCorefAnnotation: false"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FvF9fn5USZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d10d705-bd08-443b-a4f4-ff4874d062e9"
      },
      "source": [
        "examples = [\"The screen is bad\",\n",
        "            \"It is great having the LCD display\",\n",
        "            \"I like this camera\",\n",
        "            \"The optical zoom works great\",\n",
        "            \"It has movie mode that works good for a digital camera\",\n",
        "            \"There is a great camera\",\n",
        "            \"Nokia has fine, excellent, cheapest battery\",\n",
        "            \"Nokia has fine, excellent and cheapest battery\",\n",
        "            \"Nokia has good screen and battery\",\n",
        "            \"I am happy with my Nokia phone\",\n",
        "            \"Battery life was never a problem for me\",\n",
        "            \"This camera will give you a great picture quality, LCD screen, and price\"]                        \n",
        "\n",
        "reviews_list = [                # \"My network connection kept turning off randomly. It wasn’t through my internet service but issues with the laptop itself. I had to remove the whole back of the laptop, remove the battery hold down the power button for a few seconds then place the battery back in to get it to start working again. FYI, I did this 4 times already and haven’t even had this laptop for 2 whole months yet. I’m looking into the issue a little more before buying a new battery (if that’s the main cause of this). I am extremely disappointed and overwhelmed with this constant issue!Pro: Beautiful rose gold\",\n",
        "                # \"This laptop isn't ideal for a lot of reasons, but it does what it's meant to do -- very simple things. So, when the display colors were really off and it was a bit slow at certain programs, I didn't mind too much.However, the very first time I used this laptop, the F key popped off. I pressed it back in, haven't had any further issues with that key, and thought okay -- that was weird and kind of annoying for just having received the laptop, but that's fine. It seems to be fixed.Unfortunately, just after the return period ended, the C key popped off. This was after maybe a week or two of use. (I had saved the laptop for a specific trip, so after the initial setup with the F key incident, I didn't use it for a while until I got to my trip destination.)The C key now pops off routinely, and I constantly have to stop typing and press it back in. I can see there are a couple of other keys that seem to be threatening to do the same.Given that a good portion of my work is as a freelance writer, this is an incredibly frustrating problem to have. Although, I imagine it would be frustrating regardless. I don't think a computer I've only used consistently for a few weeks should have this many problems.While it's lightweight, has a great battery life, and more or less functions the way I need it to for basic online and MS Office tasks, the constant key issues force me to downgrade the star rating.\",\n",
        "                \"I needed a new laptop as I have not bought a decent one since 2000. One teeny tiny screened netbook and one borrowed laptop that doesn't hold a charge in between really made me feel the lack. There are loads of bad reviews saying there isn't enough memory to do anything with this particular model. I only really wanted it for some tax work and light internet browsing, and it has been great so far. It's nice a light (those models from the early 2000s looked fabulous to us since we were all used to desktops but wow were they heavy!) I haven't used the laptop long enough to drain the battery in one go, so I'm not sure exactly how long the charge lasts, but it's at least a few hours. I enjoy the portability of this unit, the keyboard feels nice and the screen size is perfect for casual usage. Clearly this isn't the fancies unit out there, but if all you need is some light internet and Microsoft usage, this is a great unit and reasonably priced. Here's hoping it will hold up for years to come.\",\n",
        "                # \"this is one of the nicest phones nokia has made \",\n",
        "                # \"my favorite features are the speaker phone , the radio and the infrared .\",\n",
        "                # \"the infrared is a blessing if you have a previous nokia and want to transfer your old phone book to this phone , saved me hours of re-entering my numbers .\",\n",
        "                # \"This camera will give you a great picture quality, LCD screen, and price\"\n",
        "                ]\n",
        "reviews_aspects = reviewsAnalyzer(reviews_list, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==========\n",
            "sentence:  I needed a new laptop as I have not bought a decent one since 2000\n",
            "dependencies:  [('nsubj', 'needed', 'I'), ('obj', 'needed', 'laptop'), ('advcl', 'needed', 'bought'), ('det', 'laptop', 'a'), ('amod', 'laptop', 'new'), ('mark', 'bought', 'as'), ('nsubj', 'bought', 'I'), ('aux', 'bought', 'have'), ('advmod', 'bought', 'not'), ('obj', 'bought', 'one'), ('obl', 'bought', '2000'), ('det', 'one', 'a'), ('amod', 'one', 'decent'), ('case', '2000', 'since')]\n",
            "POS:  {'I': 'PRP', 'needed': 'VBD', 'a': 'DT', 'new': 'JJ', 'laptop': 'NN', 'as': 'IN', 'have': 'VBP', 'not': 'RB', 'bought': 'VBN', 'decent': 'JJ', 'one': 'CD', 'since': 'IN', '2000': 'CD'}\n",
            "aspects opinion pairs:  {('one', 'decent'), ('one', 'not bought'), ('laptop', 'needed'), ('laptop', 'new')}\n",
            "==========\n",
            "==========\n",
            "sentence:  One teeny tiny screened netbook and one borrowed laptop that doesnt hold a charge in between really made me feel the lack\n",
            "dependencies:  [('nummod', 'teeny', 'One'), ('compound', 'netbook', 'teeny'), ('amod', 'netbook', 'tiny'), ('amod', 'netbook', 'screened'), ('conj', 'netbook', 'laptop'), ('ccomp', 'netbook', 'hold'), ('cc', 'laptop', 'and'), ('nummod', 'laptop', 'one'), ('amod', 'laptop', 'borrowed'), ('compound:prt', 'hold', 'in'), ('obl', 'hold', 'made'), ('nsubj', 'hold', 'that'), ('aux', 'hold', 'does'), ('advmod', 'hold', 'nt'), ('obj', 'hold', 'charge'), ('det', 'charge', 'a'), ('case', 'made', 'between'), ('advmod', 'made', 'really'), ('ccomp', 'made', 'feel'), ('nsubj', 'feel', 'me'), ('obj', 'feel', 'lack'), ('det', 'lack', 'the')]\n",
            "POS:  {'One': 'CD', 'teeny': 'NN', 'tiny': 'JJ', 'screened': 'VBN', 'netbook': 'NN', 'and': 'CC', 'one': 'CD', 'borrowed': 'VBN', 'laptop': 'NN', 'that': 'WDT', 'does': 'VBZ', 'nt': 'RB', 'hold': 'VB', 'a': 'DT', 'charge': 'NN', 'in': 'IN', 'between': 'IN', 'really': 'RB', 'made': 'VBD', 'me': 'PRP', 'feel': 'VB', 'the': 'DT', 'lack': 'NN'}\n",
            "aspects opinion pairs:  {('charge', 'hold'), ('teeny netbook', 'tiny'), ('laptop', 'tiny'), ('lack', 'feel'), ('teeny netbook', 'screened')}\n",
            "==========\n",
            "==========\n",
            "sentence:  There are loads of bad reviews saying there isnt enough memory to do anything with this particular model\n",
            "dependencies:  [('expl', 'are', 'There'), ('nsubj', 'are', 'loads'), ('nmod', 'loads', 'reviews'), ('acl', 'loads', 'saying'), ('case', 'reviews', 'of'), ('amod', 'reviews', 'bad'), ('xcomp', 'saying', 'enough'), ('advmod', 'enough', 'there'), ('advmod', 'enough', 'isnt'), ('dep', 'enough', 'do'), ('obl', 'do', 'model'), ('nsubj', 'do', 'memory'), ('mark', 'do', 'to'), ('obj', 'do', 'anything'), ('det', 'model', 'this'), ('amod', 'model', 'particular'), ('case', 'model', 'with')]\n",
            "POS:  {'There': 'EX', 'are': 'VBP', 'loads': 'NNS', 'of': 'IN', 'bad': 'JJ', 'reviews': 'NNS', 'saying': 'VBG', 'there': 'RB', 'isnt': 'JJ', 'enough': 'JJ', 'memory': 'NN', 'to': 'TO', 'do': 'VB', 'anything': 'NN', 'with': 'IN', 'this': 'DT', 'particular': 'JJ', 'model': 'NN'}\n",
            "aspects opinion pairs:  {('loads', 'reviews'), ('reviews', 'bad'), ('model', 'particular')}\n",
            "==========\n",
            "==========\n",
            "sentence:  I only really wanted it for some tax work and light internet browsing and it has been great so far\n",
            "dependencies:  [('nsubj', 'wanted', 'I'), ('advmod', 'wanted', 'only'), ('conj', 'wanted', 'great'), ('advmod', 'wanted', 'really'), ('obj', 'wanted', 'it'), ('obl', 'wanted', 'work'), ('case', 'work', 'for'), ('det', 'work', 'some'), ('compound', 'work', 'tax'), ('conj', 'work', 'internet'), ('dep', 'work', 'browsing'), ('cc', 'internet', 'and'), ('compound', 'internet', 'light'), ('aux', 'great', 'has'), ('cop', 'great', 'been'), ('advmod', 'great', 'far'), ('cc', 'great', 'and'), ('nsubj', 'great', 'it'), ('advmod', 'far', 'so')]\n",
            "POS:  {'I': 'PRP', 'only': 'RB', 'really': 'RB', 'wanted': 'VBD', 'it': 'PRP', 'for': 'IN', 'some': 'DT', 'tax': 'NN', 'work': 'NN', 'and': 'CC', 'light': 'NN', 'internet': 'NN', 'browsing': 'NN', 'has': 'VBZ', 'been': 'VBN', 'great': 'JJ', 'so': 'RB', 'far': 'RB'}\n",
            "aspects opinion pairs:  {('it', 'wanted')}\n",
            "==========\n",
            "==========\n",
            "sentence:  Its nice a light those models from the early 2000s looked fabulous to us since we were all used to desktops but wow were they heavy I havent used the laptop long enough to drain the battery in one go so Im not sure exactly how long the charge lasts but its at least a few hours\n",
            "dependencies:  [('nmod:poss', 'models', 'Its'), ('amod', 'models', 'nice'), ('det', 'models', 'a'), ('compound', 'models', 'light'), ('det', 'models', 'those'), ('nmod', 'models', '2000s'), ('case', '2000s', 'from'), ('det', '2000s', 'the'), ('amod', '2000s', 'early'), ('advcl', 'looked', 'used'), ('nsubj', 'looked', 'models'), ('conj', 'looked', 'heavy'), ('xcomp', 'looked', 'fabulous'), ('obl', 'looked', 'us'), ('case', 'us', 'to'), ('nsubj:pass', 'used', 'we'), ('aux:pass', 'used', 'were'), ('advmod', 'used', 'all'), ('obl', 'used', 'desktops'), ('mark', 'used', 'since'), ('case', 'desktops', 'to'), ('cc', 'heavy', 'but'), ('discourse', 'heavy', 'wow'), ('cop', 'heavy', 'were'), ('nsubj', 'heavy', 'they'), ('parataxis', 'heavy', 'havent'), ('nsubj', 'havent', 'I'), ('dep', 'havent', 'used'), ('dep', 'used', 'drain'), ('obj', 'used', 'laptop'), ('det', 'laptop', 'the'), ('advmod', 'enough', 'long'), ('advmod', 'drain', 'enough'), ('mark', 'drain', 'to'), ('obj', 'drain', 'battery'), ('parataxis', 'drain', 'sure'), ('det', 'battery', 'the'), ('case', 'one', 'in'), ('dep', 'sure', 'lasts'), ('obl', 'sure', 'one'), ('cop', 'sure', 'go'), ('advmod', 'sure', 'so'), ('nsubj', 'sure', 'Im'), ('advmod', 'sure', 'not'), ('advmod', 'long', 'exactly'), ('advmod', 'long', 'how'), ('det', 'charge', 'the'), ('nsubj', 'lasts', 'charge'), ('conj', 'lasts', 'hours'), ('advmod', 'lasts', 'long'), ('case', 'least', 'at'), ('obl:npmod', 'few', 'least'), ('advmod', 'few', 'a'), ('cc', 'hours', 'but'), ('nmod:poss', 'hours', 'its'), ('nummod', 'hours', 'few')]\n",
            "POS:  {'Its': 'PRP$', 'nice': 'JJ', 'a': 'DT', 'light': 'NN', 'those': 'DT', 'models': 'NNS', 'from': 'IN', 'the': 'DT', 'early': 'JJ', '2000s': 'NNS', 'looked': 'VBD', 'fabulous': 'JJ', 'to': 'TO', 'us': 'PRP', 'since': 'IN', 'we': 'PRP', 'were': 'VBD', 'all': 'RB', 'used': 'VBN', 'desktops': 'NNS', 'but': 'CC', 'wow': 'UH', 'they': 'PRP', 'heavy': 'JJ', 'I': 'PRP', 'havent': 'VBP', 'laptop': 'NN', 'long': 'RB', 'enough': 'RB', 'drain': 'VB', 'battery': 'NN', 'in': 'IN', 'one': 'CD', 'go': 'VB', 'so': 'RB', 'Im': 'NNP', 'not': 'RB', 'sure': 'JJ', 'exactly': 'RB', 'how': 'WRB', 'charge': 'NN', 'lasts': 'VBZ', 'its': 'PRP$', 'at': 'IN', 'least': 'RBS', 'few': 'JJ', 'hours': 'NNS'}\n",
            "aspects opinion pairs:  {('light models', '2000s'), ('one', 'not sure'), ('hours', 'its'), ('light models', 'fabulous'), ('light models', 'Its'), ('light models', 'nice'), ('laptop', 'used'), ('Im', 'not sure'), ('charge', 'long'), ('2000s', 'early')}\n",
            "==========\n",
            "==========\n",
            "sentence:  I enjoy the portability of this unit the keyboard feels nice and the screen size is perfect for casual usage\n",
            "dependencies:  [('nsubj', 'enjoy', 'I'), ('obj', 'enjoy', 'portability'), ('det', 'portability', 'the'), ('nmod', 'portability', 'unit'), ('dep', 'portability', 'feels'), ('case', 'unit', 'of'), ('det', 'unit', 'this'), ('det', 'keyboard', 'the'), ('conj', 'feels', 'perfect'), ('nsubj', 'feels', 'keyboard'), ('xcomp', 'feels', 'nice'), ('det', 'size', 'the'), ('compound', 'size', 'screen'), ('cop', 'perfect', 'is'), ('obl', 'perfect', 'usage'), ('cc', 'perfect', 'and'), ('nsubj', 'perfect', 'size'), ('case', 'usage', 'for'), ('amod', 'usage', 'casual')]\n",
            "POS:  {'I': 'PRP', 'enjoy': 'VBP', 'the': 'DT', 'portability': 'NN', 'of': 'IN', 'this': 'DT', 'unit': 'NN', 'keyboard': 'NN', 'feels': 'VBZ', 'nice': 'JJ', 'and': 'CC', 'screen': 'NN', 'size': 'NN', 'is': 'VBZ', 'perfect': 'JJ', 'for': 'IN', 'casual': 'JJ', 'usage': 'NN'}\n",
            "aspects opinion pairs:  {('portability', 'enjoy'), ('screen size', 'perfect'), ('keyboard', 'nice'), ('usage', 'perfect'), ('portability', 'unit'), ('usage', 'casual')}\n",
            "==========\n",
            "==========\n",
            "sentence:  Clearly this isnt the fancies unit out there but if all you need is some light internet and Microsoft usage this is a great unit and reasonably priced\n",
            "dependencies:  [('det', 'isnt', 'this'), ('advmod', 'unit', 'Clearly'), ('conj', 'unit', 'internet'), ('nsubj', 'unit', 'isnt'), ('det', 'unit', 'the'), ('amod', 'unit', 'fancies'), ('advmod', 'unit', 'there'), ('advmod', 'there', 'out'), ('mark', 'need', 'if'), ('dep', 'need', 'all'), ('nsubj', 'need', 'you'), ('amod', 'internet', 'light'), ('conj', 'internet', 'usage'), ('obj', 'internet', 'this'), ('cc', 'internet', 'but'), ('dep', 'internet', 'need'), ('cop', 'internet', 'is'), ('det', 'internet', 'some'), ('cc', 'usage', 'and'), ('compound', 'usage', 'Microsoft'), ('nsubj', 'unit', 'unit'), ('cop', 'unit', 'is'), ('det', 'unit', 'a'), ('amod', 'unit', 'great'), ('conj', 'unit', 'priced'), ('cc', 'priced', 'and'), ('advmod', 'priced', 'reasonably')]\n",
            "POS:  {'Clearly': 'RB', 'this': 'DT', 'isnt': 'NN', 'the': 'DT', 'fancies': 'VBZ', 'unit': 'NN', 'out': 'RB', 'there': 'RB', 'but': 'CC', 'if': 'IN', 'all': 'DT', 'you': 'PRP', 'need': 'VBP', 'is': 'VBZ', 'some': 'DT', 'light': 'JJ', 'internet': 'NN', 'and': 'CC', 'Microsoft': 'NNP', 'usage': 'NN', 'a': 'DT', 'great': 'JJ', 'reasonably': 'RB', 'priced': 'VBN'}\n",
            "aspects opinion pairs:  {('internet', 'great'), ('unit', 'great'), ('unit', 'unit'), ('isnt', 'unit'), ('priced', 'great'), ('internet', 'light'), ('unit', 'fancies'), ('Microsoft usage', 'light')}\n",
            "==========\n",
            "==========\n",
            "sentence:  Heres hoping it will hold up for years to come\n",
            "dependencies:  [('nsubj', 'hoping', 'Heres'), ('ccomp', 'hoping', 'hold'), ('nsubj', 'hold', 'it'), ('aux', 'hold', 'will'), ('compound:prt', 'hold', 'up'), ('advcl', 'hold', 'come'), ('mark', 'come', 'for'), ('nsubj', 'come', 'years'), ('mark', 'come', 'to')]\n",
            "POS:  {'Heres': 'NNP', 'hoping': 'VBG', 'it': 'PRP', 'will': 'MD', 'hold': 'VB', 'up': 'RP', 'for': 'IN', 'years': 'NNS', 'to': 'TO', 'come': 'VB'}\n",
            "aspects opinion pairs:  set()\n",
            "==========\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSK-H6jJVp0t",
        "outputId": "c0642bcb-1516-40f1-8040-36fcb575cd7a"
      },
      "source": [
        "reviews_aspects[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('exception', 'sound'),\n",
              "  ('player', 'had'),\n",
              "  ('wwhhhrrr sound', 'motor'),\n",
              "  ('wwhhhrrr sound', 'occasional'),\n",
              "  ('player', 'years')]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu4Vhd3fA4tL"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAVM_oVMWVuP"
      },
      "source": [
        "# 'Nikon coolpix 4300.json'\n",
        "def evaluate_extraction(dataset_path):\n",
        "  dataset_sentences, label_aspects = read_dataset(dataset_path)\n",
        "  mined_aspects = reviewsAnalyzer(dataset_sentences)\n",
        "  # aspects_precision_val = aspects_precision(label_aspects, mined_aspects)\n",
        "  # sentences_precision_val = sentences_precision(label_aspects, mined_aspects)\n",
        "  asp_val, opinpol_val = aspect_opinion_precision(label_aspects, mined_aspects)\n",
        "\n",
        "  print(\"=====\", dataset_path, \"======\\n\")\n",
        "  # print(\"Sentence Precision: \", sentences_precision_val)\n",
        "  print(\"Aspect Precision: \", asp_val)\n",
        "  print(\"Opinion Precision:\",opinpol_val)\n",
        "  print(\"===========\\n\")\n",
        "\n",
        "  return asp_val, opinpol_val\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-oyvDAD3A3r"
      },
      "source": [
        "# Read Json DataSets\n",
        "import json\n",
        "\n",
        "def read_dataset(dataset_path):\n",
        "  # Opening JSON file\n",
        "  dataset_file = open(dataset_path,)\n",
        "    \n",
        "  # returns JSON object as \n",
        "  # a dictionary\n",
        "  dataset = json.load(dataset_file)\n",
        "    \n",
        "  # Iterating through the json\n",
        "  # list\n",
        "\n",
        "  dataset_sentences = []\n",
        "  label_aspects = []\n",
        "  for review in dataset['data']:\n",
        "      dataset_sentences.append(review['sentence'])\n",
        "      in_aspects = []\n",
        "      for j in range(len(review['aspects'])):\n",
        "        # To remove implicit\n",
        "        if list(review['aspects'][j])[0] in review['sentence']:\n",
        "          in_aspects.append(review['aspects'][j])\n",
        "      label_aspects.append(in_aspects)\n",
        "\n",
        "  # Closing file\n",
        "  dataset_file.close()\n",
        "  return dataset_sentences, label_aspects"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpCEoTyNDG-G"
      },
      "source": [
        "def sentences_precision(label_aspects, mined_aspects):\n",
        "  # Correctly mined counter\n",
        "  correctly_mined = 0\n",
        "  aspects_counter = 0\n",
        "  for i in range(len(label_aspects)):\n",
        "    # print(\"===\")\n",
        "    correctly_mined_sent = True\n",
        "\n",
        "    for j in range(len(label_aspects[i])):\n",
        "      correctly_mined_aspect = False\n",
        "      # print(aspects[i][j])\n",
        "      label_aspect = list(label_aspects[i][j])[0]\n",
        "      for m in range(len(mined_aspects[i])):\n",
        "        for k in range(len(mined_aspects[i][m])):\n",
        "          if (label_aspect in mined_aspects[i][m][k][0]) or (mined_aspects[i][m][k][0] in label_aspect):\n",
        "            correctly_mined_aspect = True\n",
        "      if correctly_mined_aspect == False:\n",
        "        correctly_mined_sent = False\n",
        "        break\n",
        "    \n",
        "    if correctly_mined_sent == True:\n",
        "      aspects_counter += len(label_aspects[i])\n",
        "      correctly_mined += 1\n",
        "    # else:\n",
        "    #   print(\"review #\", i, \"\\n\")\n",
        "    #   print(\"mined aspects\", mined_aspects[i], \"\\n\")\n",
        "    #   print(\"label aspects\", label_aspects[i], \"\\n\")\n",
        "\n",
        "  # print(correctly_mined)\n",
        "  # print(len(label_aspects))\n",
        "  # print(\"aspects_counter: \", aspects_counter)\n",
        "  return correctly_mined/len(label_aspects) * 100\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV5TrQVoOvfz"
      },
      "source": [
        "def aspects_precision(label_aspects, mined_aspects):\n",
        "  # Correctly mined\n",
        "  correctly_mined = 0\n",
        "  # All Mined \n",
        "\n",
        "  # All Correct\n",
        "  all_correct = 0\n",
        "  for i in range(len(label_aspects)):\n",
        "    # print(\"===\")\n",
        "    for j in range(len(label_aspects[i])):\n",
        "      # print(aspects[i][j])\n",
        "      label_aspect = list(label_aspects[i][j])[0]\n",
        "      all_correct += 1\n",
        "      for m in range(len(mined_aspects[i])):\n",
        "        for k in range(len(mined_aspects[i][m])):\n",
        "          if (label_aspect in mined_aspects[i][m][k][0]) or (mined_aspects[i][m][k][0] in label_aspect):\n",
        "            correctly_mined += 1\n",
        "            # to be checked again\n",
        "          elif (label_aspect in mined_aspects[i][m][k][1]) or (mined_aspects[i][m][k][1] in label_aspect):\n",
        "            correctly_mined += 1\n",
        "    \n",
        "  print(\"correctly_mined: \", correctly_mined)\n",
        "  print(\"all_correct: \", all_correct)\n",
        "  return correctly_mined/all_correct * 100\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap6cipcQuSwT"
      },
      "source": [
        "from textblob import TextBlob\n",
        "def aspect_opinion_precision(label_aspects, mined_aspects):\n",
        "  pos_seed_list = open(\"../seed_list_p.txt\").read().split(\"\\n\")\n",
        "  neg_seed_list = open(\"../seed_list_n.txt\").read().split(\"\\n\")\n",
        "  # Correctly mined\n",
        "  correctly_mined_aspects = 0\n",
        "  correctly_mined_polarities = 0\n",
        "\n",
        "  # All Mined \n",
        "\n",
        "  # All Correct\n",
        "  valid_opinions_count = 0\n",
        "  all_correct_aspects = 0\n",
        "  for i in range(len(label_aspects)):\n",
        "    # print(\"===\")\n",
        "    for j in range(len(label_aspects[i])):\n",
        "      # print(aspects[i][j])\n",
        "      label_aspect = list(label_aspects[i][j])[0]\n",
        "      label_opinion = label_aspects[i][j][label_aspect]\n",
        "      all_correct_aspects += 1\n",
        "      unique_aspects = {}\n",
        "      \n",
        "      for m in range(len(mined_aspects[i])):\n",
        "        for k in range(len(mined_aspects[i][m])):\n",
        "          if (label_aspect in mined_aspects[i][m][k][0]) or (mined_aspects[i][m][k][0] in label_aspect):\n",
        "            # correctly_mined_aspects += 1\n",
        "            polarity = TextBlob(mined_aspects[i][m][k][1]).sentiment.polarity\n",
        "\n",
        "            if polarity == 0 and mined_aspects[i][m][k][1] in pos_seed_list:\n",
        "              polarity = 1\n",
        "            elif polarity == 0 and mined_aspects[i][m][k][1] in neg_seed_list:\n",
        "              polarity = -1\n",
        "\n",
        "            if mined_aspects[i][m][k][0] in unique_aspects:\n",
        "              unique_aspects[mined_aspects[i][m][k][0]] = unique_aspects[mined_aspects[i][m][k][0]] + [polarity]\n",
        "            else:\n",
        "              unique_aspects[mined_aspects[i][m][k][0]] = [polarity]\n",
        "            # to be checked again\n",
        "          elif (label_aspect in mined_aspects[i][m][k][1]) or (mined_aspects[i][m][k][1] in label_aspect):\n",
        "            # correctly_mined_aspects += 1\n",
        "            polarity = TextBlob(mined_aspects[i][m][k][0]).sentiment.polarity\n",
        "\n",
        "            if polarity == 0 and mined_aspects[i][m][k][0] in pos_seed_list:\n",
        "              polarity = 1\n",
        "            elif polarity == 0 and mined_aspects[i][m][k][0] in neg_seed_list:\n",
        "              polarity = -1\n",
        "\n",
        "            if mined_aspects[i][m][k][1] in unique_aspects:\n",
        "              unique_aspects[mined_aspects[i][m][k][1]] = unique_aspects[mined_aspects[i][m][k][1]] + [polarity]\n",
        "            else:\n",
        "              unique_aspects[mined_aspects[i][m][k][1]] = [polarity]\n",
        "      \n",
        "      correctly_mined_aspects += len(unique_aspects)\n",
        "      for aspc1 in unique_aspects:\n",
        "        opinion_polarities = unique_aspects[aspc1]\n",
        "        posC = 0\n",
        "        negC = 0\n",
        "        for polar in opinion_polarities:\n",
        "          if polar > 0:\n",
        "            posC += 1\n",
        "          elif polar < 0:\n",
        "            negC += 1\n",
        "        if label_opinion == \"+\" and (posC > negC):\n",
        "          correctly_mined_polarities += 1\n",
        "        elif label_opinion == \"-\" and (posC < negC):\n",
        "          correctly_mined_polarities += 1\n",
        "      \n",
        "        if posC > 0 or negC > 0:\n",
        "          valid_opinions_count += 1\n",
        "  # print(\"=correctly_mined_aspects: \", correctly_mined_aspects)\n",
        "  # print(\"=correctly_mined_polarities: \", correctly_mined_polarities)\n",
        "  # print(\"=all_correct_aspects: \", all_correct_aspects)\n",
        "  return correctly_mined_aspects/all_correct_aspects * 100, correctly_mined_polarities/valid_opinions_count * 100"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXmk7b2lBHe6",
        "outputId": "3e55471c-c8bb-45f5-ea16-ff0482eb2eb3"
      },
      "source": [
        "%cd drive/MyDrive/GP/pair-extraction/datasets/CustomerReviewData_2004_2012\\ json"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/GP/pair-extraction/datasets/CustomerReviewData_2004_2012 json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yjxWbbBn9WK",
        "outputId": "b861d3d5-bcb3-4f55-f428-905309b9e484"
      },
      "source": [
        "evaluate_extraction(\"Nikon coolpix 4300.json\")\n",
        "evaluate_extraction(\"Nokia 6610.json\")\n",
        "evaluate_extraction(\"Creative Labs Nomad Jukebox Zen Xtra 40GB.json\")\n",
        "evaluate_extraction(\"Canon G3.json\")\n",
        "evaluate_extraction(\"Apex AD2600 Progressive-scan DVD player.json\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== Nikon coolpix 4300.json ======\n",
            "\n",
            "Aspect Precision:  78.78787878787878\n",
            "Opinion Precision: 88.76404494382022\n",
            "===========\n",
            "\n",
            "===== Nokia 6610.json ======\n",
            "\n",
            "Aspect Precision:  83.79310344827586\n",
            "Opinion Precision: 86.1878453038674\n",
            "===========\n",
            "\n",
            "===== Creative Labs Nomad Jukebox Zen Xtra 40GB.json ======\n",
            "\n",
            "Aspect Precision:  73.77521613832853\n",
            "Opinion Precision: 76.68711656441718\n",
            "===========\n",
            "\n",
            "===== Canon G3.json ======\n",
            "\n",
            "Aspect Precision:  81.14754098360656\n",
            "Opinion Precision: 85.83333333333333\n",
            "===========\n",
            "\n",
            "===== Apex AD2600 Progressive-scan DVD player.json ======\n",
            "\n",
            "Aspect Precision:  67.98780487804879\n",
            "Opinion Precision: 75.0\n",
            "===========\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(67.98780487804879, 75.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    }
  ]
}