{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GP-parser",
      "provenance": [],
      "collapsed_sections": [
        "51J1ZqenajeH",
        "k1Az2ECuAfG8",
        "kP_qn4hAZ6Ys",
        "2zFvaA8_A32_",
        "0X9FlEjfaP04",
        "uRXWoo9VhNr6",
        "xJsuO6D8D05q",
        "5ySGY6y-exgS",
        "2wYsYaug7O7L",
        "PH9oosw4Lvx5",
        "VK-owXSwXd_2",
        "515tq6DzXxwy"
      ],
      "authorship_tag": "ABX9TyMVnUyiFSu72kvxxgNVPJyi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafanabil198/Reviewlize-Graduation-Project/blob/aspect-opinion-pair-extraction/GP_parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51J1ZqenajeH"
      },
      "source": [
        "## Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUF_TgLkaoTJ",
        "outputId": "5e21b4e1-d3bc-4f9a-8208-043a50e53348"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1jR582pjUDA"
      },
      "source": [
        "corenlp_dir = 'drive/My Drive/GP/pair-extraction/corenlp'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpKwWeVkASGt"
      },
      "source": [
        "## Installation & Environment Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Az2ECuAfG8"
      },
      "source": [
        "### Installing Stanza"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiFwYAgW4Mss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35dfafc-2d13-4072-e591-878b96e1d77e"
      },
      "source": [
        "# Install stanza\n",
        "!pip install stanza\n",
        "\n",
        "# Import stanza\n",
        "import stanza"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stanza\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/8b/3a9e7a8d8cb14ad6afffc3983b7a7322a3a24d94ebc978a70746fcffc085/stanza-1.1.1-py3-none-any.whl (227kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 15.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20kB 21.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30kB 11.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 51kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 61kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 81kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 102kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 112kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 122kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 133kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 143kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 153kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 163kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 174kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 184kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 194kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 204kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 215kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 225kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.7.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (51.3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.12.5)\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP_qn4hAZ6Ys"
      },
      "source": [
        "### Installing Spacy and Pysbd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w08A6CIPZ59f",
        "outputId": "e7ac9a59-2c9c-4452-d531-8bc5ed2bb4a7"
      },
      "source": [
        "# Install pysbd\n",
        "!pip install pysbd\n",
        "\n",
        "import spacy\n",
        "from pysbd.utils import PySBDFactory\n",
        "nlp = spacy.blank('en')\n",
        "nlp.add_pipe(PySBDFactory(nlp))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pysbd\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/db/95bd39a94eae9a5149bfde3d27760fb3595a35e11a9a01f6e97288132475/pysbd-0.3.3-py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 20kB 21.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 30kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 40kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 51kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 61kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pysbd\n",
            "Successfully installed pysbd-0.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zFvaA8_A32_"
      },
      "source": [
        "### Setting up Stanford CoreNLP on server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgK6-LPV-OdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c906592-f2f9-4694-80e7-b60179bcdccd"
      },
      "source": [
        "# Download the Stanford CoreNLP package with Stanza's installation command\n",
        "# This'll take several minutes, depending on the network speed\n",
        "corenlp_dir = './corenlp'\n",
        "stanza.install_corenlp(dir=corenlp_dir)\n",
        "\n",
        "# Set the CORENLP_HOME environment variable to point to the installation location\n",
        "import os\n",
        "os.environ[\"CORENLP_HOME\"] = corenlp_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-25 00:21:13 INFO: Installing CoreNLP package into ./corenlp...\n",
            "Downloading http://nlp.stanford.edu/software/stanford-corenlp-latest.zip: 100%|██████████| 505M/505M [08:50<00:00, 952kB/s] \n",
            "2021-01-25 00:30:06 WARNING: For customized installation location, please set the `CORENLP_HOME` environment variable to the location of the installation. In Unix, this is done with `export CORENLP_HOME=./corenlp`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X9FlEjfaP04"
      },
      "source": [
        "### Dowinloading  Stanford CoreNLP On Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKtBXh4MaSrS",
        "outputId": "11d32849-f2d6-447f-a618-78b8fd0522cc"
      },
      "source": [
        "# Download the Stanford CoreNLP package with Stanza's installation command\n",
        "# This'll take several minutes, depending on the network speed\n",
        "corenlp_dir = 'drive/My Drive/GP/pair-extraction/corenlp'\n",
        "stanza.install_corenlp(dir=corenlp_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-25 02:46:12 INFO: Installing CoreNLP package into drive/My Drive/GP/pair-extraction/corenlp...\n",
            "Downloading http://nlp.stanford.edu/software/stanford-corenlp-latest.zip: 100%|██████████| 505M/505M [21:31<00:00, 391kB/s] \n",
            "2021-01-25 03:07:49 WARNING: For customized installation location, please set the `CORENLP_HOME` environment variable to the location of the installation. In Unix, this is done with `export CORENLP_HOME=drive/My Drive/GP/pair-extraction/corenlp`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRXWoo9VhNr6"
      },
      "source": [
        "### Set Environment variable for CoreNLP on Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s63dElL0hVb0"
      },
      "source": [
        "# Set the CORENLP_HOME environment variable to point to the installation location\n",
        "import os\n",
        "os.environ[\"CORENLP_HOME\"] = corenlp_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJsuO6D8D05q"
      },
      "source": [
        "## Initialize Stanford Parser CoreNLP Interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZNHxXHkH1K2"
      },
      "source": [
        "### Constructing CoreNLPClient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS4OKnqJ8wui"
      },
      "source": [
        "# Import client module\n",
        "from stanza.server import CoreNLPClient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbOBugvd9JaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5704f835-6bc6-4381-eae6-24237ae35da5"
      },
      "source": [
        "# Construct a CoreNLPClient with some basic annotators, a memory allocation of 4GB, and port number 9001\n",
        "client = CoreNLPClient(\n",
        "        annotators=['tokenize','pos','lemma','depparse'],\n",
        "        memory='16G',\n",
        "        endpoint='http://localhost:9001',\n",
        "        be_quiet=True)\n",
        "\n",
        "print(client)\n",
        "\n",
        "# Start the background server and wait for some time\n",
        "# Note that in practice this is totally optional, as by default the server will be started when the first annotation is performed\n",
        "client.start()\n",
        "import time; time.sleep(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-26 13:21:38 INFO: Writing properties to tmp file: corenlp_server-d7454ca997e84c57.props\n",
            "2021-01-26 13:21:38 INFO: Starting server with command: java -Xmx16G -cp drive/My Drive/GP/pair-extraction/corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-d7454ca997e84c57.props -annotators tokenize,pos,lemma,depparse -preload -outputFormat serialized\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<stanza.server.client.CoreNLPClient object at 0x7f7baa265fd0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spZrJ-oFdkdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8bb80b3-666d-4212-c2ab-bdcd6af1438a"
      },
      "source": [
        "# Print background processes and look for java\n",
        "# You should be able to see a StanfordCoreNLPServer java process running in the background\n",
        "!ps -o pid,cmd | grep java"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    283 java -Xmx16G -cp ./corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-eea30e2be2264eea.props -annotators tokenize,pos,lemma,depparse -preload -outputFormat serialized\n",
            "    306 /bin/bash -c ps -o pid,cmd | grep java\n",
            "    308 grep java\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ySGY6y-exgS"
      },
      "source": [
        "# -Dependency printing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aJJ5mANUM2PG",
        "outputId": "b58e130c-733f-4d6a-f6d1-fb94256fa80b"
      },
      "source": [
        "document = client.annotate(\"I am happy with my Nokia phone\")\n",
        "sentence = document.sentence[0]\n",
        "sentence.token[2].pos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'JJ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI-LngNZagqQ"
      },
      "source": [
        "def getDependencies(review_sentence):\n",
        "  # doc = nlp(text)\n",
        "  # for t in list(doc.sents):\n",
        "  document = client.annotate(str(review_sentence))\n",
        "  sentence = document.sentence[0]\n",
        "  dependency_parse = sentence.basicDependencies\n",
        "  tokens_parse = sentence.token\n",
        "  token_dict = {}\n",
        "  pos_dict = {}\n",
        "  for i in range(0, len(sentence.token)) :\n",
        "      token_dict[sentence.token[i].tokenEndIndex] = sentence.token[i].word\n",
        "      pos_dict[sentence.token[i].word] = sentence.token[i].pos\n",
        "\n",
        "  #get a list of the dependencies with the words they connect\n",
        "  list_dep=[]\n",
        "  for i in range(0, len(dependency_parse.edge)):\n",
        "\n",
        "      source_node = dependency_parse.edge[i].source\n",
        "      source_name = token_dict[source_node]\n",
        "\n",
        "      target_node = dependency_parse.edge[i].target\n",
        "      target_name = token_dict[target_node]\n",
        "\n",
        "      dep = dependency_parse.edge[i].dep\n",
        "      list_dep.append((dep, source_name, target_name))\n",
        "  # print(list_dep)\n",
        "  return list_dep, pos_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgJMcnaGdsA"
      },
      "source": [
        "examples = {1: \"The battery life is good\",\n",
        "            2: \"It is great having the LCD display\",\n",
        "            3: \"I like this camera\",\n",
        "            4: \"The optical zoom works great\",\n",
        "            5: \"It has movie mode that works good for a digital camera\",\n",
        "            6: \"There is a great camera\",\n",
        "            71: \"Nokia has fine, excellent, cheapest battery\",\n",
        "            72: \"Nokia has fine, excellent and cheapest battery\",\n",
        "            8: \"Nokia has good screen and battery\",\n",
        "            9: \"I am happy with my Nokia phone\",\n",
        "            10: \"Battery life was never a problem for me\",\n",
        "            11: \"This camera will give you a great picture quality, LCD screen, and price\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuXqZwSaOh0-"
      },
      "source": [
        "# 1\n",
        "# Extract pair when it's after capular verb => the battery is good\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def copularVerb(list_dep, list_pos, nsubjIx):\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  for nsubjI in nsubjIx:\n",
        "    if(\"JJ\" in list_pos[list_dep[nsubjI][1]]):\n",
        "      for dep in list_dep:\n",
        "        if dep[0] == \"cop\" and dep[1] == list_dep[nsubjI][1]:\n",
        "          opinion = list_dep[nsubjI][1]\n",
        "          aspect = list_dep[nsubjI][2]\n",
        "    if aspect != \"\" and opinion != \"\":\n",
        "      break\n",
        "  return aspect, opinion\n",
        "\n",
        "# Call after any function to return compund aspects or same aspect => battery life\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getCompund(list_dep, aspect):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"compound\" and dep[1] == aspect :\n",
        "      aspect = dep[2] + \" \" + aspect\n",
        "      break;\n",
        "  return aspect\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6f1JCAoXiII"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[1])\n",
        "aspect, opinion = copularVerb(x, y, nsubjI)\n",
        "aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \",opinions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZAmM2gTX9py"
      },
      "source": [
        "# 3\n",
        "# Extract pair when the opinions is the verb like love and like\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "# sentiment_verbs => list of verbs that may be opinion\n",
        "sentiment_verbs = [\"like\", \"love\", \"adore\", \"enjoyed\", \"liked\", \"loved\", \"enjoy\"]\n",
        "def opinionVerb(list_dep, dep):\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  if(sentiment_verbs.count(dep[1])):\n",
        "    opinion = dep[1]\n",
        "    for dep in list_dep:\n",
        "      if (dep[0] == \"obj\" and dep[1] == opinion):\n",
        "        aspect = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8HEa9d6cjl0",
        "outputId": "f3b0f1db-09eb-4e0f-e9b3-9189345bc450"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[3])\n",
        "aspect, opinion = opinionVerb(x, y, nsubjI)\n",
        "aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('nsubj', 'like', 'I'), ('obj', 'like', 'camera'), ('det', 'camera', 'this')]\n",
            "['camera']  -  ['like']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PykGw5pc1Lk"
      },
      "source": [
        "# 5\n",
        "# Extract pair when there is a relative clause relation between the aspect and the opinion => movie mode that works good\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def relativeClause(list_dep, dependency):\n",
        "  aspect = dependency[1]\n",
        "  relcl_opinion = dependency[2]\n",
        "  opinion = \"\"\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"advmod\" and relcl_opinion == dep[1]:\n",
        "      opinion = dep[2]\n",
        "      return aspect, opinion\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGpNXe3KrXGm",
        "outputId": "795754a0-26c9-4a53-f2a1-b3c7a9ccadaf"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[5])\n",
        "aspect, opinion = relativeClause(x, y, nsubjI)\n",
        "aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('nsubj', 'has', 'It'), ('obj', 'has', 'mode'), ('compound', 'mode', 'movie'), ('acl:relcl', 'mode', 'works'), ('nsubj', 'works', 'that'), ('advmod', 'works', 'good'), ('obl', 'works', 'camera'), ('case', 'camera', 'for'), ('det', 'camera', 'a'), ('amod', 'camera', 'digital')]\n",
            "['movie mode']  -  ['good']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAW_vwILrW9U"
      },
      "source": [
        "# 7-1\n",
        "# Extract multi opinions if without \"and\" word. only with \",\"\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def multiOpinion(list_dep, dependency, visited_dep):\n",
        "  aspect = dependency[1]\n",
        "  opinions = []\n",
        "  for dep in list_dep:\n",
        "    if(dep[0] == \"amod\" and dependency[1] == dep[1]):\n",
        "      opinions.append(dep[2])\n",
        "      visited_dep[list_dep.index(dep)] = True\n",
        "  opinions = getAndOpinions(list_dep, opinions)\n",
        "  return aspect, opinions\n",
        "\n",
        "# 7-2\n",
        "# Call after any function to get list of opinions if multi exist with \"and\" word\n",
        "# list_dep => dependency_parsed\n",
        "# opnions => list of opinions \"List\"\n",
        "def getAndOpinions(list_dep, opinions):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (opinions.count(dep[1]) != 0):\n",
        "      opinions.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (opinions.count(dep[2]) != 0):\n",
        "      opinions.append(dep[1])\n",
        "  return opinions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcY8WSuzyd1-",
        "outputId": "60c7e2c2-56bb-495b-f871-a5ff24d89dd5"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[72])\n",
        "# aspect, opinions = multiOpinion(x, y, nsubjI)\n",
        "# opinions = getAndOpinions(x, [opinion])\n",
        "# aspects = getAndAspects(x, aspects)\n",
        "# print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('nsubj', 'has', 'Nokia'), ('advmod', 'has', 'fine'), ('punct', 'has', ','), ('obj', 'has', 'battery'), ('conj', 'excellent', 'cheapest'), ('cc', 'cheapest', 'and'), ('amod', 'battery', 'excellent')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRvjc7eB1NjK"
      },
      "source": [
        "# 9\n",
        "# Extract pair when theres a preposition => i am happy \"with\" my phone\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def prepositions(list_dep, list_pos, nsubjIs):\n",
        "  opinion_pos = [\"JJ\", \"JJS\", \"RB\"]\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  for nsubjI in nsubjIs:\n",
        "    if (opinion_pos.count(list_pos[list_dep[nsubjI][1]]) != 0):\n",
        "      for dep in list_dep:\n",
        "          if dep[0] == \"obl\" and dep[1] == list_dep[nsubjI][1]:\n",
        "            aspect = dep[2]\n",
        "            opinion = dep[1]\n",
        "    if aspect != \"\" and opinion != \"\" :\n",
        "      break\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "nold0-yy5dYH",
        "outputId": "6b858a50-6968-4164-c62b-4ee5ce46c160"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[9])\n",
        "# x, y, nsubjI = getDependencies(\"I had fun with my nokia phone\")\n",
        "aspect, opinion = prepositions(x, y, nsubjI)\n",
        "# aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('nsubj', 'happy', 'I'), ('cop', 'happy', 'am'), ('obl', 'happy', 'phone'), ('case', 'phone', 'with'), ('nmod:poss', 'phone', 'my'), ('compound', 'phone', 'Nokia')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'JJ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED91Wkdl84QV"
      },
      "source": [
        "# 11\n",
        "# Call after any function to get list of aspects if multi exist\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getAndAspects(list_dep, aspect):\n",
        "  aspects = [aspect]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (dep[1] == aspect):\n",
        "      aspects.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (dep[2] == aspect):\n",
        "      aspects.append(dep[1])\n",
        "  for i in range(len(aspects)):\n",
        "    aspects[i] = getCompund(list_dep, aspects[i])\n",
        "  return aspects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_ujdlFNOTUK",
        "outputId": "c4afa941-b33d-403c-dd56-5b0694d23597"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[11])\n",
        "# x, y, nsubjI = getDependencies(\"I had fun with my nokia phone\")\n",
        "aspect, opinions = multiOpinion(x, y, nsubjI)\n",
        "# aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, opinions)\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('det', 'camera', 'This'), ('nsubj', 'give', 'camera'), ('aux', 'give', 'will'), ('iobj', 'give', 'you'), ('obj', 'give', 'quality'), ('det', 'quality', 'a'), ('amod', 'quality', 'great'), ('compound', 'quality', 'picture'), ('punct', 'quality', ','), ('conj', 'quality', 'screen'), ('punct', 'quality', ','), ('conj', 'quality', 'price'), ('compound', 'screen', 'LCD'), ('cc', 'price', 'and')]\n",
            "['picture quality', 'LCD screen', 'price']  -  ['great']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmupLdI7TMFd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpjcqdH5Xk40"
      },
      "source": [
        "# when the secomd argument in nsubj dependency is not noun and the first is adj.\n",
        "# the feature of the sentence will be the object of it.\n",
        "# use dependencies (nsubj , xcomp , obj) to get the feature.\n",
        "# Ex : it is great having the LCD Display.\n",
        "def apply_nsubj_second(list_dep, dependancy):\n",
        "  f_arg = ''\n",
        "  s_arg = dependancy[1]\n",
        "  verb = ''\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'dep' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'obj' and dep[1] == verb :\n",
        "      f_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ub7aVsdcuJ7"
      },
      "source": [
        "# when the second argument is noun and the opnion part is verb.\n",
        "# the opinion will be the complement of the verb.\n",
        "# Ex : the flash works great.\n",
        "def apply_nsubj_forth (list_dep, dependency) :\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = ''\n",
        "  verb = dependency[1]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'advmod' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ7IDbuvi3SS"
      },
      "source": [
        "# when the feature and opinion pair candidate could in same dependency.\n",
        "# amod dependency the first arg is considered to be the feature.\n",
        "# the second arg is considered to be the opinion words.\n",
        "# Ex : this is a great screen.\n",
        "def apply_amod_sixth (list_dep, dependency) :\n",
        "  f_arg = dependency[1]\n",
        "  s_arg = dependency[2]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyNSP89wsYC-"
      },
      "source": [
        "# when the same opinion word is used to describe more than one feature.\n",
        "# apply conj dependency on the related features. \n",
        "# Ex : Nokia has a good screen and battery.\n",
        "def apply_amod_eight (list_dep, feature) :\n",
        "  feats = []\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'conj' and dep[1] == feature:\n",
        "      feats.append(dep[2])\n",
        "  #call the function check compound of each feature\n",
        "  return feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NdRa9RQ4cBS"
      },
      "source": [
        "# when nsubj dependency is between two nouns.\n",
        "# the first argument can be used as a opinion word.\n",
        "# Ex : the battery was never a problem.\n",
        "def apply_nsubj_ten (list_dep, dependency):\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = dependency[1]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DXQbM5r5qto"
      },
      "source": [
        "# check negation of the opinion words as it can reverse the sentiment.\n",
        "def check_neg(list_dep, adj):\n",
        "    list_neg = ['no' , 'never' , 'not' , 'n\\'t' , 'none' , 'neither'] \n",
        "    #can also check the negative seed list for that.\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == 'advmod' and dep[1] == adj and ( dep[2] in list_neg) :\n",
        "        adj = dep[2] + ' ' + adj\n",
        "        return adj\n",
        "    return adj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbT910j_1R4G"
      },
      "source": [
        "def nsubjAdj(list_dep, list_pos, dependency):\n",
        "  aspect = dependency[2]\n",
        "  opinion = dependency[1]\n",
        "  if list_pos[dependency[1]] == \"JJR\":\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == \"advcl\" and dep[1] == dependency[1]:\n",
        "        opinion = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wYsYaug7O7L"
      },
      "source": [
        "# -All Together\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzzD0hOc7Rz2"
      },
      "source": [
        "def aspectOpinionPairExtractor(list_dep, list_pos):\n",
        "  aspect_opinion_pairs = set()\n",
        "  visited_dep = [False]*len(list_dep)\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'nsubj':\n",
        "      # print(\"nsubj\")\n",
        "      if \"JJ\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #1\n",
        "        aspect, opinion = nsubjAdj(list_dep, list_pos, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"JJ\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #2\n",
        "        aspect, opinion = apply_nsubj_second(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #3\n",
        "        aspect, opinion = opinionVerb(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #4\n",
        "        aspect, opinion = apply_nsubj_forth(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"NN\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #10\n",
        "        aspect, opinion = apply_nsubj_ten(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'amod' and visited_dep[list_dep.index(dep)] == False:\n",
        "      # print(\"amod\")\n",
        "      if \"JJ\" in list_pos[dep[2]]:\n",
        "        aspect, opinion = apply_amod_sixth(list_dep, dep) #6\n",
        "        aspects = apply_amod_eight(list_dep, aspect) #8\n",
        "        aspects.append(aspect)\n",
        "        for a in aspects:\n",
        "          addPair(a, opinion, list_dep, aspect_opinion_pairs)\n",
        "        aspect, opinions = multiOpinion(list_dep, dep, visited_dep) #7\n",
        "        for o in opinions:\n",
        "          addPair(aspect, o, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'obl' and \"JJ\" in list_pos[dep[1]]: #9\n",
        "      # print(\"obl\")\n",
        "      aspect, opinion = prepositions(dep)\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'acl:relcl': #5\n",
        "      # print(\"acl:relcl\")\n",
        "      aspect, opinion = relativeClause(list_dep, dep)\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "  return aspect_opinion_pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A95gaDa7R09g"
      },
      "source": [
        "def addPair(aspect, opinion, list_dep, aspect_opinion_pairs):\n",
        "  if aspect == \"\" or opinion == \"\":\n",
        "    return\n",
        "  aspect = getCompund(list_dep, aspect)\n",
        "  opinion = check_neg(list_dep, opinion)\n",
        "  p = (aspect, opinion)\n",
        "  # print(p)\n",
        "  aspect_opinion_pairs.add(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW6zkW3iUUmx",
        "outputId": "3a76800d-d7fe-4805-d4f3-f5214bc2c1e7"
      },
      "source": [
        "aspect_opinion_pairs = set()\n",
        "list_dep, list_pos = getDependencies(examples[3])\n",
        "# print(list_pos[\"more\"])\n",
        "x = aspectOpinionPairExtractor(list_dep, list_pos)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{('camera', 'like')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH9oosw4Lvx5"
      },
      "source": [
        "# Aspect-Opinion Pair Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgw1VgOPXGuB"
      },
      "source": [
        "## Reviews Anlyzer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e5jSwi_L0TZ"
      },
      "source": [
        "def reviewsAnalyzer(reviews_list):\n",
        "  # list to hold each review's sentences and its aspects \n",
        "  # reviews->[ sentences->[ aspects->[{aspect: opinion}, {aspect, opinion}]], [[]], [[]], ]\n",
        "  reviews_sentences_aspects = []\n",
        "\n",
        "  # For each review:\n",
        "    # 1- split to sentences using spacy\n",
        "    # 2- for each sentence:\n",
        "      # 3- get dependences\n",
        "      # 4- extract aspect_opinion pairs\n",
        "  \n",
        "  for review in reviews_list:\n",
        "    review_boundries = nlp(review)\n",
        "    review_sentences = []\n",
        "    for sentence in list(review_boundries.sents): # 1, 2\n",
        "      sentence_aspects = []\n",
        "      list_dep, list_pos = getDependencies(sentence) # 3\n",
        "      aspect_opinion_pairs = aspectOpinionPairExtractor(list_dep=list_dep, list_pos=list_pos) # 4\n",
        "      for as_op_pair in aspect_opinion_pairs:\n",
        "        sentence_aspects.append(as_op_pair)\n",
        "      review_sentences.append(sentence_aspects)\n",
        "    reviews_sentences_aspects.append(review_sentences)\n",
        "  return reviews_sentences_aspects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-XkBXxeXV8t"
      },
      "source": [
        "def getDependencies(review_sentence):\n",
        "  document = client.annotate(str(review_sentence))\n",
        "  sentence = document.sentence[0]\n",
        "  dependency_parse = sentence.basicDependencies\n",
        "  token_dict = {}\n",
        "  pos_dict = {}\n",
        "  for i in range(0, len(sentence.token)) :\n",
        "      token_dict[sentence.token[i].tokenEndIndex] = sentence.token[i].word\n",
        "      pos_dict[sentence.token[i].word] = sentence.token[i].pos\n",
        "\n",
        "  # get a list of the dependencies with the words they connect\n",
        "  list_dep=[]\n",
        "  for i in range(0, len(dependency_parse.edge)):\n",
        "\n",
        "      source_node = dependency_parse.edge[i].source\n",
        "      source_name = token_dict[source_node]\n",
        "\n",
        "      target_node = dependency_parse.edge[i].target\n",
        "      target_name = token_dict[target_node]\n",
        "\n",
        "      dep = dependency_parse.edge[i].dep\n",
        "      list_dep.append((dep, source_name, target_name))\n",
        "  # print(list_dep)\n",
        "  return list_dep, pos_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtqcWF31Xmr-"
      },
      "source": [
        "def aspectOpinionPairExtractor(list_dep, list_pos):\n",
        "  aspect_opinion_pairs = set()\n",
        "  visited_dep = [False]*len(list_dep)\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'nsubj':\n",
        "      # print(\"nsubj\")\n",
        "      if \"JJ\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #1\n",
        "        aspect, opinion = nsubjAdj(list_dep, list_pos, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"JJ\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #2\n",
        "        aspect, opinion = apply_nsubj_second(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #3\n",
        "        aspect, opinion = opinionVerb(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #4\n",
        "        aspect, opinion = apply_nsubj_forth(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"NN\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #10\n",
        "        aspect, opinion = apply_nsubj_ten(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'amod' and visited_dep[list_dep.index(dep)] == False:\n",
        "      # print(\"amod\")\n",
        "      if \"JJ\" in list_pos[dep[2]]:\n",
        "        aspect, opinion = apply_amod_sixth(list_dep, dep) #6\n",
        "        # Get multi aspects for same opinion\n",
        "        aspects = apply_amod_eight(list_dep, aspect) #8\n",
        "        aspects.append(aspect)\n",
        "        for a in aspects:\n",
        "          addPair(a, opinion, list_dep, aspect_opinion_pairs)\n",
        "\n",
        "        # Get multi opinions for same aspect\n",
        "        aspect, opinions = multiOpinion(list_dep, dep, visited_dep) #7\n",
        "        for o in opinions:\n",
        "          addPair(aspect, o, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'obl' and \"JJ\" in list_pos[dep[1]]: #9\n",
        "      # print(\"obl\")\n",
        "      aspect = dep[2]\n",
        "      opinion = dep[1]\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'acl:relcl': #5\n",
        "      # print(\"acl:relcl\")\n",
        "      aspect, opinion = relativeClause(list_dep, dep)\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "  return aspect_opinion_pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bci22ybxXou0"
      },
      "source": [
        "def addPair(aspect, opinion, list_dep, aspect_opinion_pairs):\n",
        "  if aspect == \"\" or opinion == \"\":\n",
        "    return\n",
        "  aspect = getCompund(list_dep, aspect)\n",
        "  opinion = check_neg(list_dep, opinion)\n",
        "  p = (aspect, opinion)\n",
        "  # print(p)\n",
        "  aspect_opinion_pairs.add(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK-owXSwXd_2"
      },
      "source": [
        "## Dependencies Rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvaoHCvzXzvO"
      },
      "source": [
        "# Call after any function to return compund aspects or same aspect => battery life\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getCompund(list_dep, aspect):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"compound\" and dep[1] == aspect :\n",
        "      aspect = dep[2] + \" \" + aspect\n",
        "      break;\n",
        "  return aspect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FmKJzMqYcrA"
      },
      "source": [
        "# 1\n",
        "# Extract pair when it's after capular verb => the battery is good \n",
        "# and if having comparitave adj then get the advcl => the battery is more satisfying\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# dependency => the nsubj dep that leaded to this case\n",
        "def nsubjAdj(list_dep, list_pos, dependency):\n",
        "  aspect = dependency[2]\n",
        "  opinion = dependency[1]\n",
        "  if list_pos[dependency[1]] == \"JJR\":\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == \"advcl\" and dep[1] == dependency[1]:\n",
        "        opinion = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkb7IAnlYcq1"
      },
      "source": [
        "# 2\n",
        "# when the second argument in nsubj dependency is not noun and the first is adj.\n",
        "# the feature of the sentence will be the object of it.\n",
        "# use dependencies (nsubj , xcomp , obj) to get the feature.\n",
        "# Ex : it is great having the LCD Display.\n",
        "def apply_nsubj_second(list_dep, dependancy):\n",
        "  f_arg = ''\n",
        "  s_arg = dependancy[1]\n",
        "  verb = ''\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'dep' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'obj' and dep[1] == verb :\n",
        "      f_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAMFq3ndYcqq"
      },
      "source": [
        "# 3\n",
        "# Extract pair when the opinions is the verb like love and like\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# dependency => the current dep that leaded to this case\n",
        "# sentiment_verbs => list of verbs that may be opinion\n",
        "sentiment_verbs = [\"like\", \"love\", \"adore\", \"enjoyed\", \"liked\", \"loved\", \"enjoy\"]\n",
        "def opinionVerb(list_dep, dep):\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  if(sentiment_verbs.count(dep[1])):\n",
        "    opinion = dep[1]\n",
        "    for dep in list_dep:\n",
        "      if (dep[0] == \"obj\" and dep[1] == opinion):\n",
        "        aspect = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwr-mnGwYcq3"
      },
      "source": [
        "# 4\n",
        "# when the second argument is noun and the opnion part is verb.\n",
        "# the opinion will be the complement of the verb.\n",
        "# Ex : the flash works great.\n",
        "def apply_nsubj_forth (list_dep, dependency) :\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = ''\n",
        "  verb = dependency[1]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'advmod' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPrl0FmrYcqt"
      },
      "source": [
        "# 5\n",
        "# Extract pair when there is a relative clause relation between the aspect and the opinion => movie mode that works good\n",
        "# list_dep => dependency_parsed\n",
        "# dependency => the current dep that leaded to this case\n",
        "def relativeClause(list_dep, dependency):\n",
        "  aspect = dependency[1]\n",
        "  relcl_opinion = dependency[2]\n",
        "  opinion = \"\"\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"advmod\" and relcl_opinion == dep[1]:\n",
        "      opinion = dep[2]\n",
        "      return aspect, opinion\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FrHlqzoYcq6"
      },
      "source": [
        "# 6\n",
        "# when the feature and opinion pair candidate could in same dependency.\n",
        "# amod dependency the first arg is considered to be the feature.\n",
        "# the second arg is considered to be the opinion words.\n",
        "# Ex : this is a great screen.\n",
        "def apply_amod_sixth (list_dep, dependency) :\n",
        "  f_arg = dependency[1]\n",
        "  s_arg = dependency[2]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX9_fQ6WYcqv"
      },
      "source": [
        "# 7-1\n",
        "# Extract multi opinions if without \"and\" word. only with \",\"\n",
        "# list_dep => dependency_parsed\n",
        "# dependency => the current dep that leaded to this case\n",
        "# visited_dep => to make sure if the amod dependency was considered or not in the main loop\n",
        "def multiOpinion(list_dep, dependency, visited_dep):\n",
        "  aspect = dependency[1]\n",
        "  opinions = []\n",
        "  for dep in list_dep:\n",
        "    if(dep[0] == \"amod\" and dependency[1] == dep[1]):\n",
        "      opinions.append(dep[2])\n",
        "      visited_dep[list_dep.index(dep)] = True\n",
        "  opinions = getAndOpinions(list_dep, opinions)\n",
        "  return aspect, opinions\n",
        "\n",
        "# 7-2\n",
        "# Call after any function to get list of opinions if multi exist with \"and\" word\n",
        "# list_dep => dependency_parsed\n",
        "# opnions => list of opinions \"List\"\n",
        "def getAndOpinions(list_dep, opinions):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (opinions.count(dep[1]) != 0):\n",
        "      opinions.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (opinions.count(dep[2]) != 0):\n",
        "      opinions.append(dep[1])\n",
        "  return opinions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPyhgRTlYcq7"
      },
      "source": [
        "# 8\n",
        "# when the same opinion word is used to describe more than one feature.\n",
        "# apply conj dependency on the related features. \n",
        "# Ex : Nokia has a good screen and battery.\n",
        "def apply_amod_eight (list_dep, feature) :\n",
        "  feats = []\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'conj' and dep[1] == feature:\n",
        "      feats.append(dep[2])\n",
        "  #call the function check compound of each feature\n",
        "  return feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNfw29XHYcqx"
      },
      "source": [
        "# 9\n",
        "# Extract pair when theres a preposition => i am happy \"with\" my phone\n",
        "# dependency => the current dep that leaded to this case\n",
        "def prepositions(dependency):\n",
        "  aspect = dependency[2]\n",
        "  opinion = dependency[1]\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYpiAG8TYcq9"
      },
      "source": [
        "# 10\n",
        "# when nsubj dependency is between two nouns.\n",
        "# the first argument can be used as a opinion word.\n",
        "# Ex : the battery was never a problem.\n",
        "def apply_nsubj_ten (list_dep, dependency):\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = dependency[1]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SarUlp2hYcqz"
      },
      "source": [
        "# 11\n",
        "# Call after any function to get list of aspects if multi exist\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getAndAspects(list_dep, aspect):\n",
        "  aspects = [aspect]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (dep[1] == aspect):\n",
        "      aspects.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (dep[2] == aspect):\n",
        "      aspects.append(dep[1])\n",
        "  for i in range(len(aspects)):\n",
        "    aspects[i] = getCompund(list_dep, aspects[i])\n",
        "  return aspects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9nG8xaQYcq-"
      },
      "source": [
        "# neg\n",
        "# check negation of the opinion words as it can reverse the sentiment.\n",
        "def check_neg(list_dep, adj):\n",
        "    list_neg = ['no' , 'never' , 'not' , 'n\\'t' , 'none' , 'neither'] \n",
        "    #can also check the negative seed list for that.\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == 'advmod' and dep[1] == adj and ( dep[2] in list_neg) :\n",
        "        adj = dep[2] + ' ' + adj\n",
        "        return adj\n",
        "    return adj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "515tq6DzXxwy"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FvF9fn5USZ1"
      },
      "source": [
        "examples = {1: \"The battery life is good\",\n",
        "            2: \"It is great having the LCD display\",\n",
        "            3: \"I like this camera\",\n",
        "            4: \"The optical zoom works great\",\n",
        "            5: \"It has movie mode that works good for a digital camera\",\n",
        "            6: \"There is a great camera\",\n",
        "            71: \"Nokia has fine, excellent, cheapest battery\",\n",
        "            72: \"Nokia has fine, excellent and cheapest battery\",\n",
        "            8: \"Nokia has good screen and battery\",\n",
        "            9: \"I am happy with my Nokia phone\",\n",
        "            10: \"Battery life was never a problem for me\",\n",
        "            11: \"This camera will give you a great picture quality, LCD screen, and price\"}\n",
        "                        \n",
        "reviews_list = [\"The battery life is good. The screen is bad but the brightness is great. i loved the color\",\n",
        "                \"It is great having the LCD display\",\n",
        "                \"I like this camera\",\n",
        "                \"The optical zoom works great\",\n",
        "                \"It has movie mode that works good for a digital camera\",\n",
        "                \"There is a great camera\",\n",
        "                \"Nokia has fine, excellent, cheapest battery\",\n",
        "                \"Nokia has fine, excellent and cheapest battery\",\n",
        "                \"Nokia has good screen and battery\",\n",
        "                \"I am happy with my Nokia phone\",\n",
        "                \"Battery life was never a problem for me\",\n",
        "                \"This camera will give you a great picture quality, LCD screen, and price\"]\n",
        "reviews_aspects = reviewsAnalyzer(reviews_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSK-H6jJVp0t",
        "outputId": "7e89ac53-d5e6-4378-a632-03fc72cd00f5"
      },
      "source": [
        "reviews_aspects"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[('battery life', 'good')],\n",
              "  [('brightness', 'great'), ('screen', 'bad')],\n",
              "  [('color', 'loved')]],\n",
              " [[('LCD display', 'great')]],\n",
              " [[('camera', 'like')]],\n",
              " [[('zoom', 'optical'), ('zoom', 'great')]],\n",
              " [[('movie mode', 'good'), ('camera', 'digital')]],\n",
              " [[('camera', 'great')]],\n",
              " [[('Nokia', 'fine'), ('battery', 'excellent'), ('battery', 'cheapest')]],\n",
              " [[('Nokia', 'fine'), ('battery', 'excellent'), ('battery', 'cheapest')]],\n",
              " [[('battery', 'good'), ('screen', 'good')]],\n",
              " [[('Nokia phone', 'happy')]],\n",
              " [[('Battery life', 'never problem')]],\n",
              " [[('picture quality', 'great'), ('LCD screen', 'great'), ('price', 'great')]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-oyvDAD3A3r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}