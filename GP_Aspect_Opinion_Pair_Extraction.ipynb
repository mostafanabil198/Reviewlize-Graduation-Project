{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GP-Aspect Opinion Pair Extraction",
      "provenance": [],
      "collapsed_sections": [
        "2zFvaA8_A32_",
        "0X9FlEjfaP04",
        "5ySGY6y-exgS",
        "2wYsYaug7O7L",
        "515tq6DzXxwy"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafanabil198/Reviewlize-Graduation-Project/blob/aspect-opinion-pair-extraction/GP_Aspect_Opinion_Pair_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51J1ZqenajeH"
      },
      "source": [
        "## Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUF_TgLkaoTJ",
        "outputId": "448d0783-ec2d-4ee6-ead3-132deb9d1af5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1jR582pjUDA"
      },
      "source": [
        "corenlp_dir = 'drive/My Drive/GP/pair-extraction/corenlp'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpKwWeVkASGt"
      },
      "source": [
        "## Installation & Environment Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Az2ECuAfG8"
      },
      "source": [
        "### Installing Stanza"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiFwYAgW4Mss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cfe9471-52eb-4c88-952d-06f226c99e92"
      },
      "source": [
        "# Install stanza\n",
        "!pip install stanza\n",
        "\n",
        "# Import stanza\n",
        "import stanza"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stanza\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/ae/a70a58ce6b4e2daad538688806ee0f238dbe601954582a74ea57cde6c532/stanza-1.2-py3-none-any.whl (282kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 15.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 12.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30kB 8.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 81kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 92kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 102kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 112kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 122kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 143kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 153kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 163kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 174kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 184kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 194kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 204kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 215kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 225kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 235kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 245kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 256kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 266kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 276kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (56.0.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP_qn4hAZ6Ys"
      },
      "source": [
        "### Installing Spacy and Pysbd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w08A6CIPZ59f",
        "outputId": "bb05f3c5-2d86-4497-aca3-319ff74c33ff"
      },
      "source": [
        "# Install pysbd\n",
        "!pip install pysbd\n",
        "\n",
        "import spacy\n",
        "from pysbd.utils import PySBDFactory\n",
        "nlp = spacy.blank('en')\n",
        "nlp.add_pipe(PySBDFactory(nlp))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pysbd\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/0a/c99fb7d7e176f8b176ef19704a32e6a9c6aafdf19ef75a187f701fc15801/pysbd-0.3.4-py3-none-any.whl (71kB)\n",
            "\r\u001b[K     |████▋                           | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 20kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 30kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.1MB/s \n",
            "\u001b[?25hInstalling collected packages: pysbd\n",
            "Successfully installed pysbd-0.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zFvaA8_A32_"
      },
      "source": [
        "### Downloading & Setting up Stanford CoreNLP on server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgK6-LPV-OdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "396343e8-3993-49d6-b9a1-a99b5c7f56cf"
      },
      "source": [
        "# Download the Stanford CoreNLP package with Stanza's installation command\n",
        "# This'll take several minutes, depending on the network speed\n",
        "corenlp_dir = './corenlp'\n",
        "stanza.install_corenlp(dir=corenlp_dir)\n",
        "\n",
        "# Set the CORENLP_HOME environment variable to point to the installation location\n",
        "import os\n",
        "os.environ[\"CORENLP_HOME\"] = corenlp_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-19 15:04:16 INFO: Installing CoreNLP package into ./corenlp...\n",
            "Downloading http://nlp.stanford.edu/software/stanford-corenlp-latest.zip: 100%|██████████| 505M/505M [01:41<00:00, 4.95MB/s]\n",
            "2021-04-19 15:06:02 WARNING: For customized installation location, please set the `CORENLP_HOME` environment variable to the location of the installation. In Unix, this is done with `export CORENLP_HOME=./corenlp`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X9FlEjfaP04"
      },
      "source": [
        "### Downloading & Setting up Stanford CoreNLP On Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKtBXh4MaSrS",
        "outputId": "69745fa5-e486-4d2a-a02b-c89a66e63518"
      },
      "source": [
        "# Download the Stanford CoreNLP package with Stanza's installation command\n",
        "# This'll take several minutes, depending on the network speed\n",
        "corenlp_dir = 'drive/My Drive/GP/pair-extraction/corenlp'\n",
        "stanza.install_corenlp(dir=corenlp_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-19 15:06:46 INFO: Installing CoreNLP package into drive/My Drive/GP/pair-extraction/corenlp...\n",
            "Downloading http://nlp.stanford.edu/software/stanford-corenlp-latest.zip: 100%|██████████| 505M/505M [01:39<00:00, 5.08MB/s]\n",
            "2021-04-19 15:08:32 WARNING: For customized installation location, please set the `CORENLP_HOME` environment variable to the location of the installation. In Unix, this is done with `export CORENLP_HOME=drive/My Drive/GP/pair-extraction/corenlp`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRXWoo9VhNr6"
      },
      "source": [
        "### Set Environment variable for CoreNLP on Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s63dElL0hVb0"
      },
      "source": [
        "# Set the CORENLP_HOME environment variable to point to the installation location\n",
        "import os\n",
        "os.environ[\"CORENLP_HOME\"] = corenlp_dir"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJsuO6D8D05q"
      },
      "source": [
        "## Initialize Stanford Parser CoreNLP Interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZNHxXHkH1K2"
      },
      "source": [
        "### Constructing CoreNLPClient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS4OKnqJ8wui"
      },
      "source": [
        "# Import client module\n",
        "from stanza.server import CoreNLPClient\n",
        "import string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbOBugvd9JaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59cbc747-7d29-44aa-fa38-3c17108e2b56"
      },
      "source": [
        "# Construct a CoreNLPClient with some basic annotators, a memory allocation of 4GB, and port number 9001\n",
        "client = CoreNLPClient(\n",
        "        annotators=['tokenize','pos','lemma','depparse'],\n",
        "        memory='16G',\n",
        "        endpoint='http://localhost:9002',\n",
        "        be_quiet=True)\n",
        "\n",
        "print(client)\n",
        "\n",
        "# Start the background server and wait for some time\n",
        "# Note that in practice this is totally optional, as by default the server will be started when the first annotation is performed\n",
        "client.start()\n",
        "import time; time.sleep(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-27 03:03:26 INFO: Writing properties to tmp file: corenlp_server-959eaa51772847b3.props\n",
            "2021-04-27 03:03:26 INFO: Starting server with command: java -Xmx16G -cp drive/My Drive/GP/pair-extraction/corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9002 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-959eaa51772847b3.props -annotators tokenize,pos,lemma,depparse -preload -outputFormat serialized\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<stanza.server.client.CoreNLPClient object at 0x7fa45f885b50>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spZrJ-oFdkdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8bac41b-5e9c-4684-ee55-ee9d31925703"
      },
      "source": [
        "# Print background processes and look for java\n",
        "# You should be able to see a StanfordCoreNLPServer java process running in the background\n",
        "!ps -o pid,cmd | grep java"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    582 java -Xmx16G -cp drive/My Drive/GP/pair-extraction/corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9002 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-959eaa51772847b3.props -annotators tokenize,pos,lemma,depparse -preload -outputFormat serialized\n",
            "    601 /bin/bash -c ps -o pid,cmd | grep java\n",
            "    603 grep java\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ySGY6y-exgS"
      },
      "source": [
        "# -Dependency printing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJJ5mANUM2PG",
        "outputId": "f9756df3-c909-4ff8-f06d-deab03ec0066"
      },
      "source": [
        "document = client.annotate(\"I am happy with my Nokia phone\")\n",
        "sentence = document.sentence[0]\n",
        "sentence.token[2].pos"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text: \"I am happy with my Nokia phone\"\n",
              "sentence {\n",
              "  token {\n",
              "    word: \"I\"\n",
              "    pos: \"PRP\"\n",
              "    value: \"I\"\n",
              "    before: \"\"\n",
              "    after: \" \"\n",
              "    originalText: \"I\"\n",
              "    lemma: \"I\"\n",
              "    beginChar: 0\n",
              "    endChar: 1\n",
              "    tokenBeginIndex: 0\n",
              "    tokenEndIndex: 1\n",
              "    hasXmlContext: false\n",
              "    isNewline: false\n",
              "  }\n",
              "  token {\n",
              "    word: \"am\"\n",
              "    pos: \"VBP\"\n",
              "    value: \"am\"\n",
              "    before: \" \"\n",
              "    after: \" \"\n",
              "    originalText: \"am\"\n",
              "    lemma: \"be\"\n",
              "    beginChar: 2\n",
              "    endChar: 4\n",
              "    tokenBeginIndex: 1\n",
              "    tokenEndIndex: 2\n",
              "    hasXmlContext: false\n",
              "    isNewline: false\n",
              "  }\n",
              "  token {\n",
              "    word: \"happy\"\n",
              "    pos: \"JJ\"\n",
              "    value: \"happy\"\n",
              "    before: \" \"\n",
              "    after: \" \"\n",
              "    originalText: \"happy\"\n",
              "    lemma: \"happy\"\n",
              "    beginChar: 5\n",
              "    endChar: 10\n",
              "    tokenBeginIndex: 2\n",
              "    tokenEndIndex: 3\n",
              "    hasXmlContext: false\n",
              "    isNewline: false\n",
              "  }\n",
              "  token {\n",
              "    word: \"with\"\n",
              "    pos: \"IN\"\n",
              "    value: \"with\"\n",
              "    before: \" \"\n",
              "    after: \" \"\n",
              "    originalText: \"with\"\n",
              "    lemma: \"with\"\n",
              "    beginChar: 11\n",
              "    endChar: 15\n",
              "    tokenBeginIndex: 3\n",
              "    tokenEndIndex: 4\n",
              "    hasXmlContext: false\n",
              "    isNewline: false\n",
              "  }\n",
              "  token {\n",
              "    word: \"my\"\n",
              "    pos: \"PRP$\"\n",
              "    value: \"my\"\n",
              "    before: \" \"\n",
              "    after: \" \"\n",
              "    originalText: \"my\"\n",
              "    lemma: \"my\"\n",
              "    beginChar: 16\n",
              "    endChar: 18\n",
              "    tokenBeginIndex: 4\n",
              "    tokenEndIndex: 5\n",
              "    hasXmlContext: false\n",
              "    isNewline: false\n",
              "  }\n",
              "  token {\n",
              "    word: \"Nokia\"\n",
              "    pos: \"NNP\"\n",
              "    value: \"Nokia\"\n",
              "    before: \" \"\n",
              "    after: \" \"\n",
              "    originalText: \"Nokia\"\n",
              "    lemma: \"Nokia\"\n",
              "    beginChar: 19\n",
              "    endChar: 24\n",
              "    tokenBeginIndex: 5\n",
              "    tokenEndIndex: 6\n",
              "    hasXmlContext: false\n",
              "    isNewline: false\n",
              "  }\n",
              "  token {\n",
              "    word: \"phone\"\n",
              "    pos: \"NN\"\n",
              "    value: \"phone\"\n",
              "    before: \" \"\n",
              "    after: \"\"\n",
              "    originalText: \"phone\"\n",
              "    lemma: \"phone\"\n",
              "    beginChar: 25\n",
              "    endChar: 30\n",
              "    tokenBeginIndex: 6\n",
              "    tokenEndIndex: 7\n",
              "    hasXmlContext: false\n",
              "    isNewline: false\n",
              "  }\n",
              "  tokenOffsetBegin: 0\n",
              "  tokenOffsetEnd: 7\n",
              "  sentenceIndex: 0\n",
              "  characterOffsetBegin: 0\n",
              "  characterOffsetEnd: 30\n",
              "  basicDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 3\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 4\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 5\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 6\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 7\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 1\n",
              "      dep: \"nsubj\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 2\n",
              "      dep: \"cop\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 7\n",
              "      dep: \"obl\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 4\n",
              "      dep: \"case\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 5\n",
              "      dep: \"nmod:poss\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 6\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 3\n",
              "  }\n",
              "  collapsedDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 3\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 4\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 5\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 6\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 7\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 1\n",
              "      dep: \"nsubj\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 2\n",
              "      dep: \"cop\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 7\n",
              "      dep: \"obl:with\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 4\n",
              "      dep: \"case\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 5\n",
              "      dep: \"nmod:poss\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 6\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 3\n",
              "  }\n",
              "  collapsedCCProcessedDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 3\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 4\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 5\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 6\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 7\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 1\n",
              "      dep: \"nsubj\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 2\n",
              "      dep: \"cop\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 7\n",
              "      dep: \"obl:with\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 4\n",
              "      dep: \"case\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 5\n",
              "      dep: \"nmod:poss\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 6\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 3\n",
              "  }\n",
              "  enhancedDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 3\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 4\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 5\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 6\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 7\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 1\n",
              "      dep: \"nsubj\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 2\n",
              "      dep: \"cop\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 7\n",
              "      dep: \"obl:with\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 4\n",
              "      dep: \"case\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 5\n",
              "      dep: \"nmod:poss\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 6\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 3\n",
              "  }\n",
              "  enhancedPlusPlusDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 3\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 4\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 5\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 6\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 7\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 1\n",
              "      dep: \"nsubj\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 2\n",
              "      dep: \"cop\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 3\n",
              "      target: 7\n",
              "      dep: \"obl:with\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 4\n",
              "      dep: \"case\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 5\n",
              "      dep: \"nmod:poss\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    edge {\n",
              "      source: 7\n",
              "      target: 6\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 3\n",
              "  }\n",
              "  hasRelationAnnotations: false\n",
              "  hasNumerizedTokensAnnotation: false\n",
              "  hasEntityMentionsAnnotation: false\n",
              "}\n",
              "xmlDoc: false\n",
              "hasEntityMentionsAnnotation: false\n",
              "hasCorefMentionAnnotation: false\n",
              "hasCorefAnnotation: false"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI-LngNZagqQ"
      },
      "source": [
        "def getDependencies(review_sentence):\n",
        "  # doc = nlp(text)\n",
        "  # for t in list(doc.sents):\n",
        "  document = client.annotate(str(review_sentence))\n",
        "  sentence = document.sentence[0]\n",
        "  dependency_parse = sentence.basicDependencies\n",
        "  tokens_parse = sentence.token\n",
        "  token_dict = {}\n",
        "  pos_dict = {}\n",
        "  for i in range(0, len(sentence.token)) :\n",
        "      token_dict[sentence.token[i].tokenEndIndex] = sentence.token[i].word\n",
        "      pos_dict[sentence.token[i].word] = sentence.token[i].pos\n",
        "\n",
        "  #get a list of the dependencies with the words they connect\n",
        "  list_dep=[]\n",
        "  for i in range(0, len(dependency_parse.edge)):\n",
        "\n",
        "      source_node = dependency_parse.edge[i].source\n",
        "      source_name = token_dict[source_node]\n",
        "\n",
        "      target_node = dependency_parse.edge[i].target\n",
        "      target_name = token_dict[target_node]\n",
        "\n",
        "      dep = dependency_parse.edge[i].dep\n",
        "      list_dep.append((dep, source_name, target_name))\n",
        "  # print(list_dep)\n",
        "  return list_dep, pos_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgJMcnaGdsA"
      },
      "source": [
        "examples = {1: \"The battery life is good\",\n",
        "            2: \"It is great having the LCD display\",\n",
        "            3: \"I like this camera\",\n",
        "            4: \"The optical zoom works great\",\n",
        "            5: \"It has movie mode that works good for a digital camera\",\n",
        "            6: \"There is a great camera\",\n",
        "            71: \"Nokia has fine, excellent, cheapest battery\",\n",
        "            72: \"Nokia has fine, excellent and cheapest battery\",\n",
        "            8: \"Nokia has good screen and battery\",\n",
        "            9: \"I am happy with my Nokia phone\",\n",
        "            10: \"Battery life was never a problem for me\",\n",
        "            11: \"This camera will give you a great picture quality, LCD screen, and price\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuXqZwSaOh0-"
      },
      "source": [
        "# 1\n",
        "# Extract pair when it's after capular verb => the battery is good\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def copularVerb(list_dep, list_pos, nsubjIx):\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  for nsubjI in nsubjIx:\n",
        "    if(\"JJ\" in list_pos[list_dep[nsubjI][1]]):\n",
        "      for dep in list_dep:\n",
        "        if dep[0] == \"cop\" and dep[1] == list_dep[nsubjI][1]:\n",
        "          opinion = list_dep[nsubjI][1]\n",
        "          aspect = list_dep[nsubjI][2]\n",
        "    if aspect != \"\" and opinion != \"\":\n",
        "      break\n",
        "  return aspect, opinion\n",
        "\n",
        "# Call after any function to return compund aspects or same aspect => battery life\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getCompund(list_dep, aspect):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"compound\" and dep[1] == aspect :\n",
        "      aspect = dep[2] + \" \" + aspect\n",
        "      break;\n",
        "  return aspect\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6f1JCAoXiII"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[1])\n",
        "aspect, opinion = copularVerb(x, y, nsubjI)\n",
        "aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \",opinions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZAmM2gTX9py"
      },
      "source": [
        "# 3\n",
        "# Extract pair when the opinions is the verb like love and like\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "# sentiment_verbs => list of verbs that may be opinion\n",
        "sentiment_verbs = [\"like\", \"love\", \"adore\", \"enjoyed\", \"liked\", \"loved\", \"enjoy\"]\n",
        "def opinionVerb(list_dep, dep):\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  if(sentiment_verbs.count(dep[1])):\n",
        "    opinion = dep[1]\n",
        "    for dep in list_dep:\n",
        "      if (dep[0] == \"obj\" and dep[1] == opinion):\n",
        "        aspect = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8HEa9d6cjl0"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[3])\n",
        "aspect, opinion = opinionVerb(x, y, nsubjI)\n",
        "aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PykGw5pc1Lk"
      },
      "source": [
        "# 5\n",
        "# Extract pair when there is a relative clause relation between the aspect and the opinion => movie mode that works good\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def relativeClause(list_dep, dependency):\n",
        "  aspect = dependency[1]\n",
        "  relcl_opinion = dependency[2]\n",
        "  opinion = \"\"\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"advmod\" and relcl_opinion == dep[1]:\n",
        "      opinion = dep[2]\n",
        "      return aspect, opinion\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "QGpNXe3KrXGm",
        "outputId": "19b2202f-7f70-4182-9d43-9b6b7a46c50e"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[5])\n",
        "aspect, opinion = relativeClause(x, y, nsubjI)\n",
        "aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-fca3edc08528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsubjI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopinion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelativeClause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsubjI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maspect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetCompund\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopinions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAndOpinions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mopinion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maspects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAndAspects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAW_vwILrW9U"
      },
      "source": [
        "# 7-1\n",
        "# Extract multi opinions if without \"and\" word. only with \",\"\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def multiOpinion(list_dep, dependency, visited_dep):\n",
        "  aspect = dependency[1]\n",
        "  opinions = []\n",
        "  for dep in list_dep:\n",
        "    if(dep[0] == \"amod\" and dependency[1] == dep[1]):\n",
        "      opinions.append(dep[2])\n",
        "      visited_dep[list_dep.index(dep)] = True\n",
        "  opinions = getAndOpinions(list_dep, opinions)\n",
        "  return aspect, opinions\n",
        "\n",
        "# 7-2\n",
        "# Call after any function to get list of opinions if multi exist with \"and\" word\n",
        "# list_dep => dependency_parsed\n",
        "# opnions => list of opinions \"List\"\n",
        "def getAndOpinions(list_dep, opinions):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (opinions.count(dep[1]) != 0):\n",
        "      opinions.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (opinions.count(dep[2]) != 0):\n",
        "      opinions.append(dep[1])\n",
        "  return opinions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcY8WSuzyd1-"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[72])\n",
        "# aspect, opinions = multiOpinion(x, y, nsubjI)\n",
        "# opinions = getAndOpinions(x, [opinion])\n",
        "# aspects = getAndAspects(x, aspects)\n",
        "# print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRvjc7eB1NjK"
      },
      "source": [
        "# 9\n",
        "# Extract pair when theres a preposition => i am happy \"with\" my phone\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def prepositions(list_dep, list_pos, nsubjIs):\n",
        "  opinion_pos = [\"JJ\", \"JJS\", \"RB\"]\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  for nsubjI in nsubjIs:\n",
        "    if (opinion_pos.count(list_pos[list_dep[nsubjI][1]]) != 0):\n",
        "      for dep in list_dep:\n",
        "          if dep[0] == \"obl\" and dep[1] == list_dep[nsubjI][1]:\n",
        "            aspect = dep[2]\n",
        "            opinion = dep[1]\n",
        "    if aspect != \"\" and opinion != \"\" :\n",
        "      break\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nold0-yy5dYH"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[9])\n",
        "# x, y, nsubjI = getDependencies(\"I had fun with my nokia phone\")\n",
        "aspect, opinion = prepositions(x, y, nsubjI)\n",
        "# aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED91Wkdl84QV"
      },
      "source": [
        "# 11\n",
        "# Call after any function to get list of aspects if multi exist\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getAndAspects(list_dep, aspect):\n",
        "  aspects = [aspect]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (dep[1] == aspect):\n",
        "      aspects.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (dep[2] == aspect):\n",
        "      aspects.append(dep[1])\n",
        "  for i in range(len(aspects)):\n",
        "    aspects[i] = getCompund(list_dep, aspects[i])\n",
        "  return aspects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_ujdlFNOTUK"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[11])\n",
        "# x, y, nsubjI = getDependencies(\"I had fun with my nokia phone\")\n",
        "aspect, opinions = multiOpinion(x, y, nsubjI)\n",
        "# aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, opinions)\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmupLdI7TMFd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpjcqdH5Xk40"
      },
      "source": [
        "# when the secomd argument in nsubj dependency is not noun and the first is adj.\n",
        "# the feature of the sentence will be the object of it.\n",
        "# use dependencies (nsubj , xcomp , obj) to get the feature.\n",
        "# Ex : it is great having the LCD Display.\n",
        "def apply_nsubj_second(list_dep, dependancy):\n",
        "  f_arg = ''\n",
        "  s_arg = dependancy[1]\n",
        "  verb = ''\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'dep' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'obj' and dep[1] == verb :\n",
        "      f_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ub7aVsdcuJ7"
      },
      "source": [
        "# when the second argument is noun and the opnion part is verb.\n",
        "# the opinion will be the complement of the verb.\n",
        "# Ex : the flash works great.\n",
        "def apply_nsubj_forth (list_dep, dependency) :\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = ''\n",
        "  verb = dependency[1]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'advmod' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ7IDbuvi3SS"
      },
      "source": [
        "# when the feature and opinion pair candidate could in same dependency.\n",
        "# amod dependency the first arg is considered to be the feature.\n",
        "# the second arg is considered to be the opinion words.\n",
        "# Ex : this is a great screen.\n",
        "def apply_amod_sixth (list_dep, dependency) :\n",
        "  f_arg = dependency[1]\n",
        "  s_arg = dependency[2]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyNSP89wsYC-"
      },
      "source": [
        "# when the same opinion word is used to describe more than one feature.\n",
        "# apply conj dependency on the related features. \n",
        "# Ex : Nokia has a good screen and battery.\n",
        "def apply_amod_eight (list_dep, feature) :\n",
        "  feats = []\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'conj' and dep[1] == feature:\n",
        "      feats.append(dep[2])\n",
        "  #call the function check compound of each feature\n",
        "  return feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NdRa9RQ4cBS"
      },
      "source": [
        "# when nsubj dependency is between two nouns.\n",
        "# the first argument can be used as a opinion word.\n",
        "# Ex : the battery was never a problem.\n",
        "def apply_nsubj_ten (list_dep, dependency):\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = dependency[1]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DXQbM5r5qto"
      },
      "source": [
        "# check negation of the opinion words as it can reverse the sentiment.\n",
        "def check_neg(list_dep, adj):\n",
        "    list_neg = ['no' , 'never' , 'not' , 'n\\'t' , 'none' , 'neither'] \n",
        "    #can also check the negative seed list for that.\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == 'advmod' and dep[1] == adj and ( dep[2] in list_neg) :\n",
        "        adj = dep[2] + ' ' + adj\n",
        "        return adj\n",
        "    return adj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbT910j_1R4G"
      },
      "source": [
        "def nsubjAdj(list_dep, list_pos, dependency):\n",
        "  aspect = dependency[2]\n",
        "  opinion = dependency[1]\n",
        "  if list_pos[dependency[1]] == \"JJR\":\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == \"advcl\" and dep[1] == dependency[1]:\n",
        "        opinion = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wYsYaug7O7L"
      },
      "source": [
        "# -All Together\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzzD0hOc7Rz2"
      },
      "source": [
        "def aspectOpinionPairExtractor(list_dep, list_pos):\n",
        "  aspect_opinion_pairs = set()\n",
        "  visited_dep = [False]*len(list_dep)\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'nsubj':\n",
        "      # print(\"nsubj\")\n",
        "      if \"JJ\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #1\n",
        "        aspect, opinion = nsubjAdj(list_dep, list_pos, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"JJ\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #2\n",
        "        aspect, opinion = apply_nsubj_second(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #3\n",
        "        aspect, opinion = opinionVerb(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #4\n",
        "        aspect, opinion = apply_nsubj_forth(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"NN\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #10\n",
        "        aspect, opinion = apply_nsubj_ten(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'amod' and visited_dep[list_dep.index(dep)] == False:\n",
        "      # print(\"amod\")\n",
        "      if \"JJ\" in list_pos[dep[2]]:\n",
        "        aspect, opinion = apply_amod_sixth(list_dep, dep) #6\n",
        "        aspects = apply_amod_eight(list_dep, aspect) #8\n",
        "        aspects.append(aspect)\n",
        "        for a in aspects:\n",
        "          addPair(a, opinion, list_dep, aspect_opinion_pairs)\n",
        "        aspect, opinions = multiOpinion(list_dep, dep, visited_dep) #7\n",
        "        for o in opinions:\n",
        "          addPair(aspect, o, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'obl' and \"JJ\" in list_pos[dep[1]]: #9\n",
        "      # print(\"obl\")\n",
        "      aspect, opinion = prepositions(dep)\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'acl:relcl': #5\n",
        "      # print(\"acl:relcl\")\n",
        "      aspect, opinion = relativeClause(list_dep, dep)\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "  return aspect_opinion_pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A95gaDa7R09g"
      },
      "source": [
        "def addPair(aspect, opinion, list_dep, aspect_opinion_pairs):\n",
        "  if aspect == \"\" or opinion == \"\":\n",
        "    return\n",
        "  aspect = getCompund(list_dep, aspect)\n",
        "  opinion = check_neg(list_dep, opinion)\n",
        "  p = (aspect, opinion)\n",
        "  # print(p)\n",
        "  aspect_opinion_pairs.add(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW6zkW3iUUmx",
        "outputId": "5ac033d9-3686-4787-a45f-f1c50ab76511"
      },
      "source": [
        "aspect_opinion_pairs = set()\n",
        "list_dep, list_pos = getDependencies(examples[3])\n",
        "# print(list_pos[\"more\"])\n",
        "x = aspectOpinionPairExtractor(list_dep, list_pos)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{('camera', 'like')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH9oosw4Lvx5"
      },
      "source": [
        "# Aspect-Opinion Pair Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgw1VgOPXGuB"
      },
      "source": [
        "## Reviews Anlyzer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e5jSwi_L0TZ"
      },
      "source": [
        "def reviewsAnalyzer(reviews_list, debug = False):\n",
        "  # list to hold each review's sentences and its aspects \n",
        "  # reviews->[ sentences->[ aspects->[{aspect: opinion}, {aspect, opinion}]], [[]], [[]], ]\n",
        "  reviews_sentences_aspects = []\n",
        "\n",
        "  # For each review:\n",
        "    # 1- split to sentences using spacy\n",
        "    # 2- for each sentence:\n",
        "      # 3- get dependences\n",
        "      # 4- extract aspect_opinion pairs\n",
        "  \n",
        "  for review in reviews_list:\n",
        "    # print(\"-=-=R-=>\", review)\n",
        "    review_boundries = nlp(review)\n",
        "    review_sentences = []\n",
        "    for sentence in list(review_boundries.sents): # 1, 2\n",
        "      # print(\"-=-=S-=>\", sentence)\n",
        "      sentence_aspects = []\n",
        "      sentence1 = str(sentence).translate( str.maketrans( '', '', string.punctuation )).strip()\n",
        "      # print(\"-=-=S1-=>\", sentence1)\n",
        "      if (sentence1 == '' or sentence1 == ' ' or len(sentence1) == 0):\n",
        "            continue\n",
        "      list_dep, list_pos = getDependencies(sentence1) # 3\n",
        "      aspect_opinion_pairs = aspectOpinionPairExtractor(list_dep=list_dep, list_pos=list_pos) # 4\n",
        "      if debug == True:\n",
        "        print(\"==========\")\n",
        "        print(\"sentence: \", sentence1)\n",
        "        print(\"dependencies: \", list_dep)\n",
        "        print(\"POS: \", list_pos)\n",
        "        print(\"aspects opinion pairs: \", aspect_opinion_pairs)\n",
        "        print(\"==========\")\n",
        "      for as_op_pair in aspect_opinion_pairs:\n",
        "        sentence_aspects.append(as_op_pair)\n",
        "      review_sentences.append(sentence_aspects)\n",
        "    reviews_sentences_aspects.append(review_sentences)\n",
        "  return reviews_sentences_aspects"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-XkBXxeXV8t"
      },
      "source": [
        "def getDependencies(review_sentence):\n",
        "  document = client.annotate(str(review_sentence))\n",
        "  # print(\"=====>\", review_sentence)\n",
        "  sentence = document.sentence[0]\n",
        "  dependency_parse = sentence.basicDependencies\n",
        "  token_dict = {}\n",
        "  pos_dict = {}\n",
        "  for i in range(0, len(sentence.token)) :\n",
        "      token_dict[sentence.token[i].tokenEndIndex] = sentence.token[i].word\n",
        "      pos_dict[sentence.token[i].word] = sentence.token[i].pos\n",
        "\n",
        "  # get a list of the dependencies with the words they connect\n",
        "  list_dep=[]\n",
        "  for i in range(0, len(dependency_parse.edge)):\n",
        "\n",
        "      source_node = dependency_parse.edge[i].source\n",
        "      source_name = token_dict[source_node]\n",
        "\n",
        "      target_node = dependency_parse.edge[i].target\n",
        "      target_name = token_dict[target_node]\n",
        "\n",
        "      dep = dependency_parse.edge[i].dep\n",
        "      list_dep.append((dep, source_name, target_name))\n",
        "  # print(list_dep)\n",
        "  return list_dep, pos_dict"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtqcWF31Xmr-"
      },
      "source": [
        "def aspectOpinionPairExtractor(list_dep, list_pos):\n",
        "  aspect_opinion_pairs = set()\n",
        "  visited_dep = [False]*len(list_dep)\n",
        "  for dep in list_dep:\n",
        "    if  'nsubj' in dep[0]:\n",
        "      # print(\"nsubj\")\n",
        "      if \"JJ\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #1\n",
        "        aspect, opinion = nsubjAdj(list_dep, list_pos, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"JJ\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #2\n",
        "        aspect, opinion = apply_nsubj_second(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #3\n",
        "        aspect, opinion = opinionVerb(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and (\"NN\" in list_pos[dep[2]]): #4\n",
        "        aspect, opinion = apply_nsubj_forth(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      #elif \"NN\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #10\n",
        "        #aspect, opinion = apply_nsubj_ten(list_dep, dep)\n",
        "        #addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"NN\" in list_pos[dep[1]]: #10\n",
        "        aspect, opinion = apply_nsubj_ten(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'amod' and visited_dep[list_dep.index(dep)] == False:\n",
        "      # print(\"amod\")\n",
        "      if \"JJ\" in list_pos[dep[2]]:\n",
        "        aspect, opinion = apply_amod_sixth(list_dep, dep) #6\n",
        "        # Get multi aspects for same opinion\n",
        "        aspects = apply_amod_eight(list_dep, aspect) #8\n",
        "        aspects.append(aspect)\n",
        "        for a in aspects:\n",
        "          addPair(a, opinion, list_dep, aspect_opinion_pairs)\n",
        "\n",
        "        # Get multi opinions for same aspect\n",
        "        aspect, opinions = multiOpinion(list_dep, dep, visited_dep) #7\n",
        "        for o in opinions:\n",
        "          addPair(aspect, o, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'obl' and \"JJ\" in list_pos[dep[1]]: #9\n",
        "      # print(\"obl\")\n",
        "      aspect = dep[2]\n",
        "      opinion = dep[1]\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'acl:relcl': #5\n",
        "      # print(\"acl:relcl\")\n",
        "      aspect, opinion = relativeClause(list_dep, dep)\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif 'nmod' in dep[0]: #new\n",
        "      aspect = dep[1]\n",
        "      opinion = dep[2]\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "  return aspect_opinion_pairs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bci22ybxXou0"
      },
      "source": [
        "def addPair(aspect, opinion, list_dep, aspect_opinion_pairs):\n",
        "  if aspect == \"\" or opinion == \"\":\n",
        "    return\n",
        "  aspect = getCompund(list_dep, aspect)\n",
        "  opinion = check_neg(list_dep, opinion)\n",
        "  p = (aspect, opinion)\n",
        "  # print(p)\n",
        "  aspect_opinion_pairs.add(p)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK-owXSwXd_2"
      },
      "source": [
        "## Dependencies Rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvaoHCvzXzvO"
      },
      "source": [
        "# Call after any function to return compund aspects or same aspect => battery life\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getCompund(list_dep, aspect):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"compound\" and dep[1] == aspect :\n",
        "      aspect = dep[2] + \" \" + aspect\n",
        "      break;\n",
        "  return aspect"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FmKJzMqYcrA"
      },
      "source": [
        "# 1\n",
        "# Extract pair when it's after capular verb => the battery is good \n",
        "# and if having comparitave adj then get the advcl => the battery is more satisfying\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# dependency => the nsubj dep that leaded to this case\n",
        "def nsubjAdj(list_dep, list_pos, dependency):\n",
        "  aspect = dependency[2]\n",
        "  opinion = dependency[1]\n",
        "  if list_pos[dependency[1]] == \"JJR\":\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == \"advcl\" and dep[1] == dependency[1]:\n",
        "        opinion = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkb7IAnlYcq1"
      },
      "source": [
        "# 2\n",
        "# when the second argument in nsubj dependency is not noun and the first is adj.\n",
        "# the feature of the sentence will be the object of it.\n",
        "# use dependencies (nsubj , xcomp , obj) to get the feature.\n",
        "# Ex : it is great having the LCD Display.\n",
        "def apply_nsubj_second(list_dep, dependancy):\n",
        "  f_arg = ''\n",
        "  s_arg = dependancy[1]\n",
        "  verb = ''\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'dep' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'obj' and dep[1] == verb :\n",
        "      f_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAMFq3ndYcqq"
      },
      "source": [
        "# 3\n",
        "# Extract pair when the opinions is the verb like love and like\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# dependency => the current dep that leaded to this case\n",
        "# sentiment_verbs => list of verbs that may be opinion\n",
        "sentiment_verbs = [\"like\", \"love\", \"adore\", \"enjoyed\", \"liked\", \"loved\", \"enjoy\", \"overloaded\"]\n",
        "def opinionVerb(list_dep, dependency):\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  # if(sentiment_verbs.count(dependency[1])):\n",
        "  opinion = dependency[1]\n",
        "  for dep in list_dep:\n",
        "    if (\"obj\" in dep[0] and dep[1] == opinion):\n",
        "      aspect = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwr-mnGwYcq3"
      },
      "source": [
        "# 4\n",
        "# when the second argument is noun and the opnion part is verb.\n",
        "# the opinion will be the complement of the verb.\n",
        "# Ex : the flash works great.\n",
        "def apply_nsubj_forth (list_dep, dependency) :\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = ''\n",
        "  verb = dependency[1]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'advmod' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPrl0FmrYcqt"
      },
      "source": [
        "# 5\n",
        "# Extract pair when there is a relative clause relation between the aspect and the opinion => movie mode that works good\n",
        "# list_dep => dependency_parsed\n",
        "# dependency => the current dep that leaded to this case\n",
        "def relativeClause(list_dep, dependency):\n",
        "  aspect = dependency[1]\n",
        "  relcl_opinion = dependency[2]\n",
        "  opinion = \"\"\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"advmod\" and relcl_opinion == dep[1]:\n",
        "      opinion = dep[2]\n",
        "      return aspect, opinion\n",
        "  return aspect, opinion"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FrHlqzoYcq6"
      },
      "source": [
        "# 6\n",
        "# when the feature and opinion pair candidate could in same dependency.\n",
        "# amod dependency the first arg is considered to be the feature.\n",
        "# the second arg is considered to be the opinion words.\n",
        "# Ex : this is a great screen.\n",
        "def apply_amod_sixth (list_dep, dependency) :\n",
        "  f_arg = dependency[1]\n",
        "  s_arg = dependency[2]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX9_fQ6WYcqv"
      },
      "source": [
        "# 7-1\n",
        "# Extract multi opinions if without \"and\" word. only with \",\"\n",
        "# list_dep => dependency_parsed\n",
        "# dependency => the current dep that leaded to this case\n",
        "# visited_dep => to make sure if the amod dependency was considered or not in the main loop\n",
        "def multiOpinion(list_dep, dependency, visited_dep):\n",
        "  aspect = dependency[1]\n",
        "  opinions = []\n",
        "  for dep in list_dep:\n",
        "    if(dep[0] == \"amod\" and dependency[1] == dep[1]):\n",
        "      opinions.append(dep[2])\n",
        "      visited_dep[list_dep.index(dep)] = True\n",
        "  opinions = getAndOpinions(list_dep, opinions)\n",
        "  return aspect, opinions\n",
        "\n",
        "# 7-2\n",
        "# Call after any function to get list of opinions if multi exist with \"and\" word\n",
        "# list_dep => dependency_parsed\n",
        "# opnions => list of opinions \"List\"\n",
        "def getAndOpinions(list_dep, opinions):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (opinions.count(dep[1]) != 0):\n",
        "      opinions.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (opinions.count(dep[2]) != 0):\n",
        "      opinions.append(dep[1])\n",
        "  return opinions"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPyhgRTlYcq7"
      },
      "source": [
        "# 8\n",
        "# when the same opinion word is used to describe more than one feature.\n",
        "# apply conj dependency on the related features. \n",
        "# Ex : Nokia has a good screen and battery.\n",
        "def apply_amod_eight (list_dep, feature) :\n",
        "  feats = []\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'conj' and dep[1] == feature:\n",
        "      feats.append(dep[2])\n",
        "  #call the function check compound of each feature\n",
        "  return feats"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNfw29XHYcqx"
      },
      "source": [
        "# 9\n",
        "# Extract pair when theres a preposition => i am happy \"with\" my phone\n",
        "# dependency => the current dep that leaded to this case\n",
        "def prepositions(dependency):\n",
        "  aspect = dependency[2]\n",
        "  opinion = dependency[1]\n",
        "  return aspect, opinion"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYpiAG8TYcq9"
      },
      "source": [
        "# 10\n",
        "# when nsubj dependency is between two nouns.\n",
        "# the first argument can be used as a opinion word.\n",
        "# Ex : the battery was never a problem.\n",
        "def apply_nsubj_ten (list_dep, dependency):\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = dependency[1]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg\n",
        "  "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SarUlp2hYcqz"
      },
      "source": [
        "# 11\n",
        "# Call after any function to get list of aspects if multi exist\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getAndAspects(list_dep, aspect):\n",
        "  aspects = [aspect]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (dep[1] == aspect):\n",
        "      aspects.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (dep[2] == aspect):\n",
        "      aspects.append(dep[1])\n",
        "  for i in range(len(aspects)):\n",
        "    aspects[i] = getCompund(list_dep, aspects[i])\n",
        "  return aspects"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9nG8xaQYcq-"
      },
      "source": [
        "# neg\n",
        "# check negation of the opinion words as it can reverse the sentiment.\n",
        "def check_neg(list_dep, adj):\n",
        "    list_neg = ['no' , 'never' , 'not' , 'n\\'t' , 'none' , 'neither'] \n",
        "    #can also check the negative seed list for that.\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == 'advmod' and dep[1] == adj and ( dep[2] in list_neg) :\n",
        "        adj = dep[2] + ' ' + adj\n",
        "        return adj\n",
        "    return adj"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "515tq6DzXxwy"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWPsmLIpYkUw",
        "outputId": "95d5ad35-89c0-44c1-cdf9-54cbfefee96d"
      },
      "source": [
        "xxx = \"mostafa nabil\"\n",
        "client.annotate(xxx)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text: \"mostafa nabil\"\n",
              "sentence {\n",
              "  token {\n",
              "    word: \"mostafa\"\n",
              "    pos: \"NN\"\n",
              "    value: \"mostafa\"\n",
              "    before: \"\"\n",
              "    after: \" \"\n",
              "    originalText: \"mostafa\"\n",
              "    lemma: \"mostafa\"\n",
              "    beginChar: 0\n",
              "    endChar: 7\n",
              "    tokenBeginIndex: 0\n",
              "    tokenEndIndex: 1\n",
              "    hasXmlContext: false\n",
              "    isNewline: false\n",
              "  }\n",
              "  token {\n",
              "    word: \"nabil\"\n",
              "    pos: \"NN\"\n",
              "    value: \"nabil\"\n",
              "    before: \" \"\n",
              "    after: \"\"\n",
              "    originalText: \"nabil\"\n",
              "    lemma: \"nabil\"\n",
              "    beginChar: 8\n",
              "    endChar: 13\n",
              "    tokenBeginIndex: 1\n",
              "    tokenEndIndex: 2\n",
              "    hasXmlContext: false\n",
              "    isNewline: false\n",
              "  }\n",
              "  tokenOffsetBegin: 0\n",
              "  tokenOffsetEnd: 2\n",
              "  sentenceIndex: 0\n",
              "  characterOffsetBegin: 0\n",
              "  characterOffsetEnd: 13\n",
              "  basicDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    edge {\n",
              "      source: 2\n",
              "      target: 1\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 2\n",
              "  }\n",
              "  collapsedDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    edge {\n",
              "      source: 2\n",
              "      target: 1\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 2\n",
              "  }\n",
              "  collapsedCCProcessedDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    edge {\n",
              "      source: 2\n",
              "      target: 1\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 2\n",
              "  }\n",
              "  enhancedDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    edge {\n",
              "      source: 2\n",
              "      target: 1\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 2\n",
              "  }\n",
              "  enhancedPlusPlusDependencies {\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 1\n",
              "    }\n",
              "    node {\n",
              "      sentenceIndex: 0\n",
              "      index: 2\n",
              "    }\n",
              "    edge {\n",
              "      source: 2\n",
              "      target: 1\n",
              "      dep: \"compound\"\n",
              "      isExtra: false\n",
              "      sourceCopy: 0\n",
              "      targetCopy: 0\n",
              "      language: UniversalEnglish\n",
              "    }\n",
              "    root: 2\n",
              "  }\n",
              "  hasRelationAnnotations: false\n",
              "  hasNumerizedTokensAnnotation: false\n",
              "  hasEntityMentionsAnnotation: false\n",
              "}\n",
              "xmlDoc: false\n",
              "hasEntityMentionsAnnotation: false\n",
              "hasCorefMentionAnnotation: false\n",
              "hasCorefAnnotation: false"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FvF9fn5USZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "044c6a30-e83e-483f-dc67-2552c82fe9e9"
      },
      "source": [
        "examples = {1: \"The battery life is good\",\n",
        "            2: \"It is great having the LCD display\",\n",
        "            3: \"I like this camera\",\n",
        "            4: \"The optical zoom works great\",\n",
        "            5: \"It has movie mode that works good for a digital camera\",\n",
        "            6: \"There is a great camera\",\n",
        "            71: \"Nokia has fine, excellent, cheapest battery\",\n",
        "            72: \"Nokia has fine, excellent and cheapest battery\",\n",
        "            8: \"Nokia has good screen and battery\",\n",
        "            9: \"I am happy with my Nokia phone\",\n",
        "            10: \"Battery life was never a problem for me\",\n",
        "            11: \"This camera will give you a great picture quality, LCD screen, and price\"}\n",
        "                        \n",
        "reviews_list = [\"i 've had the player for about 2 years now and it still performs nicely with the exception of an occasional wwhhhrrr sound from the motor\",\n",
        "                \"this camera is not good\",\n",
        "                \"the infrared is a blessing if you have a previous nokia and want to transfer your old phone book to this phone , saved me hours of re-entering my numbers .\",\n",
        "                \"it does well in all aspects of internet browsing\",\n",
        "                \"this is one of the nicest phones nokia has made \",\n",
        "                \"my favorite features are the speaker phone , the radio and the infrared .\",\n",
        "                \"the infrared is a blessing if you have a previous nokia and want to transfer your old phone book to this phone , saved me hours of re-entering my numbers .\",\n",
        "                \"This camera will give you a great picture quality, LCD screen, and price\"\n",
        "                ]\n",
        "reviews_aspects = reviewsAnalyzer(reviews_list, True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==========\n",
            "sentence:  i ve had the player for about 2 years now and it still performs nicely with the exception of an occasional wwhhhrrr sound from the motor\n",
            "dependencies:  [('nsubj', 'had', 'i'), ('aux', 'had', 've'), ('obj', 'had', 'player'), ('advmod', 'had', 'now'), ('conj', 'had', 'performs'), ('det', 'player', 'the'), ('nmod', 'player', 'years'), ('advmod', '2', 'about'), ('case', 'years', 'for'), ('nummod', 'years', '2'), ('obl', 'performs', 'exception'), ('cc', 'performs', 'and'), ('nsubj', 'performs', 'it'), ('advmod', 'performs', 'still'), ('advmod', 'performs', 'nicely'), ('case', 'exception', 'with'), ('det', 'exception', 'the'), ('nmod', 'exception', 'sound'), ('case', 'sound', 'of'), ('det', 'sound', 'an'), ('amod', 'sound', 'occasional'), ('compound', 'sound', 'wwhhhrrr'), ('nmod', 'sound', 'motor'), ('case', 'motor', 'from'), ('det', 'motor', 'the')]\n",
            "POS:  {'i': 'PRP', 've': 'VBP', 'had': 'VBD', 'the': 'DT', 'player': 'NN', 'for': 'IN', 'about': 'RB', '2': 'CD', 'years': 'NNS', 'now': 'RB', 'and': 'CC', 'it': 'PRP', 'still': 'RB', 'performs': 'VBZ', 'nicely': 'RB', 'with': 'IN', 'exception': 'NN', 'of': 'IN', 'an': 'DT', 'occasional': 'JJ', 'wwhhhrrr': 'NN', 'sound': 'NN', 'from': 'IN', 'motor': 'NN'}\n",
            "aspects opinion pairs:  {('wwhhhrrr sound', 'occasional'), ('player', 'had')}\n",
            "==========\n",
            "==========\n",
            "sentence:  this camera is not good\n",
            "dependencies:  [('det', 'camera', 'this'), ('nsubj', 'good', 'camera'), ('cop', 'good', 'is'), ('advmod', 'good', 'not')]\n",
            "POS:  {'this': 'DT', 'camera': 'NN', 'is': 'VBZ', 'not': 'RB', 'good': 'JJ'}\n",
            "aspects opinion pairs:  {('camera', 'not good')}\n",
            "==========\n",
            "==========\n",
            "sentence:  the infrared is a blessing if you have a previous nokia and want to transfer your old phone book to this phone  saved me hours of reentering my numbers\n",
            "dependencies:  [('det', 'infrared', 'the'), ('nsubj', 'blessing', 'infrared'), ('cop', 'blessing', 'is'), ('det', 'blessing', 'a'), ('advcl', 'blessing', 'have'), ('mark', 'have', 'if'), ('nsubj', 'have', 'you'), ('dep', 'have', 'saved'), ('obj', 'have', 'nokia'), ('conj', 'have', 'want'), ('det', 'nokia', 'a'), ('amod', 'nokia', 'previous'), ('cc', 'want', 'and'), ('xcomp', 'want', 'transfer'), ('obj', 'transfer', 'book'), ('obl', 'transfer', 'phone'), ('mark', 'transfer', 'to'), ('nmod:poss', 'book', 'your'), ('amod', 'book', 'old'), ('compound', 'book', 'phone'), ('case', 'phone', 'to'), ('det', 'phone', 'this'), ('iobj', 'saved', 'me'), ('obj', 'saved', 'hours'), ('nmod', 'hours', 'reentering'), ('dep', 'hours', 'numbers'), ('case', 'reentering', 'of'), ('nmod:poss', 'numbers', 'my')]\n",
            "POS:  {'the': 'DT', 'infrared': 'JJ', 'is': 'VBZ', 'a': 'DT', 'blessing': 'NN', 'if': 'IN', 'you': 'PRP', 'have': 'VBP', 'previous': 'JJ', 'nokia': 'NN', 'and': 'CC', 'want': 'VB', 'to': 'IN', 'transfer': 'VB', 'your': 'PRP$', 'old': 'JJ', 'phone': 'NN', 'book': 'NN', 'this': 'DT', 'saved': 'VBD', 'me': 'PRP', 'hours': 'NNS', 'of': 'IN', 'reentering': 'VBG', 'my': 'PRP$', 'numbers': 'NNS'}\n",
            "aspects opinion pairs:  {('nokia', 'previous'), ('nokia', 'have'), ('phone book', 'old'), ('infrared', 'blessing')}\n",
            "==========\n",
            "==========\n",
            "sentence:  it does well in all aspects of internet browsing\n",
            "dependencies:  [('nsubj', 'aspects', 'it'), ('cop', 'aspects', 'does'), ('advmod', 'aspects', 'well'), ('case', 'aspects', 'in'), ('det', 'aspects', 'all'), ('nmod', 'aspects', 'browsing'), ('case', 'browsing', 'of'), ('compound', 'browsing', 'internet')]\n",
            "POS:  {'it': 'PRP', 'does': 'VBZ', 'well': 'RB', 'in': 'IN', 'all': 'DT', 'aspects': 'NNS', 'of': 'IN', 'internet': 'NN', 'browsing': 'NN'}\n",
            "aspects opinion pairs:  {('it', 'aspects')}\n",
            "==========\n",
            "==========\n",
            "sentence:  this is one of the nicest phones nokia has made\n",
            "dependencies:  [('nsubj', 'one', 'this'), ('cop', 'one', 'is'), ('nmod', 'one', 'nokia'), ('amod', 'phones', 'nicest'), ('case', 'nokia', 'of'), ('det', 'nokia', 'the'), ('compound', 'nokia', 'phones'), ('nsubj', 'made', 'one'), ('aux', 'made', 'has')]\n",
            "POS:  {'this': 'DT', 'is': 'VBZ', 'one': 'CD', 'of': 'IN', 'the': 'DT', 'nicest': 'JJS', 'phones': 'NNS', 'nokia': 'NN', 'has': 'VBZ', 'made': 'VBN'}\n",
            "aspects opinion pairs:  {('phones', 'nicest')}\n",
            "==========\n",
            "==========\n",
            "sentence:  my favorite features are the speaker phone  the radio and the infrared\n",
            "dependencies:  [('nmod:poss', 'features', 'my'), ('amod', 'features', 'favorite'), ('nsubj', 'phone', 'features'), ('cop', 'phone', 'are'), ('det', 'phone', 'the'), ('compound', 'phone', 'speaker'), ('dep', 'phone', 'radio'), ('det', 'radio', 'the'), ('conj', 'radio', 'infrared'), ('cc', 'infrared', 'and'), ('det', 'infrared', 'the')]\n",
            "POS:  {'my': 'PRP$', 'favorite': 'JJ', 'features': 'NNS', 'are': 'VBP', 'the': 'DT', 'speaker': 'NN', 'phone': 'NN', 'radio': 'NN', 'and': 'CC', 'infrared': 'JJ'}\n",
            "aspects opinion pairs:  {('features', 'favorite'), ('features', 'phone')}\n",
            "==========\n",
            "==========\n",
            "sentence:  the infrared is a blessing if you have a previous nokia and want to transfer your old phone book to this phone  saved me hours of reentering my numbers\n",
            "dependencies:  [('det', 'infrared', 'the'), ('nsubj', 'blessing', 'infrared'), ('cop', 'blessing', 'is'), ('det', 'blessing', 'a'), ('advcl', 'blessing', 'have'), ('mark', 'have', 'if'), ('nsubj', 'have', 'you'), ('dep', 'have', 'saved'), ('obj', 'have', 'nokia'), ('conj', 'have', 'want'), ('det', 'nokia', 'a'), ('amod', 'nokia', 'previous'), ('cc', 'want', 'and'), ('xcomp', 'want', 'transfer'), ('obj', 'transfer', 'book'), ('obl', 'transfer', 'phone'), ('mark', 'transfer', 'to'), ('nmod:poss', 'book', 'your'), ('amod', 'book', 'old'), ('compound', 'book', 'phone'), ('case', 'phone', 'to'), ('det', 'phone', 'this'), ('iobj', 'saved', 'me'), ('obj', 'saved', 'hours'), ('nmod', 'hours', 'reentering'), ('dep', 'hours', 'numbers'), ('case', 'reentering', 'of'), ('nmod:poss', 'numbers', 'my')]\n",
            "POS:  {'the': 'DT', 'infrared': 'JJ', 'is': 'VBZ', 'a': 'DT', 'blessing': 'NN', 'if': 'IN', 'you': 'PRP', 'have': 'VBP', 'previous': 'JJ', 'nokia': 'NN', 'and': 'CC', 'want': 'VB', 'to': 'IN', 'transfer': 'VB', 'your': 'PRP$', 'old': 'JJ', 'phone': 'NN', 'book': 'NN', 'this': 'DT', 'saved': 'VBD', 'me': 'PRP', 'hours': 'NNS', 'of': 'IN', 'reentering': 'VBG', 'my': 'PRP$', 'numbers': 'NNS'}\n",
            "aspects opinion pairs:  {('nokia', 'previous'), ('nokia', 'have'), ('phone book', 'old'), ('infrared', 'blessing')}\n",
            "==========\n",
            "==========\n",
            "sentence:  This camera will give you a great picture quality LCD screen and price\n",
            "dependencies:  [('det', 'camera', 'This'), ('nsubj', 'give', 'camera'), ('aux', 'give', 'will'), ('iobj', 'give', 'you'), ('obj', 'give', 'screen'), ('compound', 'quality', 'picture'), ('det', 'screen', 'a'), ('amod', 'screen', 'great'), ('compound', 'screen', 'quality'), ('compound', 'screen', 'LCD'), ('conj', 'screen', 'price'), ('cc', 'price', 'and')]\n",
            "POS:  {'This': 'DT', 'camera': 'NN', 'will': 'MD', 'give': 'VB', 'you': 'PRP', 'a': 'DT', 'great': 'JJ', 'picture': 'NN', 'quality': 'NN', 'LCD': 'NN', 'screen': 'NN', 'and': 'CC', 'price': 'NN'}\n",
            "aspects opinion pairs:  {('quality screen', 'great'), ('price', 'great')}\n",
            "==========\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSK-H6jJVp0t",
        "outputId": "96000078-baff-479a-87b6-6b48defc1b9d"
      },
      "source": [
        "reviews_aspects[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('speakerphone', 'perfectly')]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu4Vhd3fA4tL"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAVM_oVMWVuP"
      },
      "source": [
        "# 'Nikon coolpix 4300.json'\n",
        "def evaluate_extraction(dataset_path):\n",
        "  dataset_sentences, label_aspects = read_dataset(dataset_path)\n",
        "  mined_aspects = reviewsAnalyzer(dataset_sentences)\n",
        "  aspects_precision_val = aspects_precision(label_aspects, mined_aspects)\n",
        "  sentences_precision_val = sentences_precision(label_aspects, mined_aspects)\n",
        "  print(\"=====\", dataset_path, \"======\\n\")\n",
        "  print(sentences_precision_val)\n",
        "  print(aspects_precision_val)\n",
        "  print(\"===========\\n\")\n",
        "  return sentences_precision_val, aspects_precision_val"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tdsuknCZOcD"
      },
      "source": [
        "dataset_sentences, label_aspects = read_dataset(\"Nokia 6610.json\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMgjUYGSZYEB",
        "outputId": "44339ceb-a1d1-4fd3-aba3-427931c42eb4"
      },
      "source": [
        "del label_aspects[1] [0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'work': '+'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-oyvDAD3A3r"
      },
      "source": [
        "# Read Json DataSets\n",
        "import json\n",
        "\n",
        "def read_dataset(dataset_path):\n",
        "  # Opening JSON file\n",
        "  dataset_file = open(dataset_path,)\n",
        "    \n",
        "  # returns JSON object as \n",
        "  # a dictionary\n",
        "  dataset = json.load(dataset_file)\n",
        "    \n",
        "  # Iterating through the json\n",
        "  # list\n",
        "\n",
        "  dataset_sentences = []\n",
        "  label_aspects = []\n",
        "  for review in dataset['data']:\n",
        "      dataset_sentences.append(review['sentence'])\n",
        "      in_aspects = []\n",
        "      for j in range(len(review['aspects'])):\n",
        "        # To remove implicit\n",
        "        if list(review['aspects'][j])[0] in review['sentence']:\n",
        "          in_aspects.append(review['aspects'][j])\n",
        "      label_aspects.append(in_aspects)\n",
        "\n",
        "  # Closing file\n",
        "  dataset_file.close()\n",
        "  return dataset_sentences, label_aspects"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpCEoTyNDG-G"
      },
      "source": [
        "def sentences_precision(label_aspects, mined_aspects):\n",
        "  # Correctly mined counter\n",
        "  correctly_mined = 0\n",
        "  aspects_counter = 0\n",
        "  for i in range(len(label_aspects)):\n",
        "    # print(\"===\")\n",
        "    correctly_mined_sent = True\n",
        "\n",
        "    for j in range(len(label_aspects[i])):\n",
        "      correctly_mined_aspect = False\n",
        "      # print(aspects[i][j])\n",
        "      label_aspect = list(label_aspects[i][j])[0]\n",
        "      for m in range(len(mined_aspects[i])):\n",
        "        for k in range(len(mined_aspects[i][m])):\n",
        "          if (label_aspect in mined_aspects[i][m][k][0]) or (mined_aspects[i][m][k][0] in label_aspect):\n",
        "            correctly_mined_aspect = True\n",
        "      if correctly_mined_aspect == False:\n",
        "        correctly_mined_sent = False\n",
        "        break\n",
        "    \n",
        "    if correctly_mined_sent == True:\n",
        "      aspects_counter += len(label_aspects[i])\n",
        "      correctly_mined += 1\n",
        "    # else:\n",
        "    #   print(\"review #\", i, \"\\n\")\n",
        "    #   print(\"mined aspects\", mined_aspects[i], \"\\n\")\n",
        "    #   print(\"label aspects\", label_aspects[i], \"\\n\")\n",
        "\n",
        "  # print(correctly_mined)\n",
        "  # print(len(label_aspects))\n",
        "  # print(\"aspects_counter: \", aspects_counter)\n",
        "  return correctly_mined/len(label_aspects) * 100"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rrNd073O0WN"
      },
      "source": [
        "all_mined = 0\n",
        "for sentence in reviews_aspects:\n",
        "  uniq = set()\n",
        "  for aspects in sentence:\n",
        "    for aspect in aspects:\n",
        "      uniq.add(aspect[0])\n",
        "\n",
        "  all_mined += len(uniq)\n",
        "all_mined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV5TrQVoOvfz"
      },
      "source": [
        "def aspects_precision(label_aspects, mined_aspects):\n",
        "  # Correctly mined\n",
        "  correctly_mined = 0\n",
        "  # All Mined \n",
        "\n",
        "  # All Correct\n",
        "  all_correct = 0\n",
        "  for i in range(len(label_aspects)):\n",
        "    # print(\"===\")\n",
        "    for j in range(len(label_aspects[i])):\n",
        "      # print(aspects[i][j])\n",
        "      label_aspect = list(label_aspects[i][j])[0]\n",
        "      all_correct += 1\n",
        "      for m in range(len(mined_aspects[i])):\n",
        "        for k in range(len(mined_aspects[i][m])):\n",
        "          if (label_aspect in mined_aspects[i][m][k][0]) or (mined_aspects[i][m][k][0] in label_aspect):\n",
        "            correctly_mined += 1\n",
        "            # to be checked again\n",
        "          elif (label_aspect in mined_aspects[i][m][k][1]) or (mined_aspects[i][m][k][1] in label_aspect):\n",
        "            correctly_mined += 1\n",
        "    \n",
        "  print(\"correctly_mined: \", correctly_mined)\n",
        "  print(\"all_correct: \", all_correct)\n",
        "  return correctly_mined/all_correct * 100"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXmk7b2lBHe6",
        "outputId": "8af0a2cb-b937-47d8-8d8c-3efa8cff1762"
      },
      "source": [
        "%cd drive/MyDrive/GP/pair-extraction/datasets/CustomerReviewData_2004_2012\\ json"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/GP/pair-extraction/datasets/CustomerReviewData_2004_2012 json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Am6OA8PBiFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6bf8f20-2dfe-4b70-fc9b-b34a806a951f"
      },
      "source": [
        "evaluate_extraction(\"Nikon coolpix 4300.json\")\n",
        "evaluate_extraction(\"Nokia 6610.json\")\n",
        "evaluate_extraction(\"Creative Labs Nomad Jukebox Zen Xtra 40GB.json\")\n",
        "evaluate_extraction(\"Canon G3.json\")\n",
        "evaluate_extraction(\"Apex AD2600 Progressive-scan DVD player.json\")\n",
        "\n",
        "evaluate_extraction(\"../Reviews-9-products json/norton.json\")\n",
        "evaluate_extraction(\"../Reviews-9-products json/Nokia 6600.json\")\n",
        "evaluate_extraction(\"../Reviews-9-products json/MicroMP3.json\")\n",
        "evaluate_extraction(\"../Reviews-9-products json/Linksys Router.json\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correctly_mined:  160\n",
            "all_correct:  165\n",
            "===== Nikon coolpix 4300.json ======\n",
            "\n",
            "85.26011560693641\n",
            "96.96969696969697\n",
            "===========\n",
            "\n",
            "correctly_mined:  287\n",
            "all_correct:  290\n",
            "===== Nokia 6610.json ======\n",
            "\n",
            "84.43223443223444\n",
            "98.9655172413793\n",
            "===========\n",
            "\n",
            "correctly_mined:  580\n",
            "all_correct:  694\n",
            "===== Creative Labs Nomad Jukebox Zen Xtra 40GB.json ======\n",
            "\n",
            "83.91608391608392\n",
            "83.5734870317003\n",
            "===========\n",
            "\n",
            "correctly_mined:  227\n",
            "all_correct:  244\n",
            "===== Canon G3.json ======\n",
            "\n",
            "85.25963149078727\n",
            "93.0327868852459\n",
            "===========\n",
            "\n",
            "correctly_mined:  228\n",
            "all_correct:  328\n",
            "===== Apex AD2600 Progressive-scan DVD player.json ======\n",
            "\n",
            "80.27027027027027\n",
            "69.51219512195121\n",
            "===========\n",
            "\n",
            "correctly_mined:  109\n",
            "all_correct:  197\n",
            "===== ../Reviews-9-products json/norton.json ======\n",
            "\n",
            "71.84210526315789\n",
            "55.32994923857868\n",
            "===========\n",
            "\n",
            "correctly_mined:  288\n",
            "all_correct:  406\n",
            "===== ../Reviews-9-products json/Nokia 6600.json ======\n",
            "\n",
            "66.96750902527076\n",
            "70.93596059113301\n",
            "===========\n",
            "\n",
            "correctly_mined:  271\n",
            "all_correct:  357\n",
            "===== ../Reviews-9-products json/MicroMP3.json ======\n",
            "\n",
            "84.95049504950495\n",
            "75.91036414565826\n",
            "===========\n",
            "\n",
            "correctly_mined:  136\n",
            "all_correct:  206\n",
            "===== ../Reviews-9-products json/Linksys Router.json ======\n",
            "\n",
            "81.72231985940246\n",
            "66.01941747572816\n",
            "===========\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(81.72231985940246, 66.01941747572816)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJrf9X8MV3Qh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}