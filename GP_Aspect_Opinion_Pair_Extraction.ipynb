{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GP-Aspect Opinion Pair Extraction",
      "provenance": [],
      "collapsed_sections": [
        "k1Az2ECuAfG8",
        "kP_qn4hAZ6Ys",
        "2zFvaA8_A32_",
        "0X9FlEjfaP04",
        "5ySGY6y-exgS",
        "2wYsYaug7O7L"
      ],
      "authorship_tag": "ABX9TyMCNSHjKSPuKz5c1trjsSHL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafanabil198/Reviewlize-Graduation-Project/blob/aspect-opinion-pair-extraction/GP_Aspect_Opinion_Pair_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51J1ZqenajeH"
      },
      "source": [
        "## Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUF_TgLkaoTJ",
        "outputId": "06779311-2ded-4b28-8e05-98456d297688"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1jR582pjUDA"
      },
      "source": [
        "corenlp_dir = 'drive/My Drive/GP/pair-extraction/corenlp'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpKwWeVkASGt"
      },
      "source": [
        "## Installation & Environment Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Az2ECuAfG8"
      },
      "source": [
        "### Installing Stanza"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiFwYAgW4Mss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7ff5424-efaf-421b-9daf-d8cc499af70c"
      },
      "source": [
        "# Install stanza\n",
        "!pip install stanza\n",
        "\n",
        "# Import stanza\n",
        "import stanza"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stanza\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/ae/a70a58ce6b4e2daad538688806ee0f238dbe601954582a74ea57cde6c532/stanza-1.2-py3-none-any.whl (282kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 20.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30kB 24.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 51kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 61kB 24.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 71kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 81kB 21.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 92kB 18.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 102kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 112kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 122kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 143kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 153kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 163kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 174kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 184kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 194kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 204kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 215kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 225kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 235kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 245kB 16.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 256kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 266kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 276kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 16.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.8.1+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (54.2.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP_qn4hAZ6Ys"
      },
      "source": [
        "### Installing Spacy and Pysbd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w08A6CIPZ59f",
        "outputId": "d948e42a-3f84-40ac-e2c0-4e5fb8141e99"
      },
      "source": [
        "# Install pysbd\n",
        "!pip install pysbd\n",
        "\n",
        "import spacy\n",
        "from pysbd.utils import PySBDFactory\n",
        "nlp = spacy.blank('en')\n",
        "nlp.add_pipe(PySBDFactory(nlp))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pysbd\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/0a/c99fb7d7e176f8b176ef19704a32e6a9c6aafdf19ef75a187f701fc15801/pysbd-0.3.4-py3-none-any.whl (71kB)\n",
            "\r\u001b[K     |████▋                           | 10kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 20kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 30kB 26.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 40kB 27.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 51kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 61kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pysbd\n",
            "Successfully installed pysbd-0.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zFvaA8_A32_"
      },
      "source": [
        "### Downloading & Setting up Stanford CoreNLP on server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgK6-LPV-OdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a5ef026-67c4-4fb0-cb80-640c64cd4a53"
      },
      "source": [
        "# Download the Stanford CoreNLP package with Stanza's installation command\n",
        "# This'll take several minutes, depending on the network speed\n",
        "corenlp_dir = './corenlp'\n",
        "stanza.install_corenlp(dir=corenlp_dir)\n",
        "\n",
        "# Set the CORENLP_HOME environment variable to point to the installation location\n",
        "import os\n",
        "os.environ[\"CORENLP_HOME\"] = corenlp_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-12 16:45:27 WARNING: Directory ./corenlp already exists. Please install CoreNLP to a new directory.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X9FlEjfaP04"
      },
      "source": [
        "### Downloading & Setting up Stanford CoreNLP On Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKtBXh4MaSrS",
        "outputId": "11d32849-f2d6-447f-a618-78b8fd0522cc"
      },
      "source": [
        "# Download the Stanford CoreNLP package with Stanza's installation command\n",
        "# This'll take several minutes, depending on the network speed\n",
        "corenlp_dir = 'drive/My Drive/GP/pair-extraction/corenlp'\n",
        "stanza.install_corenlp(dir=corenlp_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-25 02:46:12 INFO: Installing CoreNLP package into drive/My Drive/GP/pair-extraction/corenlp...\n",
            "Downloading http://nlp.stanford.edu/software/stanford-corenlp-latest.zip: 100%|██████████| 505M/505M [21:31<00:00, 391kB/s] \n",
            "2021-01-25 03:07:49 WARNING: For customized installation location, please set the `CORENLP_HOME` environment variable to the location of the installation. In Unix, this is done with `export CORENLP_HOME=drive/My Drive/GP/pair-extraction/corenlp`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRXWoo9VhNr6"
      },
      "source": [
        "### Set Environment variable for CoreNLP on Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s63dElL0hVb0"
      },
      "source": [
        "# Set the CORENLP_HOME environment variable to point to the installation location\n",
        "import os\n",
        "os.environ[\"CORENLP_HOME\"] = corenlp_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJsuO6D8D05q"
      },
      "source": [
        "## Initialize Stanford Parser CoreNLP Interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZNHxXHkH1K2"
      },
      "source": [
        "### Constructing CoreNLPClient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS4OKnqJ8wui"
      },
      "source": [
        "# Import client module\n",
        "from stanza.server import CoreNLPClient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbOBugvd9JaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd5cf39-23fa-48ec-8c02-dd8e7c8ce58b"
      },
      "source": [
        "# Construct a CoreNLPClient with some basic annotators, a memory allocation of 4GB, and port number 9001\n",
        "client = CoreNLPClient(\n",
        "        annotators=['tokenize','pos','lemma','depparse'],\n",
        "        memory='16G',\n",
        "        endpoint='http://localhost:9001',\n",
        "        be_quiet=True)\n",
        "\n",
        "print(client)\n",
        "\n",
        "# Start the background server and wait for some time\n",
        "# Note that in practice this is totally optional, as by default the server will be started when the first annotation is performed\n",
        "client.start()\n",
        "import time; time.sleep(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-12 23:09:09 INFO: Writing properties to tmp file: corenlp_server-faab67083f734635.props\n",
            "2021-04-12 23:09:09 INFO: Starting server with command: java -Xmx16G -cp drive/My Drive/GP/pair-extraction/corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-faab67083f734635.props -annotators tokenize,pos,lemma,depparse -preload -outputFormat serialized\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<stanza.server.client.CoreNLPClient object at 0x7f7fa1f99710>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spZrJ-oFdkdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b991d9-5641-4819-a482-2598aeff3cf8"
      },
      "source": [
        "# Print background processes and look for java\n",
        "# You should be able to see a StanfordCoreNLPServer java process running in the background\n",
        "!ps -o pid,cmd | grep java"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    276 java -Xmx16G -cp drive/My Drive/GP/pair-extraction/corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-faab67083f734635.props -annotators tokenize,pos,lemma,depparse -preload -outputFormat serialized\n",
            "    295 /bin/bash -c ps -o pid,cmd | grep java\n",
            "    297 grep java\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ySGY6y-exgS"
      },
      "source": [
        "# -Dependency printing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aJJ5mANUM2PG",
        "outputId": "b58e130c-733f-4d6a-f6d1-fb94256fa80b"
      },
      "source": [
        "document = client.annotate(\"I am happy with my Nokia phone\")\n",
        "sentence = document.sentence[0]\n",
        "sentence.token[2].pos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'JJ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI-LngNZagqQ"
      },
      "source": [
        "def getDependencies(review_sentence):\n",
        "  # doc = nlp(text)\n",
        "  # for t in list(doc.sents):\n",
        "  document = client.annotate(str(review_sentence))\n",
        "  sentence = document.sentence[0]\n",
        "  dependency_parse = sentence.basicDependencies\n",
        "  tokens_parse = sentence.token\n",
        "  token_dict = {}\n",
        "  pos_dict = {}\n",
        "  for i in range(0, len(sentence.token)) :\n",
        "      token_dict[sentence.token[i].tokenEndIndex] = sentence.token[i].word\n",
        "      pos_dict[sentence.token[i].word] = sentence.token[i].pos\n",
        "\n",
        "  #get a list of the dependencies with the words they connect\n",
        "  list_dep=[]\n",
        "  for i in range(0, len(dependency_parse.edge)):\n",
        "\n",
        "      source_node = dependency_parse.edge[i].source\n",
        "      source_name = token_dict[source_node]\n",
        "\n",
        "      target_node = dependency_parse.edge[i].target\n",
        "      target_name = token_dict[target_node]\n",
        "\n",
        "      dep = dependency_parse.edge[i].dep\n",
        "      list_dep.append((dep, source_name, target_name))\n",
        "  # print(list_dep)\n",
        "  return list_dep, pos_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgJMcnaGdsA"
      },
      "source": [
        "examples = {1: \"The battery life is good\",\n",
        "            2: \"It is great having the LCD display\",\n",
        "            3: \"I like this camera\",\n",
        "            4: \"The optical zoom works great\",\n",
        "            5: \"It has movie mode that works good for a digital camera\",\n",
        "            6: \"There is a great camera\",\n",
        "            71: \"Nokia has fine, excellent, cheapest battery\",\n",
        "            72: \"Nokia has fine, excellent and cheapest battery\",\n",
        "            8: \"Nokia has good screen and battery\",\n",
        "            9: \"I am happy with my Nokia phone\",\n",
        "            10: \"Battery life was never a problem for me\",\n",
        "            11: \"This camera will give you a great picture quality, LCD screen, and price\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuXqZwSaOh0-"
      },
      "source": [
        "# 1\n",
        "# Extract pair when it's after capular verb => the battery is good\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def copularVerb(list_dep, list_pos, nsubjIx):\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  for nsubjI in nsubjIx:\n",
        "    if(\"JJ\" in list_pos[list_dep[nsubjI][1]]):\n",
        "      for dep in list_dep:\n",
        "        if dep[0] == \"cop\" and dep[1] == list_dep[nsubjI][1]:\n",
        "          opinion = list_dep[nsubjI][1]\n",
        "          aspect = list_dep[nsubjI][2]\n",
        "    if aspect != \"\" and opinion != \"\":\n",
        "      break\n",
        "  return aspect, opinion\n",
        "\n",
        "# Call after any function to return compund aspects or same aspect => battery life\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getCompund(list_dep, aspect):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"compound\" and dep[1] == aspect :\n",
        "      aspect = dep[2] + \" \" + aspect\n",
        "      break;\n",
        "  return aspect\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6f1JCAoXiII"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[1])\n",
        "aspect, opinion = copularVerb(x, y, nsubjI)\n",
        "aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \",opinions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZAmM2gTX9py"
      },
      "source": [
        "# 3\n",
        "# Extract pair when the opinions is the verb like love and like\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "# sentiment_verbs => list of verbs that may be opinion\n",
        "sentiment_verbs = [\"like\", \"love\", \"adore\", \"enjoyed\", \"liked\", \"loved\", \"enjoy\"]\n",
        "def opinionVerb(list_dep, dep):\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  if(sentiment_verbs.count(dep[1])):\n",
        "    opinion = dep[1]\n",
        "    for dep in list_dep:\n",
        "      if (dep[0] == \"obj\" and dep[1] == opinion):\n",
        "        aspect = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8HEa9d6cjl0",
        "outputId": "f3b0f1db-09eb-4e0f-e9b3-9189345bc450"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[3])\n",
        "aspect, opinion = opinionVerb(x, y, nsubjI)\n",
        "aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('nsubj', 'like', 'I'), ('obj', 'like', 'camera'), ('det', 'camera', 'this')]\n",
            "['camera']  -  ['like']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PykGw5pc1Lk"
      },
      "source": [
        "# 5\n",
        "# Extract pair when there is a relative clause relation between the aspect and the opinion => movie mode that works good\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def relativeClause(list_dep, dependency):\n",
        "  aspect = dependency[1]\n",
        "  relcl_opinion = dependency[2]\n",
        "  opinion = \"\"\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"advmod\" and relcl_opinion == dep[1]:\n",
        "      opinion = dep[2]\n",
        "      return aspect, opinion\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGpNXe3KrXGm",
        "outputId": "795754a0-26c9-4a53-f2a1-b3c7a9ccadaf"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[5])\n",
        "aspect, opinion = relativeClause(x, y, nsubjI)\n",
        "aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('nsubj', 'has', 'It'), ('obj', 'has', 'mode'), ('compound', 'mode', 'movie'), ('acl:relcl', 'mode', 'works'), ('nsubj', 'works', 'that'), ('advmod', 'works', 'good'), ('obl', 'works', 'camera'), ('case', 'camera', 'for'), ('det', 'camera', 'a'), ('amod', 'camera', 'digital')]\n",
            "['movie mode']  -  ['good']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAW_vwILrW9U"
      },
      "source": [
        "# 7-1\n",
        "# Extract multi opinions if without \"and\" word. only with \",\"\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def multiOpinion(list_dep, dependency, visited_dep):\n",
        "  aspect = dependency[1]\n",
        "  opinions = []\n",
        "  for dep in list_dep:\n",
        "    if(dep[0] == \"amod\" and dependency[1] == dep[1]):\n",
        "      opinions.append(dep[2])\n",
        "      visited_dep[list_dep.index(dep)] = True\n",
        "  opinions = getAndOpinions(list_dep, opinions)\n",
        "  return aspect, opinions\n",
        "\n",
        "# 7-2\n",
        "# Call after any function to get list of opinions if multi exist with \"and\" word\n",
        "# list_dep => dependency_parsed\n",
        "# opnions => list of opinions \"List\"\n",
        "def getAndOpinions(list_dep, opinions):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (opinions.count(dep[1]) != 0):\n",
        "      opinions.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (opinions.count(dep[2]) != 0):\n",
        "      opinions.append(dep[1])\n",
        "  return opinions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcY8WSuzyd1-",
        "outputId": "60c7e2c2-56bb-495b-f871-a5ff24d89dd5"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[72])\n",
        "# aspect, opinions = multiOpinion(x, y, nsubjI)\n",
        "# opinions = getAndOpinions(x, [opinion])\n",
        "# aspects = getAndAspects(x, aspects)\n",
        "# print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('nsubj', 'has', 'Nokia'), ('advmod', 'has', 'fine'), ('punct', 'has', ','), ('obj', 'has', 'battery'), ('conj', 'excellent', 'cheapest'), ('cc', 'cheapest', 'and'), ('amod', 'battery', 'excellent')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRvjc7eB1NjK"
      },
      "source": [
        "# 9\n",
        "# Extract pair when theres a preposition => i am happy \"with\" my phone\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# nsubjIx => list of indicies having nsubj relations\n",
        "def prepositions(list_dep, list_pos, nsubjIs):\n",
        "  opinion_pos = [\"JJ\", \"JJS\", \"RB\"]\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  for nsubjI in nsubjIs:\n",
        "    if (opinion_pos.count(list_pos[list_dep[nsubjI][1]]) != 0):\n",
        "      for dep in list_dep:\n",
        "          if dep[0] == \"obl\" and dep[1] == list_dep[nsubjI][1]:\n",
        "            aspect = dep[2]\n",
        "            opinion = dep[1]\n",
        "    if aspect != \"\" and opinion != \"\" :\n",
        "      break\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "nold0-yy5dYH",
        "outputId": "6b858a50-6968-4164-c62b-4ee5ce46c160"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[9])\n",
        "# x, y, nsubjI = getDependencies(\"I had fun with my nokia phone\")\n",
        "aspect, opinion = prepositions(x, y, nsubjI)\n",
        "# aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, [opinion])\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('nsubj', 'happy', 'I'), ('cop', 'happy', 'am'), ('obl', 'happy', 'phone'), ('case', 'phone', 'with'), ('nmod:poss', 'phone', 'my'), ('compound', 'phone', 'Nokia')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'JJ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED91Wkdl84QV"
      },
      "source": [
        "# 11\n",
        "# Call after any function to get list of aspects if multi exist\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getAndAspects(list_dep, aspect):\n",
        "  aspects = [aspect]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (dep[1] == aspect):\n",
        "      aspects.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (dep[2] == aspect):\n",
        "      aspects.append(dep[1])\n",
        "  for i in range(len(aspects)):\n",
        "    aspects[i] = getCompund(list_dep, aspects[i])\n",
        "  return aspects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_ujdlFNOTUK",
        "outputId": "c4afa941-b33d-403c-dd56-5b0694d23597"
      },
      "source": [
        "x, y, nsubjI = getDependencies(examples[11])\n",
        "# x, y, nsubjI = getDependencies(\"I had fun with my nokia phone\")\n",
        "aspect, opinions = multiOpinion(x, y, nsubjI)\n",
        "# aspect = getCompund(x, aspect)\n",
        "opinions = getAndOpinions(x, opinions)\n",
        "aspects = getAndAspects(x, aspect)\n",
        "print(aspects, \" - \", opinions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('det', 'camera', 'This'), ('nsubj', 'give', 'camera'), ('aux', 'give', 'will'), ('iobj', 'give', 'you'), ('obj', 'give', 'quality'), ('det', 'quality', 'a'), ('amod', 'quality', 'great'), ('compound', 'quality', 'picture'), ('punct', 'quality', ','), ('conj', 'quality', 'screen'), ('punct', 'quality', ','), ('conj', 'quality', 'price'), ('compound', 'screen', 'LCD'), ('cc', 'price', 'and')]\n",
            "['picture quality', 'LCD screen', 'price']  -  ['great']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmupLdI7TMFd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpjcqdH5Xk40"
      },
      "source": [
        "# when the secomd argument in nsubj dependency is not noun and the first is adj.\n",
        "# the feature of the sentence will be the object of it.\n",
        "# use dependencies (nsubj , xcomp , obj) to get the feature.\n",
        "# Ex : it is great having the LCD Display.\n",
        "def apply_nsubj_second(list_dep, dependancy):\n",
        "  f_arg = ''\n",
        "  s_arg = dependancy[1]\n",
        "  verb = ''\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'dep' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'obj' and dep[1] == verb :\n",
        "      f_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ub7aVsdcuJ7"
      },
      "source": [
        "# when the second argument is noun and the opnion part is verb.\n",
        "# the opinion will be the complement of the verb.\n",
        "# Ex : the flash works great.\n",
        "def apply_nsubj_forth (list_dep, dependency) :\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = ''\n",
        "  verb = dependency[1]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'advmod' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ7IDbuvi3SS"
      },
      "source": [
        "# when the feature and opinion pair candidate could in same dependency.\n",
        "# amod dependency the first arg is considered to be the feature.\n",
        "# the second arg is considered to be the opinion words.\n",
        "# Ex : this is a great screen.\n",
        "def apply_amod_sixth (list_dep, dependency) :\n",
        "  f_arg = dependency[1]\n",
        "  s_arg = dependency[2]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyNSP89wsYC-"
      },
      "source": [
        "# when the same opinion word is used to describe more than one feature.\n",
        "# apply conj dependency on the related features. \n",
        "# Ex : Nokia has a good screen and battery.\n",
        "def apply_amod_eight (list_dep, feature) :\n",
        "  feats = []\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'conj' and dep[1] == feature:\n",
        "      feats.append(dep[2])\n",
        "  #call the function check compound of each feature\n",
        "  return feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NdRa9RQ4cBS"
      },
      "source": [
        "# when nsubj dependency is between two nouns.\n",
        "# the first argument can be used as a opinion word.\n",
        "# Ex : the battery was never a problem.\n",
        "def apply_nsubj_ten (list_dep, dependency):\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = dependency[1]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DXQbM5r5qto"
      },
      "source": [
        "# check negation of the opinion words as it can reverse the sentiment.\n",
        "def check_neg(list_dep, adj):\n",
        "    list_neg = ['no' , 'never' , 'not' , 'n\\'t' , 'none' , 'neither'] \n",
        "    #can also check the negative seed list for that.\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == 'advmod' and dep[1] == adj and ( dep[2] in list_neg) :\n",
        "        adj = dep[2] + ' ' + adj\n",
        "        return adj\n",
        "    return adj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbT910j_1R4G"
      },
      "source": [
        "def nsubjAdj(list_dep, list_pos, dependency):\n",
        "  aspect = dependency[2]\n",
        "  opinion = dependency[1]\n",
        "  if list_pos[dependency[1]] == \"JJR\":\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == \"advcl\" and dep[1] == dependency[1]:\n",
        "        opinion = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wYsYaug7O7L"
      },
      "source": [
        "# -All Together\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzzD0hOc7Rz2"
      },
      "source": [
        "def aspectOpinionPairExtractor(list_dep, list_pos):\n",
        "  aspect_opinion_pairs = set()\n",
        "  visited_dep = [False]*len(list_dep)\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'nsubj':\n",
        "      # print(\"nsubj\")\n",
        "      if \"JJ\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #1\n",
        "        aspect, opinion = nsubjAdj(list_dep, list_pos, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"JJ\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #2\n",
        "        aspect, opinion = apply_nsubj_second(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #3\n",
        "        aspect, opinion = opinionVerb(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #4\n",
        "        aspect, opinion = apply_nsubj_forth(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"NN\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #10\n",
        "        aspect, opinion = apply_nsubj_ten(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'amod' and visited_dep[list_dep.index(dep)] == False:\n",
        "      # print(\"amod\")\n",
        "      if \"JJ\" in list_pos[dep[2]]:\n",
        "        aspect, opinion = apply_amod_sixth(list_dep, dep) #6\n",
        "        aspects = apply_amod_eight(list_dep, aspect) #8\n",
        "        aspects.append(aspect)\n",
        "        for a in aspects:\n",
        "          addPair(a, opinion, list_dep, aspect_opinion_pairs)\n",
        "        aspect, opinions = multiOpinion(list_dep, dep, visited_dep) #7\n",
        "        for o in opinions:\n",
        "          addPair(aspect, o, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'obl' and \"JJ\" in list_pos[dep[1]]: #9\n",
        "      # print(\"obl\")\n",
        "      aspect, opinion = prepositions(dep)\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'acl:relcl': #5\n",
        "      # print(\"acl:relcl\")\n",
        "      aspect, opinion = relativeClause(list_dep, dep)\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "  return aspect_opinion_pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A95gaDa7R09g"
      },
      "source": [
        "def addPair(aspect, opinion, list_dep, aspect_opinion_pairs):\n",
        "  if aspect == \"\" or opinion == \"\":\n",
        "    return\n",
        "  aspect = getCompund(list_dep, aspect)\n",
        "  opinion = check_neg(list_dep, opinion)\n",
        "  p = (aspect, opinion)\n",
        "  # print(p)\n",
        "  aspect_opinion_pairs.add(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW6zkW3iUUmx",
        "outputId": "3a76800d-d7fe-4805-d4f3-f5214bc2c1e7"
      },
      "source": [
        "aspect_opinion_pairs = set()\n",
        "list_dep, list_pos = getDependencies(examples[3])\n",
        "# print(list_pos[\"more\"])\n",
        "x = aspectOpinionPairExtractor(list_dep, list_pos)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{('camera', 'like')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH9oosw4Lvx5"
      },
      "source": [
        "# Aspect-Opinion Pair Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgw1VgOPXGuB"
      },
      "source": [
        "## Reviews Anlyzer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e5jSwi_L0TZ"
      },
      "source": [
        "def reviewsAnalyzer(reviews_list):\n",
        "  # list to hold each review's sentences and its aspects \n",
        "  # reviews->[ sentences->[ aspects->[{aspect: opinion}, {aspect, opinion}]], [[]], [[]], ]\n",
        "  reviews_sentences_aspects = []\n",
        "\n",
        "  # For each review:\n",
        "    # 1- split to sentences using spacy\n",
        "    # 2- for each sentence:\n",
        "      # 3- get dependences\n",
        "      # 4- extract aspect_opinion pairs\n",
        "  \n",
        "  for review in reviews_list:\n",
        "    review_boundries = nlp(review)\n",
        "    review_sentences = []\n",
        "    for sentence in list(review_boundries.sents): # 1, 2\n",
        "      sentence_aspects = []\n",
        "      list_dep, list_pos = getDependencies(sentence) # 3\n",
        "      aspect_opinion_pairs = aspectOpinionPairExtractor(list_dep=list_dep, list_pos=list_pos) # 4\n",
        "      for as_op_pair in aspect_opinion_pairs:\n",
        "        sentence_aspects.append(as_op_pair)\n",
        "      review_sentences.append(sentence_aspects)\n",
        "    reviews_sentences_aspects.append(review_sentences)\n",
        "  return reviews_sentences_aspects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-XkBXxeXV8t"
      },
      "source": [
        "def getDependencies(review_sentence):\n",
        "  document = client.annotate(str(review_sentence))\n",
        "  sentence = document.sentence[0]\n",
        "  dependency_parse = sentence.basicDependencies\n",
        "  token_dict = {}\n",
        "  pos_dict = {}\n",
        "  for i in range(0, len(sentence.token)) :\n",
        "      token_dict[sentence.token[i].tokenEndIndex] = sentence.token[i].word\n",
        "      pos_dict[sentence.token[i].word] = sentence.token[i].pos\n",
        "\n",
        "  # get a list of the dependencies with the words they connect\n",
        "  list_dep=[]\n",
        "  for i in range(0, len(dependency_parse.edge)):\n",
        "\n",
        "      source_node = dependency_parse.edge[i].source\n",
        "      source_name = token_dict[source_node]\n",
        "\n",
        "      target_node = dependency_parse.edge[i].target\n",
        "      target_name = token_dict[target_node]\n",
        "\n",
        "      dep = dependency_parse.edge[i].dep\n",
        "      list_dep.append((dep, source_name, target_name))\n",
        "  # print(list_dep)\n",
        "  return list_dep, pos_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtqcWF31Xmr-"
      },
      "source": [
        "def aspectOpinionPairExtractor(list_dep, list_pos):\n",
        "  aspect_opinion_pairs = set()\n",
        "  visited_dep = [False]*len(list_dep)\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'nsubj':\n",
        "      # print(\"nsubj\")\n",
        "      if \"JJ\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #1\n",
        "        aspect, opinion = nsubjAdj(list_dep, list_pos, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"JJ\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #2\n",
        "        aspect, opinion = apply_nsubj_second(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and \"NN\" not in list_pos[dep[2]]: #3\n",
        "        aspect, opinion = opinionVerb(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"VB\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #4\n",
        "        aspect, opinion = apply_nsubj_forth(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "      elif \"NN\" in list_pos[dep[1]] and \"NN\" in list_pos[dep[2]]: #10\n",
        "        aspect, opinion = apply_nsubj_ten(list_dep, dep)\n",
        "        addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'amod' and visited_dep[list_dep.index(dep)] == False:\n",
        "      # print(\"amod\")\n",
        "      if \"JJ\" in list_pos[dep[2]]:\n",
        "        aspect, opinion = apply_amod_sixth(list_dep, dep) #6\n",
        "        # Get multi aspects for same opinion\n",
        "        aspects = apply_amod_eight(list_dep, aspect) #8\n",
        "        aspects.append(aspect)\n",
        "        for a in aspects:\n",
        "          addPair(a, opinion, list_dep, aspect_opinion_pairs)\n",
        "\n",
        "        # Get multi opinions for same aspect\n",
        "        aspect, opinions = multiOpinion(list_dep, dep, visited_dep) #7\n",
        "        for o in opinions:\n",
        "          addPair(aspect, o, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'obl' and \"JJ\" in list_pos[dep[1]]: #9\n",
        "      # print(\"obl\")\n",
        "      aspect = dep[2]\n",
        "      opinion = dep[1]\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "    elif dep[0] == 'acl:relcl': #5\n",
        "      # print(\"acl:relcl\")\n",
        "      aspect, opinion = relativeClause(list_dep, dep)\n",
        "      addPair(aspect, opinion, list_dep, aspect_opinion_pairs)\n",
        "  return aspect_opinion_pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bci22ybxXou0"
      },
      "source": [
        "def addPair(aspect, opinion, list_dep, aspect_opinion_pairs):\n",
        "  if aspect == \"\" or opinion == \"\":\n",
        "    return\n",
        "  aspect = getCompund(list_dep, aspect)\n",
        "  opinion = check_neg(list_dep, opinion)\n",
        "  p = (aspect, opinion)\n",
        "  # print(p)\n",
        "  aspect_opinion_pairs.add(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK-owXSwXd_2"
      },
      "source": [
        "## Dependencies Rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvaoHCvzXzvO"
      },
      "source": [
        "# Call after any function to return compund aspects or same aspect => battery life\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getCompund(list_dep, aspect):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"compound\" and dep[1] == aspect :\n",
        "      aspect = dep[2] + \" \" + aspect\n",
        "      break;\n",
        "  return aspect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FmKJzMqYcrA"
      },
      "source": [
        "# 1\n",
        "# Extract pair when it's after capular verb => the battery is good \n",
        "# and if having comparitave adj then get the advcl => the battery is more satisfying\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# dependency => the nsubj dep that leaded to this case\n",
        "def nsubjAdj(list_dep, list_pos, dependency):\n",
        "  aspect = dependency[2]\n",
        "  opinion = dependency[1]\n",
        "  if list_pos[dependency[1]] == \"JJR\":\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == \"advcl\" and dep[1] == dependency[1]:\n",
        "        opinion = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkb7IAnlYcq1"
      },
      "source": [
        "# 2\n",
        "# when the second argument in nsubj dependency is not noun and the first is adj.\n",
        "# the feature of the sentence will be the object of it.\n",
        "# use dependencies (nsubj , xcomp , obj) to get the feature.\n",
        "# Ex : it is great having the LCD Display.\n",
        "def apply_nsubj_second(list_dep, dependancy):\n",
        "  f_arg = ''\n",
        "  s_arg = dependancy[1]\n",
        "  verb = ''\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'dep' and dep[1] == s_arg :\n",
        "      verb = dep[2]\n",
        "      break\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'obj' and dep[1] == verb :\n",
        "      f_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAMFq3ndYcqq"
      },
      "source": [
        "# 3\n",
        "# Extract pair when the opinions is the verb like love and like\n",
        "# list_dep => dependency_parsed\n",
        "# list_pos => Part Of Speech \"dictionary\"\n",
        "# dependency => the current dep that leaded to this case\n",
        "# sentiment_verbs => list of verbs that may be opinion\n",
        "sentiment_verbs = [\"like\", \"love\", \"adore\", \"enjoyed\", \"liked\", \"loved\", \"enjoy\"]\n",
        "def opinionVerb(list_dep, dep):\n",
        "  aspect = \"\"\n",
        "  opinion = \"\"\n",
        "  if(sentiment_verbs.count(dep[1])):\n",
        "    opinion = dep[1]\n",
        "    for dep in list_dep:\n",
        "      if (dep[0] == \"obj\" and dep[1] == opinion):\n",
        "        aspect = dep[2]\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwr-mnGwYcq3"
      },
      "source": [
        "# 4\n",
        "# when the second argument is noun and the opnion part is verb.\n",
        "# the opinion will be the complement of the verb.\n",
        "# Ex : the flash works great.\n",
        "def apply_nsubj_forth (list_dep, dependency) :\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = ''\n",
        "  verb = dependency[1]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'xcomp' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "    if dep[0] == 'advmod' and dep[1] == verb :\n",
        "      s_arg = dep[2]\n",
        "      break\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPrl0FmrYcqt"
      },
      "source": [
        "# 5\n",
        "# Extract pair when there is a relative clause relation between the aspect and the opinion => movie mode that works good\n",
        "# list_dep => dependency_parsed\n",
        "# dependency => the current dep that leaded to this case\n",
        "def relativeClause(list_dep, dependency):\n",
        "  aspect = dependency[1]\n",
        "  relcl_opinion = dependency[2]\n",
        "  opinion = \"\"\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"advmod\" and relcl_opinion == dep[1]:\n",
        "      opinion = dep[2]\n",
        "      return aspect, opinion\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FrHlqzoYcq6"
      },
      "source": [
        "# 6\n",
        "# when the feature and opinion pair candidate could in same dependency.\n",
        "# amod dependency the first arg is considered to be the feature.\n",
        "# the second arg is considered to be the opinion words.\n",
        "# Ex : this is a great screen.\n",
        "def apply_amod_sixth (list_dep, dependency) :\n",
        "  f_arg = dependency[1]\n",
        "  s_arg = dependency[2]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(f_arg)\n",
        "  # print(s_arg)\n",
        "  return f_arg , s_arg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX9_fQ6WYcqv"
      },
      "source": [
        "# 7-1\n",
        "# Extract multi opinions if without \"and\" word. only with \",\"\n",
        "# list_dep => dependency_parsed\n",
        "# dependency => the current dep that leaded to this case\n",
        "# visited_dep => to make sure if the amod dependency was considered or not in the main loop\n",
        "def multiOpinion(list_dep, dependency, visited_dep):\n",
        "  aspect = dependency[1]\n",
        "  opinions = []\n",
        "  for dep in list_dep:\n",
        "    if(dep[0] == \"amod\" and dependency[1] == dep[1]):\n",
        "      opinions.append(dep[2])\n",
        "      visited_dep[list_dep.index(dep)] = True\n",
        "  opinions = getAndOpinions(list_dep, opinions)\n",
        "  return aspect, opinions\n",
        "\n",
        "# 7-2\n",
        "# Call after any function to get list of opinions if multi exist with \"and\" word\n",
        "# list_dep => dependency_parsed\n",
        "# opnions => list of opinions \"List\"\n",
        "def getAndOpinions(list_dep, opinions):\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (opinions.count(dep[1]) != 0):\n",
        "      opinions.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (opinions.count(dep[2]) != 0):\n",
        "      opinions.append(dep[1])\n",
        "  return opinions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPyhgRTlYcq7"
      },
      "source": [
        "# 8\n",
        "# when the same opinion word is used to describe more than one feature.\n",
        "# apply conj dependency on the related features. \n",
        "# Ex : Nokia has a good screen and battery.\n",
        "def apply_amod_eight (list_dep, feature) :\n",
        "  feats = []\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == 'conj' and dep[1] == feature:\n",
        "      feats.append(dep[2])\n",
        "  #call the function check compound of each feature\n",
        "  return feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNfw29XHYcqx"
      },
      "source": [
        "# 9\n",
        "# Extract pair when theres a preposition => i am happy \"with\" my phone\n",
        "# dependency => the current dep that leaded to this case\n",
        "def prepositions(dependency):\n",
        "  aspect = dependency[2]\n",
        "  opinion = dependency[1]\n",
        "  return aspect, opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYpiAG8TYcq9"
      },
      "source": [
        "# 10\n",
        "# when nsubj dependency is between two nouns.\n",
        "# the first argument can be used as a opinion word.\n",
        "# Ex : the battery was never a problem.\n",
        "def apply_nsubj_ten (list_dep, dependency):\n",
        "  f_arg = dependency[2]\n",
        "  s_arg = dependency[1]\n",
        "  # for dep in list_dep:\n",
        "  #   if dep[0] == 'compound' and dep[1] == f_arg :\n",
        "  #     f_arg = dep[2] + \" \"+f_arg\n",
        "  #     break\n",
        "  # print(s_arg)\n",
        "  # print(f_arg)\n",
        "  return f_arg , s_arg\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SarUlp2hYcqz"
      },
      "source": [
        "# 11\n",
        "# Call after any function to get list of aspects if multi exist\n",
        "# list_dep => dependency_parsed\n",
        "# aspect => single aspect \"String\"\n",
        "def getAndAspects(list_dep, aspect):\n",
        "  aspects = [aspect]\n",
        "  for dep in list_dep:\n",
        "    if dep[0] == \"conj\" and (dep[1] == aspect):\n",
        "      aspects.append(dep[2])\n",
        "    elif dep[0] == \"conj\" and (dep[2] == aspect):\n",
        "      aspects.append(dep[1])\n",
        "  for i in range(len(aspects)):\n",
        "    aspects[i] = getCompund(list_dep, aspects[i])\n",
        "  return aspects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9nG8xaQYcq-"
      },
      "source": [
        "# neg\n",
        "# check negation of the opinion words as it can reverse the sentiment.\n",
        "def check_neg(list_dep, adj):\n",
        "    list_neg = ['no' , 'never' , 'not' , 'n\\'t' , 'none' , 'neither'] \n",
        "    #can also check the negative seed list for that.\n",
        "    for dep in list_dep:\n",
        "      if dep[0] == 'advmod' and dep[1] == adj and ( dep[2] in list_neg) :\n",
        "        adj = dep[2] + ' ' + adj\n",
        "        return adj\n",
        "    return adj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "515tq6DzXxwy"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FvF9fn5USZ1"
      },
      "source": [
        "examples = {1: \"The battery life is good\",\n",
        "            2: \"It is great having the LCD display\",\n",
        "            3: \"I like this camera\",\n",
        "            4: \"The optical zoom works great\",\n",
        "            5: \"It has movie mode that works good for a digital camera\",\n",
        "            6: \"There is a great camera\",\n",
        "            71: \"Nokia has fine, excellent, cheapest battery\",\n",
        "            72: \"Nokia has fine, excellent and cheapest battery\",\n",
        "            8: \"Nokia has good screen and battery\",\n",
        "            9: \"I am happy with my Nokia phone\",\n",
        "            10: \"Battery life was never a problem for me\",\n",
        "            11: \"This camera will give you a great picture quality, LCD screen, and price\"}\n",
        "                        \n",
        "reviews_list = [\"i recently purchased the canon powershot g3 and am extremely satisfied with the purchase .\",\n",
        "                \"It is great having the LCD display\",\n",
        "                \"I like this camera\",\n",
        "                \"The optical zoom works great\",\n",
        "                \"It has movie mode that works good for a digital camera\",\n",
        "                \"There is a great camera\",\n",
        "                \"Nokia has fine, excellent, cheapest battery\",\n",
        "                \"Nokia has fine, excellent and cheapest battery\",\n",
        "                \"Nokia has good screen and battery\",\n",
        "                \"I am happy with my Nokia phone\",\n",
        "                \"Battery life was never a problem for me\",\n",
        "                \"This camera will give you a great picture quality, LCD screen, and price\"]\n",
        "reviews_aspects = reviewsAnalyzer(reviews_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSK-H6jJVp0t",
        "outputId": "4afbd763-7bda-4ff1-d165-9c4dd858829f"
      },
      "source": [
        "reviews_aspects[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('purchase', 'satisfied')]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu4Vhd3fA4tL"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAVM_oVMWVuP"
      },
      "source": [
        "# 'Nikon coolpix 4300.json'\n",
        "def evaluate_extraction(dataset_path):\n",
        "  dataset_sentences, label_aspects = read_dataset(dataset_path)\n",
        "  mined_aspects = reviewsAnalyzer(dataset_sentences)\n",
        "  aspects_precision_val = aspects_precision(label_aspects, mined_aspects)\n",
        "  sentences_precision_val = sentences_precision(label_aspects, mined_aspects)\n",
        "  print(\"=====\", dataset_path, \"======\\n\")\n",
        "  print(sentences_precision_val)\n",
        "  print(aspects_precision_val)\n",
        "  print(\"===========\\n\")\n",
        "  return sentences_precision_val, aspects_precision_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-oyvDAD3A3r"
      },
      "source": [
        "# Read Json DataSets\n",
        "import json\n",
        "\n",
        "def read_dataset(dataset_path):\n",
        "  # Opening JSON file\n",
        "  dataset_file = open(dataset_path,)\n",
        "    \n",
        "  # returns JSON object as \n",
        "  # a dictionary\n",
        "  dataset = json.load(dataset_file)\n",
        "    \n",
        "  # Iterating through the json\n",
        "  # list\n",
        "  dataset_sentences = []\n",
        "  label_aspects = []\n",
        "  for review in dataset['data']:\n",
        "      dataset_sentences.append(review['sentence'])\n",
        "      label_aspects.append(review['aspects'])\n",
        "\n",
        "  # Closing file\n",
        "  dataset_file.close()\n",
        "  return dataset_sentences, label_aspects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpCEoTyNDG-G"
      },
      "source": [
        "def sentences_precision(label_aspects, mined_aspects):\n",
        "  # Correctly mined counter\n",
        "  correctly_mined = 0\n",
        "  \n",
        "  for i in range(len(label_aspects)):\n",
        "    # print(\"===\")\n",
        "    correctly_mined_sent = True\n",
        "\n",
        "    for j in range(len(label_aspects[i])):\n",
        "      correctly_mined_aspect = False\n",
        "      # print(aspects[i][j])\n",
        "      label_aspect = list(label_aspects[i][j])[0]\n",
        "      for m in range(len(mined_aspects[i])):\n",
        "        for k in range(len(mined_aspects[i][m])):\n",
        "          if (label_aspect in mined_aspects[i][m][k][0]) or (mined_aspects[i][m][k][0] in label_aspect):\n",
        "            correctly_mined_aspect = True\n",
        "      if correctly_mined_aspect == False:\n",
        "        correctly_mined_sent = False\n",
        "        break\n",
        "    \n",
        "    if correctly_mined_sent == True:\n",
        "      correctly_mined += 1\n",
        "\n",
        "  # print(correctly_mined)\n",
        "  # print(len(label_aspects))\n",
        "  return correctly_mined/len(label_aspects) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rrNd073O0WN"
      },
      "source": [
        "all_mined = 0\n",
        "for sentence in reviews_aspects:\n",
        "  uniq = set()\n",
        "  for aspects in sentence:\n",
        "    for aspect in aspects:\n",
        "      uniq.add(aspect[0])\n",
        "\n",
        "  all_mined += len(uniq)\n",
        "all_mined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV5TrQVoOvfz"
      },
      "source": [
        "def aspects_precision(label_aspects, mined_aspects):\n",
        "  # Correctly mined\n",
        "  correctly_mined = 0\n",
        "  # All Mined \n",
        "\n",
        "  # All Correct\n",
        "  all_correct = 0\n",
        "  for i in range(len(label_aspects)):\n",
        "    # print(\"===\")\n",
        "    for j in range(len(label_aspects[i])):\n",
        "      # print(aspects[i][j])\n",
        "      label_aspect = list(label_aspects[i][j])[0]\n",
        "      all_correct += 1\n",
        "      for m in range(len(mined_aspects[i])):\n",
        "        for k in range(len(mined_aspects[i][m])):\n",
        "          if (label_aspect in mined_aspects[i][m][k][0]) or (mined_aspects[i][m][k][0] in label_aspect):\n",
        "            correctly_mined += 1\n",
        "    \n",
        "  # print(correctly_mined)\n",
        "  # print(all_correct)\n",
        "  return correctly_mined/all_correct * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXmk7b2lBHe6",
        "outputId": "63ef5986-d7f5-4bcf-89a5-0a028b0d4d5c"
      },
      "source": [
        "%cd drive/MyDrive/GP/pair-extraction/datasets/CustomerReviewData_2004_2012\\ json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/GP/pair-extraction/datasets/CustomerReviewData_2004_2012 json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Am6OA8PBiFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c9d721-5df0-4871-a702-5ead3c033fae"
      },
      "source": [
        "evaluate_extraction(\"Nikon coolpix 4300.json\")\n",
        "evaluate_extraction(\"Nokia 6610.json\")\n",
        "evaluate_extraction(\"Creative Labs Nomad Jukebox Zen Xtra 40GB.json\")\n",
        "evaluate_extraction(\"Canon G3.json\")\n",
        "evaluate_extraction(\"Apex AD2600 Progressive-scan DVD player.json\")\n",
        "\n",
        "evaluate_extraction(\"../Reviews-9-products json/norton.json\")\n",
        "evaluate_extraction(\"../Reviews-9-products json/Nokia 6600.json\")\n",
        "evaluate_extraction(\"../Reviews-9-products json/MicroMP3.json\")\n",
        "evaluate_extraction(\"../Reviews-9-products json/Linksys Router.json\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== Nikon coolpix 4300.json ======\n",
            "\n",
            "78.03468208092485\n",
            "71.42857142857143\n",
            "===========\n",
            "\n",
            "===== Nokia 6610.json ======\n",
            "\n",
            "74.35897435897436\n",
            "64.11764705882354\n",
            "===========\n",
            "\n",
            "===== Creative Labs Nomad Jukebox Zen Xtra 40GB.json ======\n",
            "\n",
            "75.0\n",
            "55.188679245283026\n",
            "===========\n",
            "\n",
            "===== Canon G3.json ======\n",
            "\n",
            "78.72696817420436\n",
            "66.08391608391608\n",
            "===========\n",
            "\n",
            "===== Apex AD2600 Progressive-scan DVD player.json ======\n",
            "\n",
            "67.02702702702703\n",
            "34.80278422273782\n",
            "===========\n",
            "\n",
            "===== ../Reviews-9-products json/norton.json ======\n",
            "\n",
            "57.631578947368425\n",
            "29.268292682926827\n",
            "===========\n",
            "\n",
            "===== ../Reviews-9-products json/Nokia 6600.json ======\n",
            "\n",
            "54.51263537906137\n",
            "45.84221748400853\n",
            "===========\n",
            "\n",
            "===== ../Reviews-9-products json/MicroMP3.json ======\n",
            "\n",
            "65.84158415841584\n",
            "39.9673735725938\n",
            "===========\n",
            "\n",
            "===== ../Reviews-9-products json/Linksys Router.json ======\n",
            "\n",
            "78.73462214411248\n",
            "46.846846846846844\n",
            "===========\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(78.73462214411248, 46.846846846846844)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    }
  ]
}